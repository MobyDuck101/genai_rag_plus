{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f17305f-a113-4423-9b9a-43737763ed90",
   "metadata": {},
   "source": [
    "**Minimal install for Vertex AI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9d33f38-6324-4175-8689-d4e8f278c8ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-google-vertexai in /opt/conda/lib/python3.10/site-packages (1.0.3)\n",
      "Collecting langchain-experimental\n",
      "  Downloading langchain_experimental-0.0.58-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting neo4j\n",
      "  Downloading neo4j-5.20.0.tar.gz (202 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.0/203.0 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: google-cloud-aiplatform<2.0.0,>=1.47.0 in /opt/conda/lib/python3.10/site-packages (from langchain-google-vertexai) (1.49.0)\n",
      "Requirement already satisfied: google-cloud-storage<3.0.0,>=2.14.0 in /opt/conda/lib/python3.10/site-packages (from langchain-google-vertexai) (2.14.0)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.42 in /opt/conda/lib/python3.10/site-packages (from langchain-google-vertexai) (0.1.52)\n",
      "Requirement already satisfied: types-protobuf<5.0.0.0,>=4.24.0.4 in /opt/conda/lib/python3.10/site-packages (from langchain-google-vertexai) (4.25.0.20240417)\n",
      "Requirement already satisfied: types-requests<3.0.0,>=2.31.0 in /opt/conda/lib/python3.10/site-packages (from langchain-google-vertexai) (2.31.0.20240406)\n",
      "Collecting langchain<0.2.0,>=0.1.17 (from langchain-experimental)\n",
      "  Downloading langchain-0.1.17-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.10/site-packages (from neo4j) (2024.1)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai) (1.34.1)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai) (2.29.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai) (1.23.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai) (3.20.3)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai) (23.2)\n",
      "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai) (3.21.0)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai) (1.12.3)\n",
      "Requirement already satisfied: shapely<3.0.0dev in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai) (2.0.4)\n",
      "Requirement already satisfied: pydantic<3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai) (2.7.1)\n",
      "Requirement already satisfied: docstring-parser<1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai) (0.16)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage<3.0.0,>=2.14.0->langchain-google-vertexai) (2.4.1)\n",
      "Requirement already satisfied: google-resumable-media>=2.6.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage<3.0.0,>=2.14.0->langchain-google-vertexai) (2.7.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage<3.0.0,>=2.14.0->langchain-google-vertexai) (2.31.0)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage<3.0.0,>=2.14.0->langchain-google-vertexai) (1.5.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain<0.2.0,>=0.1.17->langchain-experimental) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain<0.2.0,>=0.1.17->langchain-experimental) (2.0.29)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain<0.2.0,>=0.1.17->langchain-experimental) (3.9.5)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain<0.2.0,>=0.1.17->langchain-experimental) (4.0.3)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain<0.2.0,>=0.1.17->langchain-experimental)\n",
      "  Downloading dataclasses_json-0.6.5-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain<0.2.0,>=0.1.17->langchain-experimental) (1.33)\n",
      "Collecting langchain-community<0.1,>=0.0.36 (from langchain<0.2.0,>=0.1.17->langchain-experimental)\n",
      "  Downloading langchain_community-0.0.37-py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting langchain-text-splitters<0.1,>=0.0.1 (from langchain<0.2.0,>=0.1.17->langchain-experimental)\n",
      "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /opt/conda/lib/python3.10/site-packages (from langchain<0.2.0,>=0.1.17->langchain-experimental) (0.1.55)\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain<0.2.0,>=0.1.17->langchain-experimental) (1.26.4)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain<0.2.0,>=0.1.17->langchain-experimental) (8.2.3)\n",
      "Requirement already satisfied: urllib3>=2 in /opt/conda/lib/python3.10/site-packages (from types-requests<3.0.0,>=2.31.0->langchain-google-vertexai) (2.2.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.17->langchain-experimental) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.17->langchain-experimental) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.17->langchain-experimental) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.17->langchain-experimental) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.17->langchain-experimental) (1.9.4)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.17->langchain-experimental)\n",
      "  Downloading marshmallow-3.21.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.17->langchain-experimental)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai) (1.63.0)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai) (1.63.0)\n",
      "Requirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai) (1.48.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai) (4.9)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai) (2.9.0)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /opt/conda/lib/python3.10/site-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai) (0.13.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain<0.2.0,>=0.1.17->langchain-experimental) (2.4)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain<0.2.0,>=0.1.17->langchain-experimental) (3.10.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3->google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in /opt/conda/lib/python3.10/site-packages (from pydantic<3->google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai) (2.18.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3->google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage<3.0.0,>=2.14.0->langchain-google-vertexai) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage<3.0.0,>=2.14.0->langchain-google-vertexai) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage<3.0.0,>=2.14.0->langchain-google-vertexai) (2024.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain<0.2.0,>=0.1.17->langchain-experimental) (3.0.3)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai) (0.6.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil<3.0dev,>=2.7.2->google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai) (1.16.0)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.17->langchain-experimental)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Downloading langchain_experimental-0.0.58-py3-none-any.whl (199 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.4/199.4 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain-0.1.17-py3-none-any.whl (867 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m867.6/867.6 kB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dataclasses_json-0.6.5-py3-none-any.whl (28 kB)\n",
      "Downloading langchain_community-0.0.37-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m72.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
      "Downloading marshmallow-3.21.2-py3-none-any.whl (49 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Building wheels for collected packages: neo4j\n",
      "  Building wheel for neo4j (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for neo4j: filename=neo4j-5.20.0-py3-none-any.whl size=280771 sha256=b669ba71dd4573bacd31d2d1b6815e7b95a4c00c02a1582adfb092274d144f64\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/cb/12/66/764554d079caad4b9a11a02cfc0d200dd876d12935b9cf7e64\n",
      "Successfully built neo4j\n",
      "Installing collected packages: neo4j, mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain-text-splitters, langchain-community, langchain, langchain-experimental\n",
      "Successfully installed dataclasses-json-0.6.5 langchain-0.1.17 langchain-community-0.0.37 langchain-experimental-0.0.58 langchain-text-splitters-0.0.1 marshmallow-3.21.2 mypy-extensions-1.0.0 neo4j-5.20.0 typing-inspect-0.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U langchain-google-vertexai langchain-experimental neo4j"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9ccb08-3868-4a2b-9eda-6dab0e99b53e",
   "metadata": {},
   "source": [
    "**Check Version Nos of what was installed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9709e6a-f98c-4e5e-b7b1-b734db5ae1e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: langchain-core\n",
      "Version: 0.1.52\n",
      "Summary: Building applications with LLMs through composability\n",
      "Home-page: https://github.com/langchain-ai/langchain\n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: /opt/conda/lib/python3.10/site-packages\n",
      "Requires: jsonpatch, langsmith, packaging, pydantic, PyYAML, tenacity\n",
      "Required-by: langchain, langchain-community, langchain-experimental, langchain-google-vertexai, langchain-text-splitters\n",
      "---\n",
      "Name: langchain-google-vertexai\n",
      "Version: 1.0.3\n",
      "Summary: An integration package connecting Google VertexAI and LangChain\n",
      "Home-page: https://github.com/langchain-ai/langchain-google\n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: /opt/conda/lib/python3.10/site-packages\n",
      "Requires: google-cloud-aiplatform, google-cloud-storage, langchain-core, types-protobuf, types-requests\n",
      "Required-by: \n",
      "---\n",
      "Name: langchain-experimental\n",
      "Version: 0.0.58\n",
      "Summary: Building applications with LLMs through composability\n",
      "Home-page: https://github.com/langchain-ai/langchain\n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: /opt/conda/lib/python3.10/site-packages\n",
      "Requires: langchain, langchain-core\n",
      "Required-by: \n",
      "---\n",
      "Name: neo4j\n",
      "Version: 5.20.0\n",
      "Summary: Neo4j Bolt driver for Python\n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: \"Neo4j, Inc.\" <drivers@neo4j.com>\n",
      "License: Apache License, Version 2.0\n",
      "Location: /opt/conda/lib/python3.10/site-packages\n",
      "Requires: pytz\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show langchain-core langchain-google-vertexai langchain-experimental neo4j"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3475874d-7cdc-4e51-8a0c-50421f4a3d70",
   "metadata": {},
   "source": [
    "**Check Jupyter Version No**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "332bfcdc-8d2c-410d-8473-c4cb65ad3d4a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Jupyter core packages...\n",
      "IPython          : 8.21.0\n",
      "ipykernel        : 6.29.4\n",
      "ipywidgets       : 8.1.2\n",
      "jupyter_client   : 7.4.9\n",
      "jupyter_core     : 5.7.2\n",
      "jupyter_server   : 1.24.0\n",
      "jupyterlab       : 3.4.8\n",
      "nbclient         : 0.10.0\n",
      "nbconvert        : 7.16.4\n",
      "nbformat         : 5.10.4\n",
      "notebook         : 6.5.7\n",
      "qtconsole        : not installed\n",
      "traitlets        : 5.14.3\n"
     ]
    }
   ],
   "source": [
    "!jupyter --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4cc7f4-ee89-4e5e-bd61-054c71931ffd",
   "metadata": {},
   "source": [
    "**Now for the Imports**\n",
    "\n",
    "This time we are isloating Vertex AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "642f246f-53e3-4786-ab49-8fb5bdb567f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "from langchain_google_vertexai import ChatVertexAI\n",
    "from langchain_core.documents import Document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a1967b-907b-4635-9d14-29c51de06016",
   "metadata": {},
   "source": [
    "**Connect to Google LLMs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc6314e9-e801-4103-aa9b-85c7a1befdd2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b4ec4da8045818a51abfd6681b6917066ae75764\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Set It - will require regeneration\n",
    "os.environ['GOOGLE_API_KEY'] = 'b4ec4da8045818a51abfd6681b6917066ae75764'\n",
    "# Access the environment variable later in your code\n",
    "api_key = os.environ['GOOGLE_API_KEY']\n",
    "print(api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a2b08b-8722-41ae-a5aa-4dda5af5f7ad",
   "metadata": {},
   "source": [
    "**Create The LLMs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5ecd7658-ec29-474c-b89e-9a59d43015f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<vertexai.generative_models.GenerativeModel object at 0x7fc9d228b0a0> model_name='gemini-pro' client_preview=<vertexai.generative_models.GenerativeModel object at 0x7fc9d21e1930>\n",
      "client=<vertexai.language_models.ChatModel object at 0x7fc9d1efa110> client_preview=<vertexai.preview.language_models._PreviewChatModel object at 0x7fc9d21e3790>\n"
     ]
    }
   ],
   "source": [
    "geminiOnVertex = ChatVertexAI(model=\"gemini-pro\")\n",
    "print(geminiOnVertex)\n",
    "bisonOnVertex = ChatVertexAI()\n",
    "print(bisonOnVertex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7dba7c3-8534-496f-a4bc-bf086c546815",
   "metadata": {},
   "source": [
    "**Check Model Properties**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "695f63e0-8c42-49bd-adf0-c01df7b8d31f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: chat-bison\n",
      "examples: \n",
      "None\n",
      "tuned_model_name: \n",
      "None\n",
      "convert_system_message_to_human: \n",
      "False\n",
      "temperature: \n",
      "None\n",
      "max_output_tokens: \n",
      "None\n",
      "top_p: \n",
      "None\n",
      "top_k: \n",
      "None\n",
      "credentials: \n",
      "None\n",
      "n: \n",
      "1\n",
      "streaming: \n",
      "False\n",
      "safety_settings: \n",
      "None\n",
      "api_transport: \n",
      "None\n",
      "api_endpoint: \n",
      "None\n",
      "properties\n",
      "_llm_type\n",
      "vertexai\n",
      "is_codey_model\n",
      "False\n",
      "_is_gemini_model\n",
      "False\n",
      "_identifying_params\n",
      "{'model_name': 'chat-bison', 'temperature': 0.0, 'max_output_tokens': 128, 'candidate_count': 1, 'top_k': 40, 'top_p': 0.95}\n",
      "_default_params\n",
      "{'temperature': 0.0, 'max_output_tokens': 128, 'candidate_count': 1, 'top_k': 40, 'top_p': 0.95}\n",
      "_user_agent\n",
      "langchain-google-vertexai/1.0.3-ChatVertexAI_chat-bison\n"
     ]
    }
   ],
   "source": [
    "## Vertex ATI Model Diagnostic Dump\n",
    "llm = bisonOnVertex\n",
    "print('name: ' + llm.model_name)\n",
    "print('examples: ') \n",
    "print(llm.examples)\n",
    "print('tuned_model_name: ')\n",
    "print(llm.tuned_model_name)\n",
    "print('convert_system_message_to_human: ')\n",
    "print(llm.convert_system_message_to_human)\n",
    "print('temperature: ')\n",
    "print(llm.temperature)\n",
    "print('max_output_tokens: ' )\n",
    "print(llm.max_output_tokens)\n",
    "print('top_p: ')\n",
    "print(llm.top_p)\n",
    "print('top_k: ')\n",
    "print(llm.top_k)\n",
    "print('credentials: ')\n",
    "print(llm.credentials)\n",
    "print('n: ')\n",
    "print(llm.n)\n",
    "print('streaming: ')\n",
    "print(llm.streaming)\n",
    "print('safety_settings: ')\n",
    "print(llm.safety_settings)\n",
    "print('api_transport: ')\n",
    "print(llm.api_transport)\n",
    "print('api_endpoint: ')\n",
    "print(llm.api_endpoint)\n",
    "\n",
    "print('properties') \n",
    "print('_llm_type') \n",
    "print(llm._llm_type)\n",
    "print('is_codey_model') \n",
    "print(llm.is_codey_model)\n",
    "print('_is_gemini_model') \n",
    "print(llm._is_gemini_model)\n",
    "print('_identifying_params') \n",
    "print(llm._identifying_params)\n",
    "print('_default_params') \n",
    "print(llm._default_params)\n",
    "print('_user_agent') \n",
    "print(llm._user_agent)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193d9703-1fde-4a23-8f8a-e139e9c4737f",
   "metadata": {},
   "source": [
    "**Construct Graph Transformer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4da6f4bb-d922-4774-86be-aeb5a3cb289b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<langchain_experimental.graph_transformers.llm.LLMGraphTransformer object at 0x7fc9d1eb7a30>\n",
      "<langchain_experimental.graph_transformers.llm.LLMGraphTransformer object at 0x7fc9d1eb52a0>\n"
     ]
    }
   ],
   "source": [
    "llm_transformer = LLMGraphTransformer(llm=geminiOnVertex)\n",
    "print(llm_transformer)\n",
    "llm_transformerb = LLMGraphTransformer(llm=bisonOnVertex)\n",
    "print(llm_transformerb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c9df06eb-6527-44fe-8e8d-6d6c0fb394cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "allowed_nodes: \n",
      "[]\n",
      "allowed_relationships: \n",
      "[]\n",
      "strict_mode: \n",
      "True\n"
     ]
    }
   ],
   "source": [
    "llm_xfrm = llm_transformerb\n",
    "#print('llm: ') \n",
    "#print(llm_xfrm.super.llm.model_name)\n",
    "print('allowed_nodes: ') \n",
    "print(llm_xfrm.allowed_nodes)\n",
    "print('allowed_relationships: ') \n",
    "print(llm_xfrm.allowed_relationships)\n",
    "#print('prompt: ') \n",
    "#print(llm_xfrm.prompt)\n",
    "print('strict_mode: ') \n",
    "print(llm_xfrm.strict_mode)\n",
    "#print('node_properties: ') \n",
    "#print(llm_xfrm.node_properties)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b46647-b939-400e-b569-30f93fe24c45",
   "metadata": {},
   "source": [
    "**Easy Test Case**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "52a0456c-cf46-48d4-aa5c-b2d97a6933fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "text = \"\"\"\n",
    "Current Professional Machine Learning Engineer Certification exam guide\n",
    "A Professional Machine Learning Engineer builds, evaluates, productionizes, and optimizes ML models by using Google Cloud technologies and knowledge of proven models and techniques. The ML Engineer handles large, complex datasets and creates repeatable, reusable code. The ML Engineer considers responsible AI and fairness throughout the ML model development process, and collaborates closely with other job roles to ensure long-term success of ML-based applications. The ML Engineer has strong programming skills and experience with data platforms and distributed data processing tools. The ML Engineer is proficient in the areas of model architecture, data and ML pipeline creation, and metrics interpretation. The ML Engineer is familiar with foundational concepts of MLOps, application development, infrastructure management, data engineering, and data governance. The ML Engineer makes ML accessible and enables teams across the organization. By training, retraining, deploying, scheduling, monitoring, and improving models, the ML Engineer designs and creates scalable, performant solutions.\n",
    "Note: The exam does not directly assess coding skill. If you have a minimum proficiency in Python and Cloud SQL, you should be able to interpret any questions with code snippets.\n",
    "Register now\n",
    "The Professional Machine Learning Engineer exam does not cover generative AI, as the tools used to develop generative AI-based solutions are evolving quickly. If you are interested in generative AI, please refer to the Introduction to Generative AI Learning Path (all audiences) or the Generative AI for Developers Learning Path (technical audience). If you are a partner, please refer to the Gen AI partner courses: Introduction to Generative AI Learning Path, Generative AI for ML Engineers, and Generative AI for Developers.\n",
    "Section 1: Architecting low-code ML solutions (~12% of the exam)\n",
    "1.1 Developing ML models by using BigQuery ML. Considerations include:\n",
    "Building the appropriate BigQuery ML model (e.g., linear and binary classification, regression, time-series, matrix factorization, boosted trees, autoencoders) based on the business problem\n",
    "Feature engineering or selection by using BigQuery ML\n",
    "Generating predictions by using BigQuery ML\n",
    "1.2 Building AI solutions by using ML APIs. Considerations include:\n",
    "Building applications by using ML APIs (e.g., Cloud Vision API, Natural Language API, Cloud Speech API, Translation)\n",
    "Building applications by using industry-specific APIs (e.g., Document AI API, Retail API)\n",
    "1.3 Training models by using AutoML. Considerations include:\n",
    "Preparing data for AutoML (e.g., feature selection, data labeling, Tabular Workflows on AutoML)\n",
    "Using available data (e.g., tabular, text, speech, images, videos) to train custom models\n",
    "Using AutoML for tabular data\n",
    "Creating forecasting models using AutoML\n",
    "Configuring and debugging trained models\n",
    "Section 2: Collaborating within and across teams to manage data and models (~16% of the exam)\n",
    "2.1 Exploring and preprocessing organization-wide data (e.g., Cloud Storage, BigQuery, Spanner, Cloud SQL, Apache Spark, Apache Hadoop). Considerations include:\n",
    "Organizing different types of data (e.g., tabular, text, speech, images, videos) for efficient training\n",
    "Managing datasets in Vertex AI\n",
    "Data preprocessing (e.g., Dataflow, TensorFlow Extended [TFX], BigQuery)\n",
    "Creating and consolidating features in Vertex AI Feature Store\n",
    "Privacy implications of data usage and/or collection (e.g., handling sensitive data such as personally identifiable information [PII] and protected health information [PHI])\n",
    "2.2 Model prototyping using Jupyter notebooks. Considerations include:\n",
    "Choosing the appropriate Jupyter backend on Google Cloud (e.g., Vertex AI Workbench, notebooks on Dataproc)\n",
    "Applying security best practices in Vertex AI Workbench\n",
    "Using Spark kernels\n",
    "Integration with code source repositories\n",
    "Developing models in Vertex AI Workbench by using common frameworks (e.g., TensorFlow, PyTorch, sklearn, Spark, JAX)\n",
    "2.3 Tracking and running ML experiments. Considerations include:\n",
    "Choosing the appropriate Google Cloud environment for development and experimentation (e.g., Vertex AI Experiments, Kubeflow Pipelines, Vertex AI TensorBoard with TensorFlow and PyTorch) given the framework\n",
    "Section 3: Scaling prototypes into ML models (~18% of the exam)\n",
    "3.1 Building models. Considerations include:\n",
    "Choosing ML framework and model architecture\n",
    "Modeling techniques given interpretability requirements\n",
    "3.2 Training models. Considerations include:\n",
    "Organizing training data (e.g., tabular, text, speech, images, videos) on Google Cloud (e.g., Cloud Storage, BigQuery)\n",
    "Ingestion of various file types (e.g., CSV, JSON, images, Hadoop, databases) into training\n",
    "Training using different SDKs (e.g., Vertex AI custom training, Kubeflow on Google Kubernetes Engine, AutoML, tabular workflows)\n",
    "Using distributed training to organize reliable pipelines\n",
    "Hyperparameter tuning\n",
    "Troubleshooting ML model training failures\n",
    "3.3 Choosing appropriate hardware for training. Considerations include:\n",
    "Evaluation of compute and accelerator options (e.g., CPU, GPU, TPU, edge devices)\n",
    "Distributed training with TPUs and GPUs (e.g., Reduction Server on Vertex AI, Horovod)\n",
    "Section 4: Serving and scaling models (~19% of the exam)\n",
    "4.1 Serving models. Considerations include:\n",
    "Batch and online inference (e.g., Vertex AI, Dataflow, BigQuery ML, Dataproc)\n",
    "Using different frameworks (e.g., PyTorch, XGBoost) to serve models\n",
    "Organizing a model registry\n",
    "A/B testing different versions of a model\n",
    "4.2 Scaling online model serving. Considerations include:\n",
    "Vertex AI Feature Store\n",
    "Vertex AI public and private endpoints\n",
    "Choosing appropriate hardware (e.g., CPU, GPU, TPU, edge)\n",
    "Scaling the serving backend based on the throughput (e.g., Vertex AI Prediction, containerized serving)\n",
    "Tuning ML models for training and serving in production (e.g., simplification techniques, optimizing the ML solution for increased performance, latency, memory, throughput)\n",
    "Section 5: Automating and orchestrating ML pipelines (~21% of the exam)\n",
    "5.1 Developing end-to-end ML pipelines. Considerations include:\n",
    "Data and model validation\n",
    "Ensuring consistent data pre-processing between training and serving\n",
    "Hosting third-party pipelines on Google Cloud (e.g., MLFlow)\n",
    "Identifying components, parameters, triggers, and compute needs (e.g., Cloud Build, Cloud Run)\n",
    "Orchestration framework (e.g., Kubeflow Pipelines, Vertex AI Pipelines, Cloud Composer)\n",
    "Hybrid or multicloud strategies\n",
    "System design with TFX components or Kubeflow DSL (e.g., Dataflow)\n",
    "5.2 Automating model retraining. Considerations include:\n",
    "Determining an appropriate retraining policy\n",
    "Continuous integration and continuous delivery (CI/CD) model deployment (e.g., Cloud Build, Jenkins)\n",
    "5.3 Tracking and auditing metadata. Considerations include: \n",
    "Tracking and comparing model artifacts and versions (e.g., Vertex AI Experiments, Vertex ML Metadata)\n",
    "Hooking into model and dataset versioning\n",
    "Model and data lineage\n",
    "Section 6: Monitoring ML solutions (~14% of the exam)\n",
    "6.1 Identifying risks to ML solutions. Considerations include:\n",
    "Building secure ML systems (e.g., protecting against unintentional exploitation of data or models, hacking)\n",
    "Aligning with Google’s Responsible AI practices (e.g., biases)\n",
    "Assessing ML solution readiness (e.g., data bias, fairness)\n",
    "Model explainability on Vertex AI (e.g., Vertex AI Prediction)\n",
    "6.2 Monitoring, testing, and troubleshooting ML solutions. Considerations include:\n",
    "Establishing continuous evaluation metrics (e.g., Vertex AI Model Monitoring, Explainable AI)\n",
    "Monitoring for training-serving skew\n",
    "Monitoring for feature attribution drift\n",
    "Monitoring model performance against baselines, simpler models, and across the time dimension\n",
    "Common training and serving errors\n",
    "\"\"\"\n",
    "documents1 = [Document(page_content=text)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5db59a-f095-4301-9294-1c4e921be614",
   "metadata": {},
   "source": [
    "**Use Bison**\n",
    "\n",
    "Fails with a unexpected tools message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fa5c2a8f-0e7c-4b5c-9e36-7436271d976e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#graph_documentsb = llm_transformerb.convert_to_graph_documents(documents1)\n",
    "#print(f\"Nodes:{graph_documentsb[0].nodes}\")\n",
    "#print(f\"Relationships:{graph_documentsb[0].relationships}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "477c8d12-057c-40ad-ba53-e6f4bd90db56",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_vertexai.chat_models._completion_with_retry.<locals>._completion_with_retry_inner in 4.0 seconds as it raised InternalServerError: 500 Internal error occurred. Please contact support..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes:[Node(id='Exam Guide', type='Document'), Node(id='Machine Learning Engineer', type='Job role'), Node(id='Google Cloud', type='Technology'), Node(id='Bigquery Ml', type='Service'), Node(id='Automl', type='Service'), Node(id='Vertex Ai', type='Service'), Node(id='Jupyter Notebook', type='Tool'), Node(id='Dataflow', type='Service'), Node(id='Tensorflow', type='Framework'), Node(id='Pytorch', type='Framework'), Node(id='Scikit-Learn', type='Framework'), Node(id='Kubeflow', type='Framework'), Node(id='Cloud Storage', type='Service'), Node(id='Bigquery', type='Service'), Node(id='Cloud Sql', type='Database'), Node(id='Cloud Vision Api', type='Service'), Node(id='Natural Language Api', type='Service'), Node(id='Cloud Speech Api', type='Service'), Node(id='Translation Api', type='Service'), Node(id='Document Ai Api', type='Service'), Node(id='Retail Api', type='Service'), Node(id='Vertex Ai Workbench', type='Service'), Node(id='Vertex Ai Experiments', type='Service'), Node(id='Vertex Ai Tensorboard', type='Tool'), Node(id='Tpus', type='Hardware'), Node(id='Gpus', type='Hardware'), Node(id='Vertex Ai Feature Store', type='Service'), Node(id='Cloud Build', type='Service'), Node(id='Cloud Run', type='Service'), Node(id='Vertex Ai Pipelines', type='Service'), Node(id='Cloud Composer', type='Service'), Node(id='Tfx', type='Framework'), Node(id='Kubeflow Dsl', type='Framework'), Node(id='Vertex Ai Model Monitoring', type='Service'), Node(id='Explainable Ai', type='Service')]\n",
      "Relationships:[Relationship(source=Node(id='Exam Guide', type='Document'), target=Node(id='Machine Learning Engineer', type='Job role'), type='GUIDE_FOR'), Relationship(source=Node(id='Job Role', type='Job role'), target=Node(id='Google Cloud', type='Technology'), type='USES'), Relationship(source=Node(id='Google Cloud', type='Technology'), target=Node(id='Bigquery Ml', type='Service'), type='PROVIDES'), Relationship(source=Node(id='Google Cloud', type='Technology'), target=Node(id='Automl', type='Service'), type='PROVIDES'), Relationship(source=Node(id='Google Cloud', type='Technology'), target=Node(id='Vertex Ai', type='Service'), type='PROVIDES'), Relationship(source=Node(id='Vertex Ai', type='Service'), target=Node(id='Bigquery Ml', type='Service'), type='INTEGRATES_WITH'), Relationship(source=Node(id='Vertex Ai', type='Service'), target=Node(id='Automl', type='Service'), type='INTEGRATES_WITH'), Relationship(source=Node(id='Vertex Ai', type='Service'), target=Node(id='Jupyter Notebook', type='Tool'), type='PROVIDES_ACCESS_TO'), Relationship(source=Node(id='Vertex Ai', type='Service'), target=Node(id='Dataflow', type='Service'), type='INTEGRATES_WITH'), Relationship(source=Node(id='Vertex Ai', type='Service'), target=Node(id='Tensorflow', type='Framework'), type='INTEGRATES_WITH'), Relationship(source=Node(id='Vertex Ai', type='Service'), target=Node(id='Pytorch', type='Framework'), type='INTEGRATES_WITH'), Relationship(source=Node(id='Vertex Ai', type='Service'), target=Node(id='Scikit-Learn', type='Framework'), type='INTEGRATES_WITH'), Relationship(source=Node(id='Vertex Ai', type='Service'), target=Node(id='Kubeflow', type='Framework'), type='INTEGRATES_WITH'), Relationship(source=Node(id='Google Cloud', type='Technology'), target=Node(id='Cloud Storage', type='Service'), type='PROVIDES'), Relationship(source=Node(id='Google Cloud', type='Technology'), target=Node(id='Bigquery', type='Service'), type='PROVIDES'), Relationship(source=Node(id='Google Cloud', type='Technology'), target=Node(id='Cloud Sql', type='Database'), type='PROVIDES'), Relationship(source=Node(id='Google Cloud', type='Technology'), target=Node(id='Cloud Vision Api', type='Service'), type='PROVIDES'), Relationship(source=Node(id='Google Cloud', type='Technology'), target=Node(id='Natural Language Api', type='Service'), type='PROVIDES'), Relationship(source=Node(id='Google Cloud', type='Technology'), target=Node(id='Cloud Speech Api', type='Service'), type='PROVIDES'), Relationship(source=Node(id='Google Cloud', type='Technology'), target=Node(id='Translation Api', type='Service'), type='PROVIDES'), Relationship(source=Node(id='Google Cloud', type='Technology'), target=Node(id='Document Ai Api', type='Service'), type='PROVIDES'), Relationship(source=Node(id='Google Cloud', type='Technology'), target=Node(id='Retail Api', type='Service'), type='PROVIDES'), Relationship(source=Node(id='Vertex Ai', type='Service'), target=Node(id='Vertex Ai Workbench', type='Service'), type='PROVIDES_ACCESS_TO'), Relationship(source=Node(id='Vertex Ai', type='Service'), target=Node(id='Vertex Ai Experiments', type='Service'), type='PROVIDES_ACCESS_TO'), Relationship(source=Node(id='Vertex Ai', type='Service'), target=Node(id='Vertex Ai Tensorboard', type='Tool'), type='INTEGRATES_WITH'), Relationship(source=Node(id='Vertex Ai', type='Service'), target=Node(id='Tpus', type='Hardware'), type='PROVIDES_ACCESS_TO'), Relationship(source=Node(id='Vertex Ai', type='Service'), target=Node(id='Gpus', type='Hardware'), type='PROVIDES_ACCESS_TO'), Relationship(source=Node(id='Vertex Ai', type='Service'), target=Node(id='Vertex Ai Feature Store', type='Service'), type='INTEGRATES_WITH'), Relationship(source=Node(id='Google Cloud', type='Technology'), target=Node(id='Cloud Build', type='Service'), type='PROVIDES'), Relationship(source=Node(id='Google Cloud', type='Technology'), target=Node(id='Cloud Run', type='Service'), type='PROVIDES'), Relationship(source=Node(id='Vertex Ai', type='Service'), target=Node(id='Vertex Ai Pipelines', type='Service'), type='PROVIDES_ACCESS_TO'), Relationship(source=Node(id='Vertex Ai', type='Service'), target=Node(id='Cloud Composer', type='Service'), type='INTEGRATES_WITH'), Relationship(source=Node(id='Vertex Ai', type='Service'), target=Node(id='Tfx', type='Framework'), type='INTEGRATES_WITH'), Relationship(source=Node(id='Vertex Ai', type='Service'), target=Node(id='Kubeflow Dsl', type='Framework'), type='INTEGRATES_WITH'), Relationship(source=Node(id='Vertex Ai', type='Service'), target=Node(id='Vertex Ai Model Monitoring', type='Service'), type='PROVIDES_ACCESS_TO'), Relationship(source=Node(id='Vertex Ai', type='Service'), target=Node(id='Explainable Ai', type='Service'), type='PROVIDES_ACCESS_TO')]\n"
     ]
    }
   ],
   "source": [
    "graph_documents = llm_transformer.convert_to_graph_documents(documents1)\n",
    "print(f\"Nodes:{graph_documents[0].nodes}\")\n",
    "print(f\"Relationships:{graph_documents[0].relationships}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7550372a-5e4c-4719-966f-58bb04d19ccd",
   "metadata": {},
   "source": [
    "**Enter Node4J**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f2e2c285-73ed-41c7-ac46-eea0d3aec3b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "\n",
    "os.environ[\"NEO4J_URI\"] = \"neo4j+s://a657168d.databases.neo4j.io\"\n",
    "os.environ[\"NEO4J_USERNAME\"] = \"neo4j\"\n",
    "os.environ[\"NEO4J_PASSWORD\"] = \"VM3A9Mz6usNT99nLs_lqQssfVK8JxeD81DnEiXlDkZU\"\n",
    "\n",
    "graph = Neo4jGraph()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48151b0d-29cd-4c1b-b572-bab3a3049f9d",
   "metadata": {},
   "source": [
    "**Add to GraphDB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3082a075-0722-49d0-98c8-e9b908b52284",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "graph.add_graph_documents(graph_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3a3d52-26bb-4b2c-aa37-1930fcb38f95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m120",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m120"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
