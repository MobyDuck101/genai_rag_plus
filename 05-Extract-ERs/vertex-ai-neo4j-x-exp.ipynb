{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8f9e3f7-ade1-4049-90e9-96d963538c5c",
   "metadata": {},
   "source": [
    "****Ingest Website to Graph DB****\n",
    "\n",
    "**Part 3** - Extract Entities & Relationships using Langchain\n",
    "\n",
    "Extract Entities and Relatonships from a body of Text using langchain.\n",
    "\n",
    "This is a GCP reworking of\n",
    "\n",
    "https://python.langchain.com/docs/use_cases/graph/constructing/#llm-graph-transformer\n",
    "\n",
    "This notebook seeks to become independant of the following packages.\n",
    "\n",
    "*langchain-experimental*\n",
    "\n",
    "*langchain-community*\n",
    "\n",
    "Instead copying the relevant classes into notebook cells.  "
   ]
  },
  {
   "cell_type": "raw",
   "id": "5fa5cee1-967c-4024-9329-7c473430ceca",
   "metadata": {},
   "source": [
    "**Minimal install for Vertex AI**\n",
    "\n",
    "This solved the instability problem by *NOT* installing OpenAI classes via the community install. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9d33f38-6324-4175-8689-d4e8f278c8ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /opt/conda/lib/python3.10/site-packages (0.1.20)\n",
      "Requirement already satisfied: langchain-google-vertexai in /opt/conda/lib/python3.10/site-packages (1.0.3)\n",
      "Requirement already satisfied: neo4j in /opt/conda/lib/python3.10/site-packages (5.20.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.0.29)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (3.9.5)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.6.6)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.38 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.0.38)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.52 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.1.52)\n",
      "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.0.1)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.1.57)\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.7.1)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: google-cloud-aiplatform<2.0.0,>=1.47.0 in /opt/conda/lib/python3.10/site-packages (from langchain-google-vertexai) (1.49.0)\n",
      "Requirement already satisfied: google-cloud-storage<3.0.0,>=2.14.0 in /opt/conda/lib/python3.10/site-packages (from langchain-google-vertexai) (2.14.0)\n",
      "Requirement already satisfied: types-protobuf<5.0.0.0,>=4.24.0.4 in /opt/conda/lib/python3.10/site-packages (from langchain-google-vertexai) (4.25.0.20240417)\n",
      "Requirement already satisfied: types-requests<3.0.0,>=2.31.0 in /opt/conda/lib/python3.10/site-packages (from langchain-google-vertexai) (2.31.0.20240406)\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.10/site-packages (from neo4j) (2024.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai) (1.34.1)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai) (2.29.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai) (1.23.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai) (3.20.3)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai) (23.2)\n",
      "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai) (3.21.0)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai) (1.12.3)\n",
      "Requirement already satisfied: shapely<3.0.0dev in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai) (2.0.4)\n",
      "Requirement already satisfied: docstring-parser<1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai) (0.16)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage<3.0.0,>=2.14.0->langchain-google-vertexai) (2.4.1)\n",
      "Requirement already satisfied: google-resumable-media>=2.6.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage<3.0.0,>=2.14.0->langchain-google-vertexai) (2.7.0)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage<3.0.0,>=2.14.0->langchain-google-vertexai) (1.5.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.2.0,>=0.1.52->langchain) (1.33)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (2.18.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai) (1.63.0)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai) (1.63.0)\n",
      "Requirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai) (1.48.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai) (4.9)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai) (2.9.0)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /opt/conda/lib/python3.10/site-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai) (0.13.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.52->langchain) (2.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai) (0.6.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil<3.0dev,>=2.7.2->google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.47.0->langchain-google-vertexai) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U langchain langchain-google-vertexai neo4j"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9ccb08-3868-4a2b-9eda-6dab0e99b53e",
   "metadata": {},
   "source": [
    "**Check Version Nos of what was installed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9709e6a-f98c-4e5e-b7b1-b734db5ae1e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Package(s) not found: langchain-experimental\u001b[0m\u001b[33m\n",
      "\u001b[0mName: langchain\n",
      "Version: 0.1.20\n",
      "Summary: Building applications with LLMs through composability\n",
      "Home-page: https://github.com/langchain-ai/langchain\n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: /opt/conda/lib/python3.10/site-packages\n",
      "Requires: aiohttp, async-timeout, dataclasses-json, langchain-community, langchain-core, langchain-text-splitters, langsmith, numpy, pydantic, PyYAML, requests, SQLAlchemy, tenacity\n",
      "Required-by: \n",
      "---\n",
      "Name: langchain-core\n",
      "Version: 0.1.52\n",
      "Summary: Building applications with LLMs through composability\n",
      "Home-page: https://github.com/langchain-ai/langchain\n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: /opt/conda/lib/python3.10/site-packages\n",
      "Requires: jsonpatch, langsmith, packaging, pydantic, PyYAML, tenacity\n",
      "Required-by: langchain, langchain-community, langchain-google-vertexai, langchain-text-splitters\n",
      "---\n",
      "Name: langchain-google-vertexai\n",
      "Version: 1.0.3\n",
      "Summary: An integration package connecting Google VertexAI and LangChain\n",
      "Home-page: https://github.com/langchain-ai/langchain-google\n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: /opt/conda/lib/python3.10/site-packages\n",
      "Requires: google-cloud-aiplatform, google-cloud-storage, langchain-core, types-protobuf, types-requests\n",
      "Required-by: \n",
      "---\n",
      "Name: langchain-community\n",
      "Version: 0.0.38\n",
      "Summary: Community contributed LangChain integrations.\n",
      "Home-page: https://github.com/langchain-ai/langchain\n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: /opt/conda/lib/python3.10/site-packages\n",
      "Requires: aiohttp, dataclasses-json, langchain-core, langsmith, numpy, PyYAML, requests, SQLAlchemy, tenacity\n",
      "Required-by: langchain\n",
      "---\n",
      "Name: neo4j\n",
      "Version: 5.20.0\n",
      "Summary: Neo4j Bolt driver for Python\n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: \"Neo4j, Inc.\" <drivers@neo4j.com>\n",
      "License: Apache License, Version 2.0\n",
      "Location: /opt/conda/lib/python3.10/site-packages\n",
      "Requires: pytz\n",
      "Required-by: \n",
      "---\n",
      "Name: google-cloud-aiplatform\n",
      "Version: 1.49.0\n",
      "Summary: Vertex AI API client library\n",
      "Home-page: https://github.com/googleapis/python-aiplatform\n",
      "Author: Google LLC\n",
      "Author-email: googleapis-packages@google.com\n",
      "License: Apache 2.0\n",
      "Location: /opt/conda/lib/python3.10/site-packages\n",
      "Requires: docstring-parser, google-api-core, google-auth, google-cloud-bigquery, google-cloud-resource-manager, google-cloud-storage, packaging, proto-plus, protobuf, pydantic, shapely\n",
      "Required-by: langchain-google-vertexai\n"
     ]
    }
   ],
   "source": [
    "!pip show langchain langchain-core langchain-google-vertexai langchain-experimental langchain-community neo4j google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3475874d-7cdc-4e51-8a0c-50421f4a3d70",
   "metadata": {},
   "source": [
    "**Check Jupyter Version No**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "332bfcdc-8d2c-410d-8473-c4cb65ad3d4a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Jupyter core packages...\n",
      "IPython          : 8.21.0\n",
      "ipykernel        : 6.29.4\n",
      "ipywidgets       : 8.1.2\n",
      "jupyter_client   : 7.4.9\n",
      "jupyter_core     : 5.7.2\n",
      "jupyter_server   : 1.24.0\n",
      "jupyterlab       : 3.4.8\n",
      "nbclient         : 0.10.0\n",
      "nbconvert        : 7.16.4\n",
      "nbformat         : 5.10.4\n",
      "notebook         : 6.5.7\n",
      "qtconsole        : not installed\n",
      "traitlets        : 5.14.3\n"
     ]
    }
   ],
   "source": [
    "!jupyter --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38b224b-03e5-4068-a564-2fa642cab286",
   "metadata": {},
   "source": [
    "**Check Python Version/Path** - *Expect 3.10.14*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dea00fad-2121-4150-a520-60d8ca5c8f1e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.10.14 | packaged by conda-forge | (main, Mar 20 2024, 12:45:18) [GCC 12.3.0]\n",
      "3.10.14\n",
      "['/opt/conda/lib/python310.zip', '/opt/conda/lib/python3.10', '/opt/conda/lib/python3.10/lib-dynload', '', '/opt/conda/lib/python3.10/site-packages']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import platform\n",
    "print(sys.version)\n",
    "print(platform.python_version())\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c5da4b-d690-4a21-8990-5a462abd28ae",
   "metadata": {},
   "source": [
    "***OpenAI Detox***\n",
    "\n",
    "Copy Required Code from langchain-experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d8df8cb-3671-46c2-b5b1-5e1f945b9033",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import json\n",
    "from typing import Any, Dict, List, Optional, Sequence, Tuple, Type, Union, cast\n",
    "\n",
    "from langchain_community.graphs.graph_document import GraphDocument, Node, Relationship\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.language_models import BaseLanguageModel\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    PromptTemplate,\n",
    ")\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field, create_model\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"text\": (\n",
    "            \"Adam is a software engineer in Microsoft since 2009, \"\n",
    "            \"and last year he got an award as the Best Talent\"\n",
    "        ),\n",
    "        \"head\": \"Adam\",\n",
    "        \"head_type\": \"Person\",\n",
    "        \"relation\": \"WORKS_FOR\",\n",
    "        \"tail\": \"Microsoft\",\n",
    "        \"tail_type\": \"Company\",\n",
    "    },\n",
    "    {\n",
    "        \"text\": (\n",
    "            \"Adam is a software engineer in Microsoft since 2009, \"\n",
    "            \"and last year he got an award as the Best Talent\"\n",
    "        ),\n",
    "        \"head\": \"Adam\",\n",
    "        \"head_type\": \"Person\",\n",
    "        \"relation\": \"HAS_AWARD\",\n",
    "        \"tail\": \"Best Talent\",\n",
    "        \"tail_type\": \"Award\",\n",
    "    },\n",
    "    {\n",
    "        \"text\": (\n",
    "            \"Microsoft is a tech company that provide \"\n",
    "            \"several products such as Microsoft Word\"\n",
    "        ),\n",
    "        \"head\": \"Microsoft Word\",\n",
    "        \"head_type\": \"Product\",\n",
    "        \"relation\": \"PRODUCED_BY\",\n",
    "        \"tail\": \"Microsoft\",\n",
    "        \"tail_type\": \"Company\",\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Microsoft Word is a lightweight app that accessible offline\",\n",
    "        \"head\": \"Microsoft Word\",\n",
    "        \"head_type\": \"Product\",\n",
    "        \"relation\": \"HAS_CHARACTERISTIC\",\n",
    "        \"tail\": \"lightweight app\",\n",
    "        \"tail_type\": \"Characteristic\",\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Microsoft Word is a lightweight app that accessible offline\",\n",
    "        \"head\": \"Microsoft Word\",\n",
    "        \"head_type\": \"Product\",\n",
    "        \"relation\": \"HAS_CHARACTERISTIC\",\n",
    "        \"tail\": \"accessible offline\",\n",
    "        \"tail_type\": \"Characteristic\",\n",
    "    },\n",
    "]\n",
    "\n",
    "system_prompt = (\n",
    "    \"# Knowledge Graph Instructions for GPT-4\\n\"\n",
    "    \"## 1. Overview\\n\"\n",
    "    \"You are a top-tier algorithm designed for extracting information in structured \"\n",
    "    \"formats to build a knowledge graph.\\n\"\n",
    "    \"Try to capture as much information from the text as possible without \"\n",
    "    \"sacrifing accuracy. Do not add any information that is not explicitly \"\n",
    "    \"mentioned in the text\\n\"\n",
    "    \"- **Nodes** represent entities and concepts.\\n\"\n",
    "    \"- The aim is to achieve simplicity and clarity in the knowledge graph, making it\\n\"\n",
    "    \"accessible for a vast audience.\\n\"\n",
    "    \"## 2. Labeling Nodes\\n\"\n",
    "    \"- **Consistency**: Ensure you use available types for node labels.\\n\"\n",
    "    \"Ensure you use basic or elementary types for node labels.\\n\"\n",
    "    \"- For example, when you identify an entity representing a person, \"\n",
    "    \"always label it as **'person'**. Avoid using more specific terms \"\n",
    "    \"like 'mathematician' or 'scientist'\"\n",
    "    \"  - **Node IDs**: Never utilize integers as node IDs. Node IDs should be \"\n",
    "    \"names or human-readable identifiers found in the text.\\n\"\n",
    "    \"- **Relationships** represent connections between entities or concepts.\\n\"\n",
    "    \"Ensure consistency and generality in relationship types when constructing \"\n",
    "    \"knowledge graphs. Instead of using specific and momentary types \"\n",
    "    \"such as 'BECAME_PROFESSOR', use more general and timeless relationship types \"\n",
    "    \"like 'PROFESSOR'. Make sure to use general and timeless relationship types!\\n\"\n",
    "    \"## 3. Coreference Resolution\\n\"\n",
    "    \"- **Maintain Entity Consistency**: When extracting entities, it's vital to \"\n",
    "    \"ensure consistency.\\n\"\n",
    "    'If an entity, such as \"John Doe\", is mentioned multiple times in the text '\n",
    "    'but is referred to by different names or pronouns (e.g., \"Joe\", \"he\"),'\n",
    "    \"always use the most complete identifier for that entity throughout the \"\n",
    "    'knowledge graph. In this example, use \"John Doe\" as the entity ID.\\n'\n",
    "    \"Remember, the knowledge graph should be coherent and easily understandable, \"\n",
    "    \"so maintaining consistency in entity references is crucial.\\n\"\n",
    "    \"## 4. Strict Compliance\\n\"\n",
    "    \"Adhere to the rules strictly. Non-compliance will result in termination.\"\n",
    ")\n",
    "\n",
    "default_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            system_prompt,\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            (\n",
    "                \"Tip: Make sure to answer in the correct format and do \"\n",
    "                \"not include any explanations. \"\n",
    "                \"Use the given format to extract information from the \"\n",
    "                \"following input: {input}\"\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def _get_additional_info(input_type: str) -> str:\n",
    "    # Check if the input_type is one of the allowed values\n",
    "    if input_type not in [\"node\", \"relationship\", \"property\"]:\n",
    "        raise ValueError(\"input_type must be 'node', 'relationship', or 'property'\")\n",
    "\n",
    "    # Perform actions based on the input_type\n",
    "    if input_type == \"node\":\n",
    "        return (\n",
    "            \"Ensure you use basic or elementary types for node labels.\\n\"\n",
    "            \"For example, when you identify an entity representing a person, \"\n",
    "            \"always label it as **'Person'**. Avoid using more specific terms \"\n",
    "            \"like 'Mathematician' or 'Scientist'\"\n",
    "        )\n",
    "    elif input_type == \"relationship\":\n",
    "        return (\n",
    "            \"Instead of using specific and momentary types such as \"\n",
    "            \"'BECAME_PROFESSOR', use more general and timeless relationship types like \"\n",
    "            \"'PROFESSOR'. However, do not sacrifice any accuracy for generality\"\n",
    "        )\n",
    "    elif input_type == \"property\":\n",
    "        return \"\"\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def optional_enum_field(\n",
    "    enum_values: Optional[List[str]] = None,\n",
    "    description: str = \"\",\n",
    "    input_type: str = \"node\",\n",
    "    **field_kwargs: Any,\n",
    ") -> Any:\n",
    "    \"\"\"Utility function to conditionally create a field with an enum constraint.\"\"\"\n",
    "    if enum_values:\n",
    "        return Field(\n",
    "            ...,\n",
    "            enum=enum_values,\n",
    "            description=f\"{description}. Available options are {enum_values}\",\n",
    "            **field_kwargs,\n",
    "        )\n",
    "    else:\n",
    "        additional_info = _get_additional_info(input_type)\n",
    "        return Field(..., description=description + additional_info, **field_kwargs)\n",
    "\n",
    "\n",
    "class _Graph(BaseModel):\n",
    "    nodes: Optional[List]\n",
    "    relationships: Optional[List]\n",
    "\n",
    "\n",
    "class UnstructuredRelation(BaseModel):\n",
    "    head: str = Field(\n",
    "        description=(\n",
    "            \"extracted head entity like Microsoft, Apple, John. \"\n",
    "            \"Must use human-readable unique identifier.\"\n",
    "        )\n",
    "    )\n",
    "    head_type: str = Field(\n",
    "        description=\"type of the extracted head entity like Person, Company, etc\"\n",
    "    )\n",
    "    relation: str = Field(description=\"relation between the head and the tail entities\")\n",
    "    tail: str = Field(\n",
    "        description=(\n",
    "            \"extracted tail entity like Microsoft, Apple, John. \"\n",
    "            \"Must use human-readable unique identifier.\"\n",
    "        )\n",
    "    )\n",
    "    tail_type: str = Field(\n",
    "        description=\"type of the extracted tail entity like Person, Company, etc\"\n",
    "    )\n",
    "\n",
    "\n",
    "def create_unstructured_prompt(\n",
    "    node_labels: Optional[List[str]] = None, rel_types: Optional[List[str]] = None\n",
    ") -> ChatPromptTemplate:\n",
    "    node_labels_str = str(node_labels) if node_labels else \"\"\n",
    "    rel_types_str = str(rel_types) if rel_types else \"\"\n",
    "    base_string_parts = [\n",
    "        \"You are a top-tier algorithm designed for extracting information in \"\n",
    "        \"structured formats to build a knowledge graph. Your task is to identify \"\n",
    "        \"the entities and relations requested with the user prompt from a given \"\n",
    "        \"text. You must generate the output in a JSON format containing a list \"\n",
    "        'with JSON objects. Each object should have the keys: \"head\", '\n",
    "        '\"head_type\", \"relation\", \"tail\", and \"tail_type\". The \"head\" '\n",
    "        \"key must contain the text of the extracted entity with one of the types \"\n",
    "        \"from the provided list in the user prompt.\",\n",
    "        f'The \"head_type\" key must contain the type of the extracted head entity, '\n",
    "        f\"which must be one of the types from {node_labels_str}.\"\n",
    "        if node_labels\n",
    "        else \"\",\n",
    "        f'The \"relation\" key must contain the type of relation between the \"head\" '\n",
    "        f'and the \"tail\", which must be one of the relations from {rel_types_str}.'\n",
    "        if rel_types\n",
    "        else \"\",\n",
    "        f'The \"tail\" key must represent the text of an extracted entity which is '\n",
    "        f'the tail of the relation, and the \"tail_type\" key must contain the type '\n",
    "        f\"of the tail entity from {node_labels_str}.\"\n",
    "        if node_labels\n",
    "        else \"\",\n",
    "        \"Attempt to extract as many entities and relations as you can. Maintain \"\n",
    "        \"Entity Consistency: When extracting entities, it's vital to ensure \"\n",
    "        'consistency. If an entity, such as \"John Doe\", is mentioned multiple '\n",
    "        \"times in the text but is referred to by different names or pronouns \"\n",
    "        '(e.g., \"Joe\", \"he\"), always use the most complete identifier for '\n",
    "        \"that entity. The knowledge graph should be coherent and easily \"\n",
    "        \"understandable, so maintaining consistency in entity references is \"\n",
    "        \"crucial.\",\n",
    "        \"IMPORTANT NOTES:\\n- Don't add any explanation and text.\",\n",
    "    ]\n",
    "    system_prompt = \"\\n\".join(filter(None, base_string_parts))\n",
    "\n",
    "    system_message = SystemMessage(content=system_prompt)\n",
    "    parser = JsonOutputParser(pydantic_object=UnstructuredRelation)\n",
    "\n",
    "    human_prompt = PromptTemplate(\n",
    "        template=\"\"\"Based on the following example, extract entities and \n",
    "relations from the provided text.\\n\\n\n",
    "Use the following entity types, don't use other entity that is not defined below:\n",
    "# ENTITY TYPES:\n",
    "{node_labels}\n",
    "\n",
    "Use the following relation types, don't use other relation that is not defined below:\n",
    "# RELATION TYPES:\n",
    "{rel_types}\n",
    "\n",
    "Below are a number of examples of text and their extracted entities and relationships.\n",
    "{examples}\n",
    "\n",
    "For the following text, extract entities and relations as in the provided example.\n",
    "{format_instructions}\\nText: {input}\"\"\",\n",
    "        input_variables=[\"input\"],\n",
    "        partial_variables={\n",
    "            \"format_instructions\": parser.get_format_instructions(),\n",
    "            \"node_labels\": node_labels,\n",
    "            \"rel_types\": rel_types,\n",
    "            \"examples\": examples,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    human_message_prompt = HumanMessagePromptTemplate(prompt=human_prompt)\n",
    "\n",
    "    chat_prompt = ChatPromptTemplate.from_messages(\n",
    "        [system_message, human_message_prompt]\n",
    "    )\n",
    "    return chat_prompt\n",
    "\n",
    "\n",
    "def create_simple_model(\n",
    "    node_labels: Optional[List[str]] = None,\n",
    "    rel_types: Optional[List[str]] = None,\n",
    "    node_properties: Union[bool, List[str]] = False,\n",
    ") -> Type[_Graph]:\n",
    "    \"\"\"\n",
    "    Simple model allows to limit node and/or relationship types.\n",
    "    Doesn't have any node or relationship properties.\n",
    "    \"\"\"\n",
    "\n",
    "    node_fields: Dict[str, Tuple[Any, Any]] = {\n",
    "        \"id\": (\n",
    "            str,\n",
    "            Field(..., description=\"Name or human-readable unique identifier.\"),\n",
    "        ),\n",
    "        \"type\": (\n",
    "            str,\n",
    "            optional_enum_field(\n",
    "                node_labels,\n",
    "                description=\"The type or label of the node.\",\n",
    "                input_type=\"node\",\n",
    "            ),\n",
    "        ),\n",
    "    }\n",
    "    if node_properties:\n",
    "        if isinstance(node_properties, list) and \"id\" in node_properties:\n",
    "            raise ValueError(\"The node property 'id' is reserved and cannot be used.\")\n",
    "        # Map True to empty array\n",
    "        node_properties_mapped: List[str] = (\n",
    "            [] if node_properties is True else node_properties\n",
    "        )\n",
    "\n",
    "        class Property(BaseModel):\n",
    "            \"\"\"A single property consisting of key and value\"\"\"\n",
    "\n",
    "            key: str = optional_enum_field(\n",
    "                node_properties_mapped,\n",
    "                description=\"Property key.\",\n",
    "                input_type=\"property\",\n",
    "            )\n",
    "            value: str = Field(..., description=\"value\")\n",
    "\n",
    "        node_fields[\"properties\"] = (\n",
    "            Optional[List[Property]],\n",
    "            Field(None, description=\"List of node properties\"),\n",
    "        )\n",
    "    SimpleNode = create_model(\"SimpleNode\", **node_fields)  # type: ignore\n",
    "\n",
    "    class SimpleRelationship(BaseModel):\n",
    "        \"\"\"Represents a directed relationship between two nodes in a graph.\"\"\"\n",
    "\n",
    "        source_node_id: str = Field(\n",
    "            description=\"Name or human-readable unique identifier of source node\"\n",
    "        )\n",
    "        source_node_type: str = optional_enum_field(\n",
    "            node_labels,\n",
    "            description=\"The type or label of the source node.\",\n",
    "            input_type=\"node\",\n",
    "        )\n",
    "        target_node_id: str = Field(\n",
    "            description=\"Name or human-readable unique identifier of target node\"\n",
    "        )\n",
    "        target_node_type: str = optional_enum_field(\n",
    "            node_labels,\n",
    "            description=\"The type or label of the target node.\",\n",
    "            input_type=\"node\",\n",
    "        )\n",
    "        type: str = optional_enum_field(\n",
    "            rel_types,\n",
    "            description=\"The type of the relationship.\",\n",
    "            input_type=\"relationship\",\n",
    "        )\n",
    "\n",
    "    class DynamicGraph(_Graph):\n",
    "        \"\"\"Represents a graph document consisting of nodes and relationships.\"\"\"\n",
    "\n",
    "        nodes: Optional[List[SimpleNode]] = Field(description=\"List of nodes\")  # type: ignore\n",
    "        relationships: Optional[List[SimpleRelationship]] = Field(\n",
    "            description=\"List of relationships\"\n",
    "        )\n",
    "\n",
    "    return DynamicGraph\n",
    "\n",
    "\n",
    "def map_to_base_node(node: Any) -> Node:\n",
    "    \"\"\"Map the SimpleNode to the base Node.\"\"\"\n",
    "    properties = {}\n",
    "    if hasattr(node, \"properties\") and node.properties:\n",
    "        for p in node.properties:\n",
    "            properties[format_property_key(p.key)] = p.value\n",
    "    return Node(id=node.id, type=node.type, properties=properties)\n",
    "\n",
    "\n",
    "def map_to_base_relationship(rel: Any) -> Relationship:\n",
    "    \"\"\"Map the SimpleRelationship to the base Relationship.\"\"\"\n",
    "    source = Node(id=rel.source_node_id, type=rel.source_node_type)\n",
    "    target = Node(id=rel.target_node_id, type=rel.target_node_type)\n",
    "    return Relationship(source=source, target=target, type=rel.type)\n",
    "\n",
    "\n",
    "def _parse_and_clean_json(\n",
    "    argument_json: Dict[str, Any],\n",
    ") -> Tuple[List[Node], List[Relationship]]:\n",
    "    nodes = []\n",
    "    for node in argument_json[\"nodes\"]:\n",
    "        if not node.get(\"id\"):  # Id is mandatory, skip this node\n",
    "            continue\n",
    "        nodes.append(\n",
    "            Node(\n",
    "                id=node[\"id\"],\n",
    "                type=node.get(\"type\"),\n",
    "            )\n",
    "        )\n",
    "    relationships = []\n",
    "    for rel in argument_json[\"relationships\"]:\n",
    "        # Mandatory props\n",
    "        if (\n",
    "            not rel.get(\"source_node_id\")\n",
    "            or not rel.get(\"target_node_id\")\n",
    "            or not rel.get(\"type\")\n",
    "        ):\n",
    "            continue\n",
    "\n",
    "        # Node type copying if needed from node list\n",
    "        if not rel.get(\"source_node_type\"):\n",
    "            try:\n",
    "                rel[\"source_node_type\"] = [\n",
    "                    el.get(\"type\")\n",
    "                    for el in argument_json[\"nodes\"]\n",
    "                    if el[\"id\"] == rel[\"source_node_id\"]\n",
    "                ][0]\n",
    "            except IndexError:\n",
    "                rel[\"source_node_type\"] = None\n",
    "        if not rel.get(\"target_node_type\"):\n",
    "            try:\n",
    "                rel[\"target_node_type\"] = [\n",
    "                    el.get(\"type\")\n",
    "                    for el in argument_json[\"nodes\"]\n",
    "                    if el[\"id\"] == rel[\"target_node_id\"]\n",
    "                ][0]\n",
    "            except IndexError:\n",
    "                rel[\"target_node_type\"] = None\n",
    "\n",
    "        source_node = Node(\n",
    "            id=rel[\"source_node_id\"],\n",
    "            type=rel[\"source_node_type\"],\n",
    "        )\n",
    "        target_node = Node(\n",
    "            id=rel[\"target_node_id\"],\n",
    "            type=rel[\"target_node_type\"],\n",
    "        )\n",
    "        relationships.append(\n",
    "            Relationship(\n",
    "                source=source_node,\n",
    "                target=target_node,\n",
    "                type=rel[\"type\"],\n",
    "            )\n",
    "        )\n",
    "    return nodes, relationships\n",
    "\n",
    "\n",
    "def _format_nodes(nodes: List[Node]) -> List[Node]:\n",
    "    return [\n",
    "        Node(\n",
    "            id=el.id.title() if isinstance(el.id, str) else el.id,\n",
    "            type=el.type.capitalize(),\n",
    "            properties=el.properties,\n",
    "        )\n",
    "        for el in nodes\n",
    "    ]\n",
    "\n",
    "\n",
    "def _format_relationships(rels: List[Relationship]) -> List[Relationship]:\n",
    "    return [\n",
    "        Relationship(\n",
    "            source=_format_nodes([el.source])[0],\n",
    "            target=_format_nodes([el.target])[0],\n",
    "            type=el.type.replace(\" \", \"_\").upper(),\n",
    "        )\n",
    "        for el in rels\n",
    "    ]\n",
    "\n",
    "\n",
    "def format_property_key(s: str) -> str:\n",
    "    words = s.split()\n",
    "    if not words:\n",
    "        return s\n",
    "    first_word = words[0].lower()\n",
    "    capitalized_words = [word.capitalize() for word in words[1:]]\n",
    "    return \"\".join([first_word] + capitalized_words)\n",
    "\n",
    "\n",
    "def _convert_to_graph_document(\n",
    "    raw_schema: Dict[Any, Any],\n",
    ") -> Tuple[List[Node], List[Relationship]]:\n",
    "    # If there are validation errors\n",
    "    if not raw_schema[\"parsed\"]:\n",
    "        try:\n",
    "            try:  # OpenAI type response\n",
    "                argument_json = json.loads(\n",
    "                    raw_schema[\"raw\"].additional_kwargs[\"tool_calls\"][0][\"function\"][\n",
    "                        \"arguments\"\n",
    "                    ]\n",
    "                )\n",
    "            except Exception:  # Google type response\n",
    "                argument_json = json.loads(\n",
    "                    raw_schema[\"raw\"].additional_kwargs[\"function_call\"][\"arguments\"]\n",
    "                )\n",
    "\n",
    "            nodes, relationships = _parse_and_clean_json(argument_json)\n",
    "        except Exception:  # If we can't parse JSON\n",
    "            return ([], [])\n",
    "    else:  # If there are no validation errors use parsed pydantic object\n",
    "        parsed_schema: _Graph = raw_schema[\"parsed\"]\n",
    "        nodes = (\n",
    "            [map_to_base_node(node) for node in parsed_schema.nodes]\n",
    "            if parsed_schema.nodes\n",
    "            else []\n",
    "        )\n",
    "\n",
    "        relationships = (\n",
    "            [map_to_base_relationship(rel) for rel in parsed_schema.relationships]\n",
    "            if parsed_schema.relationships\n",
    "            else []\n",
    "        )\n",
    "    # Title / Capitalize\n",
    "    return _format_nodes(nodes), _format_relationships(relationships)\n",
    "\n",
    "\n",
    "class LLMGraphTransformer:\n",
    "    \"\"\"Transform documents into graph-based documents using a LLM.\n",
    "\n",
    "    It allows specifying constraints on the types of nodes and relationships to include\n",
    "    in the output graph. The class doesn't support neither extract and node or\n",
    "    relationship properties\n",
    "\n",
    "    Args:\n",
    "        llm (BaseLanguageModel): An instance of a language model supporting structured\n",
    "          output.\n",
    "        allowed_nodes (List[str], optional): Specifies which node types are\n",
    "          allowed in the graph. Defaults to an empty list, allowing all node types.\n",
    "        allowed_relationships (List[str], optional): Specifies which relationship types\n",
    "          are allowed in the graph. Defaults to an empty list, allowing all relationship\n",
    "          types.\n",
    "        prompt (Optional[ChatPromptTemplate], optional): The prompt to pass to\n",
    "          the LLM with additional instructions.\n",
    "        strict_mode (bool, optional): Determines whether the transformer should apply\n",
    "          filtering to strictly adhere to `allowed_nodes` and `allowed_relationships`.\n",
    "          Defaults to True.\n",
    "\n",
    "    Example:\n",
    "        .. code-block:: python\n",
    "            from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "            from langchain_core.documents import Document\n",
    "            from langchain_openai import ChatOpenAI\n",
    "\n",
    "            llm=ChatOpenAI(temperature=0)\n",
    "            transformer = LLMGraphTransformer(\n",
    "                llm=llm,\n",
    "                allowed_nodes=[\"Person\", \"Organization\"])\n",
    "\n",
    "            doc = Document(page_content=\"Elon Musk is suing OpenAI\")\n",
    "            graph_documents = transformer.convert_to_graph_documents([doc])\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        llm: BaseLanguageModel,\n",
    "        allowed_nodes: List[str] = [],\n",
    "        allowed_relationships: List[str] = [],\n",
    "        prompt: Optional[ChatPromptTemplate] = None,\n",
    "        strict_mode: bool = True,\n",
    "        node_properties: Union[bool, List[str]] = False,\n",
    "    ) -> None:\n",
    "        self.allowed_nodes = allowed_nodes\n",
    "        self.allowed_relationships = allowed_relationships\n",
    "        self.strict_mode = strict_mode\n",
    "        self._function_call = True\n",
    "        # Check if the LLM really supports structured output\n",
    "        try:\n",
    "            llm.with_structured_output(_Graph)\n",
    "        except NotImplementedError:\n",
    "            self._function_call = False\n",
    "        if not self._function_call:\n",
    "            if node_properties:\n",
    "                raise ValueError(\n",
    "                    \"The 'node_properties' parameter cannot be used \"\n",
    "                    \"in combination with a LLM that doesn't support \"\n",
    "                    \"native function calling.\"\n",
    "                )\n",
    "            try:\n",
    "                import json_repair\n",
    "\n",
    "                self.json_repair = json_repair\n",
    "            except ImportError:\n",
    "                raise ImportError(\n",
    "                    \"Could not import json_repair python package. \"\n",
    "                    \"Please install it with `pip install json-repair`.\"\n",
    "                )\n",
    "            prompt = prompt or create_unstructured_prompt(\n",
    "                allowed_nodes, allowed_relationships\n",
    "            )\n",
    "            self.chain = prompt | llm\n",
    "        else:\n",
    "            # Define chain\n",
    "            schema = create_simple_model(\n",
    "                allowed_nodes, allowed_relationships, node_properties\n",
    "            )\n",
    "            structured_llm = llm.with_structured_output(schema, include_raw=True)\n",
    "            prompt = prompt or default_prompt\n",
    "            self.chain = prompt | structured_llm\n",
    "\n",
    "    def process_response(self, document: Document) -> GraphDocument:\n",
    "        \"\"\"\n",
    "        Processes a single document, transforming it into a graph document using\n",
    "        an LLM based on the model's schema and constraints.\n",
    "        \"\"\"\n",
    "        text = document.page_content\n",
    "        raw_schema = self.chain.invoke({\"input\": text})\n",
    "        if self._function_call:\n",
    "            raw_schema = cast(Dict[Any, Any], raw_schema)\n",
    "            nodes, relationships = _convert_to_graph_document(raw_schema)\n",
    "        else:\n",
    "            nodes_set = set()\n",
    "            relationships = []\n",
    "            parsed_json = self.json_repair.loads(raw_schema.content)\n",
    "            for rel in parsed_json:\n",
    "                # Nodes need to be deduplicated using a set\n",
    "                nodes_set.add((rel[\"head\"], rel[\"head_type\"]))\n",
    "                nodes_set.add((rel[\"tail\"], rel[\"tail_type\"]))\n",
    "\n",
    "                source_node = Node(id=rel[\"head\"], type=rel[\"head_type\"])\n",
    "                target_node = Node(id=rel[\"tail\"], type=rel[\"tail_type\"])\n",
    "                relationships.append(\n",
    "                    Relationship(\n",
    "                        source=source_node, target=target_node, type=rel[\"relation\"]\n",
    "                    )\n",
    "                )\n",
    "            # Create nodes list\n",
    "            nodes = [Node(id=el[0], type=el[1]) for el in list(nodes_set)]\n",
    "\n",
    "        # Strict mode filtering\n",
    "        if self.strict_mode and (self.allowed_nodes or self.allowed_relationships):\n",
    "            if self.allowed_nodes:\n",
    "                lower_allowed_nodes = [el.lower() for el in self.allowed_nodes]\n",
    "                nodes = [\n",
    "                    node for node in nodes if node.type.lower() in lower_allowed_nodes\n",
    "                ]\n",
    "                relationships = [\n",
    "                    rel\n",
    "                    for rel in relationships\n",
    "                    if rel.source.type.lower() in lower_allowed_nodes\n",
    "                    and rel.target.type.lower() in lower_allowed_nodes\n",
    "                ]\n",
    "            if self.allowed_relationships:\n",
    "                relationships = [\n",
    "                    rel\n",
    "                    for rel in relationships\n",
    "                    if rel.type.lower()\n",
    "                    in [el.lower() for el in self.allowed_relationships]\n",
    "                ]\n",
    "\n",
    "        return GraphDocument(nodes=nodes, relationships=relationships, source=document)\n",
    "\n",
    "    def convert_to_graph_documents(\n",
    "        self, documents: Sequence[Document]\n",
    "    ) -> List[GraphDocument]:\n",
    "        \"\"\"Convert a sequence of documents into graph documents.\n",
    "\n",
    "        Args:\n",
    "            documents (Sequence[Document]): The original documents.\n",
    "            **kwargs: Additional keyword arguments.\n",
    "\n",
    "        Returns:\n",
    "            Sequence[GraphDocument]: The transformed documents as graphs.\n",
    "        \"\"\"\n",
    "        return [self.process_response(document) for document in documents]\n",
    "\n",
    "    async def aprocess_response(self, document: Document) -> GraphDocument:\n",
    "        \"\"\"\n",
    "        Asynchronously processes a single document, transforming it into a\n",
    "        graph document.\n",
    "        \"\"\"\n",
    "        text = document.page_content\n",
    "        raw_schema = await self.chain.ainvoke({\"input\": text})\n",
    "        raw_schema = cast(Dict[Any, Any], raw_schema)\n",
    "        nodes, relationships = _convert_to_graph_document(raw_schema)\n",
    "\n",
    "        if self.strict_mode and (self.allowed_nodes or self.allowed_relationships):\n",
    "            if self.allowed_nodes:\n",
    "                lower_allowed_nodes = [el.lower() for el in self.allowed_nodes]\n",
    "                nodes = [\n",
    "                    node for node in nodes if node.type.lower() in lower_allowed_nodes\n",
    "                ]\n",
    "                relationships = [\n",
    "                    rel\n",
    "                    for rel in relationships\n",
    "                    if rel.source.type.lower() in lower_allowed_nodes\n",
    "                    and rel.target.type.lower() in lower_allowed_nodes\n",
    "                ]\n",
    "            if self.allowed_relationships:\n",
    "                relationships = [\n",
    "                    rel\n",
    "                    for rel in relationships\n",
    "                    if rel.type.lower()\n",
    "                    in [el.lower() for el in self.allowed_relationships]\n",
    "                ]\n",
    "\n",
    "        return GraphDocument(nodes=nodes, relationships=relationships, source=document)\n",
    "\n",
    "    async def aconvert_to_graph_documents(\n",
    "        self, documents: Sequence[Document]\n",
    "    ) -> List[GraphDocument]:\n",
    "        \"\"\"\n",
    "        Asynchronously convert a sequence of documents into graph documents.\n",
    "        \"\"\"\n",
    "        tasks = [\n",
    "            asyncio.create_task(self.aprocess_response(document))\n",
    "            for document in documents\n",
    "        ]\n",
    "        results = await asyncio.gather(*tasks)\n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4cc7f4-ee89-4e5e-bd61-054c71931ffd",
   "metadata": {},
   "source": [
    "**Now for the Imports**\n",
    "\n",
    "This time we are isloating Vertex AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "642f246f-53e3-4786-ab49-8fb5bdb567f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "#from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "from langchain_google_vertexai import ChatVertexAI\n",
    "from langchain_core.documents import Document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f00f8cc-8185-4fcb-b670-9c423d033b50",
   "metadata": {},
   "source": [
    "**Diagnostic Methods**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9df06eb-6527-44fe-8e8d-6d6c0fb394cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Vertex AI Model Graph Transformer Diagnostic Dump\n",
    "def print_llm_xfrm(llm_xfrm):\n",
    "    print(f\"llm_xfrm: {llm_xfrm}\") \n",
    "    print(f\"allowed_nodes: {llm_xfrm.allowed_nodes}\") \n",
    "    print(f\"allowed_relationships: {llm_xfrm.allowed_relationships}\") \n",
    "    print(f\"strict_mode: {llm_xfrm.strict_mode}\")  \n",
    "    print(f\"_function_call: {llm_xfrm._function_call}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "695f63e0-8c42-49bd-adf0-c01df7b8d31f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Vertex AI Model Diagnostic Dump\n",
    "def print_llm(llm):\n",
    "    print(f\"llm: {llm}\")\n",
    "    print(f\"name: {llm.model_name}\")\n",
    "    print(f\"examples: {llm.examples}\") \n",
    "    print(f\"tuned_model_name: {llm.tuned_model_name}\") \n",
    "    print(f\"convert_system_message_to_human: {llm.convert_system_message_to_human}\") \n",
    "    print(f\"max_output_tokens: {llm.max_output_tokens}\") \n",
    "    print(f\"top_p: {llm.top_p}\") \n",
    "    print(f\"top_k: {llm.top_k}\") \n",
    "    print(f\"credentials: {llm.credentials}\")     \n",
    "    print(f\"n: {llm.n}\") \n",
    "    print(f\"streaming: {llm.streaming}\") \n",
    "    print(f\"safety_settings: {llm.safety_settings}\")     \n",
    "    print(f\"api_transport: {llm.api_transport}\") \n",
    "    print(f\"api_endpoint: {llm.api_endpoint}\") \n",
    " \n",
    "    print('properties') \n",
    "    print('----------') \n",
    "    \n",
    "    print(f\"_llm_type: {llm._llm_type}\") \n",
    "    print(f\"is_codey_model: {llm.is_codey_model}\")     \n",
    "    print(f\"_is_gemini_model: {llm._is_gemini_model}\")\n",
    "    print(f\"_identifying_params: {llm._identifying_params}\")     \n",
    "    print(f\"_default_params: {llm._default_params}\") \n",
    "    print(f\"_user_agent: {llm._user_agent}\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5858d1e5-2387-435b-a34f-0317cdd45d24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_graph_documents(graph_documents):\n",
    "    print(f\"graph_documents_len: {len(graph_documents)}\") \n",
    "    graphdoc_idx = 0\n",
    "    for gdoc in graph_documents:\n",
    "        print(\" \") \n",
    "        print(f\"graphdoc_idx: {graphdoc_idx}\") \n",
    "        graphdoc_idx += 1\n",
    "        \n",
    "        print(f\"Len doc_page_content {len(gdoc.source.page_content)}\") \n",
    "        print(f\"No. doc_metadata: {len(gdoc.source.metadata)}\")        \n",
    "        \n",
    "        print(f\"No. nodes: {len(gdoc.nodes)}\") \n",
    "        for noddy in gdoc.nodes:\n",
    "            print(f\"Node: {noddy}\")\n",
    "        \n",
    "        print(f\"No. relationships: {len(gdoc.relationships)}\") \n",
    "        for relly in gdoc.relationships:\n",
    "            print(f\"Relationship: {relly}\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a1967b-907b-4635-9d14-29c51de06016",
   "metadata": {},
   "source": [
    "**Connect to Google LLMs**\n",
    "\n",
    "*Least Privilege Security.*\n",
    "\n",
    "The Notebook is \"owned\" by a bespoke Service Account created in terrafrom for this purpose.\n",
    "\n",
    "Minimal permisisons are added (also via terraform) via predefined roles (esp. Vertex) as required.\n",
    "\n",
    "This is typically triggered by a PERMISSION DENIED error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc6314e9-e801-4103-aa9b-85c7a1befdd2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d23f54b60a95e062becfc280514f90842e3b8169\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Set It - will require regeneration\n",
    "os.environ['GOOGLE_API_KEY'] = 'd23f54b60a95e062becfc280514f90842e3b8169'\n",
    "# Access the environment variable later in your code\n",
    "api_key = os.environ['GOOGLE_API_KEY']\n",
    "print(api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03c9d7a-f26a-40ff-9784-837c9b80d270",
   "metadata": {},
   "source": [
    "****Enable Langchain Debugging****\n",
    "\n",
    "See: https://python.langchain.com/v0.1/docs/guides/development/debugging/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24d3fce2-7775-4b22-8b61-b4e10ae87edd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.globals import set_debug   \n",
    "\n",
    "set_debug(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a2b08b-8722-41ae-a5aa-4dda5af5f7ad",
   "metadata": {},
   "source": [
    "**Create The LLMs**\n",
    "\n",
    "Both *Gemini* & *Chat Bison* were created.\n",
    "\n",
    "Chat Bison malfunctioned so has been abandoned FTTB \n",
    "\n",
    "Sourced from here: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a9c76ea-8232-4404-b82a-8d344ae786b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Avalable Model Variables\n",
    "\n",
    "# Gemini 1.5 Pro (Preview)\n",
    "# 404 Publisher Model `projects/nlp-dev-6aae/locations/us-central1/publishers/google/models/gemini-1.5-pro` not found.\n",
    "#gemini_1pt5_proOnVertex = ChatVertexAI(model=\"gemini-1.5-pro\")\n",
    "#Retrying langchain_google_vertexai.chat_models._completion_with_retry.<locals>._completion_with_retry_inner in 10.0 seconds as it raised InvalidArgument: 400 Request contains an invalid argument..\n",
    "gemini_1pt5_proOnVertex = ChatVertexAI(model=\"gemini-1.5-pro-preview-0409\")\n",
    "\n",
    "\n",
    "\n",
    "# Gemini 1.0 Pro\n",
    "# This works with Errors - chunking\n",
    "gemini_1pt0_proOnVertex = ChatVertexAI(model=\"gemini-1.0-pro\")\n",
    "\n",
    "gemini_proOnVertex = ChatVertexAI(model=\"gemini-pro\")\n",
    "\n",
    "# PaLM 2 for Chat (\"chat-bison\")\n",
    "# This fails atm\n",
    "model_chat_bison = ChatVertexAI()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e39c0ff-e607-4a74-ab7b-962c16c8c45c",
   "metadata": {},
   "source": [
    "**Choose which model we are using**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ecd7658-ec29-474c-b89e-9a59d43015f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chat_llm = gemini_1pt0_proOnVertex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7dba7c3-8534-496f-a4bc-bf086c546815",
   "metadata": {},
   "source": [
    "*Check Model Properties*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c67bec55-3505-4481-b385-d152838cc891",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm: client=<vertexai.generative_models.GenerativeModel object at 0x7fda0f57ead0> model_name='gemini-1.0-pro' client_preview=<vertexai.generative_models.GenerativeModel object at 0x7fda0f57e9b0>\n",
      "name: gemini-1.0-pro\n",
      "examples: None\n",
      "tuned_model_name: None\n",
      "convert_system_message_to_human: False\n",
      "max_output_tokens: None\n",
      "top_p: None\n",
      "top_k: None\n",
      "credentials: None\n",
      "n: 1\n",
      "streaming: False\n",
      "safety_settings: None\n",
      "api_transport: None\n",
      "api_endpoint: None\n",
      "properties\n",
      "----------\n",
      "_llm_type: vertexai\n",
      "is_codey_model: False\n",
      "_is_gemini_model: True\n",
      "_identifying_params: {'model_name': 'gemini-1.0-pro', 'candidate_count': 1}\n",
      "_default_params: {'candidate_count': 1}\n",
      "_user_agent: langchain-google-vertexai/1.0.3-ChatVertexAI_gemini-1.0-pro\n"
     ]
    }
   ],
   "source": [
    "print_llm(chat_llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193d9703-1fde-4a23-8f8a-e139e9c4737f",
   "metadata": {},
   "source": [
    "**Construct Graph Transformer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4da6f4bb-d922-4774-86be-aeb5a3cb289b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "default_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Extract all Entities\",\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            (\n",
    "                \"Tip: Make sure to answer in the correct format and do \"\n",
    "                \"not include any explanations. \"\n",
    "                \"Use the given format to extract information from the \"\n",
    "                \"following input: {input}\"\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "llm_transformer = LLMGraphTransformer(llm=chat_llm)\n",
    "#llm_transformer._function_call = False # Causes Error\n",
    "## Shows how to override prompt\n",
    "#llm_transformer = LLMGraphTransformer(llm=chat_llm, prompt=default_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7408462-c748-4805-8c91-9e25440f8e96",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm_xfrm: <__main__.LLMGraphTransformer object at 0x7fda17568eb0>\n",
      "allowed_nodes: []\n",
      "allowed_relationships: []\n",
      "strict_mode: True\n",
      "_function_call: True\n"
     ]
    }
   ],
   "source": [
    "print_llm_xfrm(llm_transformer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b46647-b939-400e-b569-30f93fe24c45",
   "metadata": {},
   "source": [
    "**Easy Test Case**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "52a0456c-cf46-48d4-aa5c-b2d97a6933fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "text = \"\"\"\n",
    "Current Professional Machine Learning Engineer Certification exam guide\n",
    "A Professional Machine Learning Engineer builds, evaluates, productionizes, and optimizes ML models by using Google Cloud technologies and knowledge of proven models and techniques. The ML Engineer handles large, complex datasets and creates repeatable, reusable code. The ML Engineer considers responsible AI and fairness throughout the ML model development process, and collaborates closely with other job roles to ensure long-term success of ML-based applications. The ML Engineer has strong programming skills and experience with data platforms and distributed data processing tools. The ML Engineer is proficient in the areas of model architecture, data and ML pipeline creation, and metrics interpretation. The ML Engineer is familiar with foundational concepts of MLOps, application development, infrastructure management, data engineering, and data governance. The ML Engineer makes ML accessible and enables teams across the organization. By training, retraining, deploying, scheduling, monitoring, and improving models, the ML Engineer designs and creates scalable, performant solutions.\n",
    "Note: The exam does not directly assess coding skill. If you have a minimum proficiency in Python and Cloud SQL, you should be able to interpret any questions with code snippets.\n",
    "Register now\n",
    "The Professional Machine Learning Engineer exam does not cover generative AI, as the tools used to develop generative AI-based solutions are evolving quickly. If you are interested in generative AI, please refer to the Introduction to Generative AI Learning Path (all audiences) or the Generative AI for Developers Learning Path (technical audience). If you are a partner, please refer to the Gen AI partner courses: Introduction to Generative AI Learning Path, Generative AI for ML Engineers, and Generative AI for Developers.\n",
    "Section 1: Architecting low-code ML solutions (~12% of the exam)\n",
    "1.1 Developing ML models by using BigQuery ML. Considerations include:\n",
    "Building the appropriate BigQuery ML model (e.g., linear and binary classification, regression, time-series, matrix factorization, boosted trees, autoencoders) based on the business problem\n",
    "Feature engineering or selection by using BigQuery ML\n",
    "Generating predictions by using BigQuery ML\n",
    "1.2 Building AI solutions by using ML APIs. Considerations include:\n",
    "Building applications by using ML APIs (e.g., Cloud Vision API, Natural Language API, Cloud Speech API, Translation)\n",
    "Building applications by using industry-specific APIs (e.g., Document AI API, Retail API)\n",
    "1.3 Training models by using AutoML. Considerations include:\n",
    "Preparing data for AutoML (e.g., feature selection, data labeling, Tabular Workflows on AutoML)\n",
    "Using available data (e.g., tabular, text, speech, images, videos) to train custom models\n",
    "Using AutoML for tabular data\n",
    "Creating forecasting models using AutoML\n",
    "Configuring and debugging trained models\n",
    "Section 2: Collaborating within and across teams to manage data and models (~16% of the exam)\n",
    "2.1 Exploring and preprocessing organization-wide data (e.g., Cloud Storage, BigQuery, Spanner, Cloud SQL, Apache Spark, Apache Hadoop). Considerations include:\n",
    "Organizing different types of data (e.g., tabular, text, speech, images, videos) for efficient training\n",
    "Managing datasets in Vertex AI\n",
    "Data preprocessing (e.g., Dataflow, TensorFlow Extended [TFX], BigQuery)\n",
    "Creating and consolidating features in Vertex AI Feature Store\n",
    "Privacy implications of data usage and/or collection (e.g., handling sensitive data such as personally identifiable information [PII] and protected health information [PHI])\n",
    "2.2 Model prototyping using Jupyter notebooks. Considerations include:\n",
    "Choosing the appropriate Jupyter backend on Google Cloud (e.g., Vertex AI Workbench, notebooks on Dataproc)\n",
    "Applying security best practices in Vertex AI Workbench\n",
    "Using Spark kernels\n",
    "Integration with code source repositories\n",
    "Developing models in Vertex AI Workbench by using common frameworks (e.g., TensorFlow, PyTorch, sklearn, Spark, JAX)\n",
    "2.3 Tracking and running ML experiments. Considerations include:\n",
    "Choosing the appropriate Google Cloud environment for development and experimentation (e.g., Vertex AI Experiments, Kubeflow Pipelines, Vertex AI TensorBoard with TensorFlow and PyTorch) given the framework\n",
    "Section 3: Scaling prototypes into ML models (~18% of the exam)\n",
    "3.1 Building models. Considerations include:\n",
    "Choosing ML framework and model architecture\n",
    "Modeling techniques given interpretability requirements\n",
    "3.2 Training models. Considerations include:\n",
    "Organizing training data (e.g., tabular, text, speech, images, videos) on Google Cloud (e.g., Cloud Storage, BigQuery)\n",
    "Ingestion of various file types (e.g., CSV, JSON, images, Hadoop, databases) into training\n",
    "Training using different SDKs (e.g., Vertex AI custom training, Kubeflow on Google Kubernetes Engine, AutoML, tabular workflows)\n",
    "Using distributed training to organize reliable pipelines\n",
    "Hyperparameter tuning\n",
    "Troubleshooting ML model training failures\n",
    "3.3 Choosing appropriate hardware for training. Considerations include:\n",
    "Evaluation of compute and accelerator options (e.g., CPU, GPU, TPU, edge devices)\n",
    "Distributed training with TPUs and GPUs (e.g., Reduction Server on Vertex AI, Horovod)\n",
    "Section 4: Serving and scaling models (~19% of the exam)\n",
    "4.1 Serving models. Considerations include:\n",
    "Batch and online inference (e.g., Vertex AI, Dataflow, BigQuery ML, Dataproc)\n",
    "Using different frameworks (e.g., PyTorch, XGBoost) to serve models\n",
    "Organizing a model registry\n",
    "A/B testing different versions of a model\n",
    "4.2 Scaling online model serving. Considerations include:\n",
    "Vertex AI Feature Store\n",
    "Vertex AI public and private endpoints\n",
    "Choosing appropriate hardware (e.g., CPU, GPU, TPU, edge)\n",
    "Scaling the serving backend based on the throughput (e.g., Vertex AI Prediction, containerized serving)\n",
    "Tuning ML models for training and serving in production (e.g., simplification techniques, optimizing the ML solution for increased performance, latency, memory, throughput)\n",
    "Section 5: Automating and orchestrating ML pipelines (~21% of the exam)\n",
    "5.1 Developing end-to-end ML pipelines. Considerations include:\n",
    "Data and model validation\n",
    "Ensuring consistent data pre-processing between training and serving\n",
    "Hosting third-party pipelines on Google Cloud (e.g., MLFlow)\n",
    "Identifying components, parameters, triggers, and compute needs (e.g., Cloud Build, Cloud Run)\n",
    "Orchestration framework (e.g., Kubeflow Pipelines, Vertex AI Pipelines, Cloud Composer)\n",
    "Hybrid or multicloud strategies\n",
    "System design with TFX components or Kubeflow DSL (e.g., Dataflow)\n",
    "5.2 Automating model retraining. Considerations include:\n",
    "Determining an appropriate retraining policy\n",
    "Continuous integration and continuous delivery (CI/CD) model deployment (e.g., Cloud Build, Jenkins)\n",
    "5.3 Tracking and auditing metadata. Considerations include: \n",
    "Tracking and comparing model artifacts and versions (e.g., Vertex AI Experiments, Vertex ML Metadata)\n",
    "Hooking into model and dataset versioning\n",
    "Model and data lineage\n",
    "Section 6: Monitoring ML solutions (~14% of the exam)\n",
    "6.1 Identifying risks to ML solutions. Considerations include:\n",
    "Building secure ML systems (e.g., protecting against unintentional exploitation of data or models, hacking)\n",
    "Aligning with Googles Responsible AI practices (e.g., biases)\n",
    "Assessing ML solution readiness (e.g., data bias, fairness)\n",
    "Model explainability on Vertex AI (e.g., Vertex AI Prediction)\n",
    "6.2 Monitoring, testing, and troubleshooting ML solutions. Considerations include:\n",
    "Establishing continuous evaluation metrics (e.g., Vertex AI Model Monitoring, Explainable AI)\n",
    "Monitoring for training-serving skew\n",
    "Monitoring for feature attribution drift\n",
    "Monitoring model performance against baselines, simpler models, and across the time dimension\n",
    "Common training and serving errors\n",
    "\"\"\"\n",
    "documents = [Document(page_content=text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca4799f4-f4f9-47bc-b791-d290d7d1733d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. chunks20\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "# split documents into text and embeddings\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "   chunk_size=512, \n",
    "   chunk_overlap=20,\n",
    "   length_function=len,\n",
    "   is_separator_regex=False\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "print(f\"No. chunks{len(chunks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbf8c4c-2165-4b44-a14b-39822f82eddc",
   "metadata": {},
   "source": [
    "**Use Gemini** \n",
    "\n",
    "Works but with intermittent error which may cause data loss.\n",
    "\n",
    "Hence need for chunking per variouis discisions forums &c.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "477c8d12-057c-40ad-ba53-e6f4bd90db56",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"Current Professional Machine Learning Engineer Certification exam guide\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"Current Professional Machine Learning Engineer Certification exam guide\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<raw>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<raw> > llm:ChatVertexAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: Extract all Entities\\nHuman: Tip: Make sure to answer in the correct format and do not include any explanations. Use the given format to extract information from the following input: Current Professional Machine Learning Engineer Certification exam guide\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<raw> > llm:ChatVertexAI] [1.26s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"\",\n",
      "        \"generation_info\": {\n",
      "          \"is_blocked\": false,\n",
      "          \"safety_ratings\": [\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
      "              \"probability_label\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
      "              \"probability_label\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
      "              \"probability_label\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
      "              \"probability_label\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            }\n",
      "          ],\n",
      "          \"citation_metadata\": null,\n",
      "          \"usage_metadata\": {\n",
      "            \"prompt_token_count\": 368,\n",
      "            \"candidates_token_count\": 14,\n",
      "            \"total_token_count\": 382\n",
      "          }\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"function_call\": {\n",
      "                \"name\": \"DynamicGraph\",\n",
      "                \"arguments\": \"{\\\"nodes\\\": [{\\\"id\\\": \\\"Current Professional Machine Learning Engineer Certification exam guide\\\", \\\"type\\\": \\\"Text\\\"}]}\"\n",
      "              }\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"is_blocked\": false,\n",
      "              \"safety_ratings\": [\n",
      "                {\n",
      "                  \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
      "                  \"probability_label\": \"NEGLIGIBLE\",\n",
      "                  \"blocked\": false\n",
      "                },\n",
      "                {\n",
      "                  \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
      "                  \"probability_label\": \"NEGLIGIBLE\",\n",
      "                  \"blocked\": false\n",
      "                },\n",
      "                {\n",
      "                  \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
      "                  \"probability_label\": \"NEGLIGIBLE\",\n",
      "                  \"blocked\": false\n",
      "                },\n",
      "                {\n",
      "                  \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
      "                  \"probability_label\": \"NEGLIGIBLE\",\n",
      "                  \"blocked\": false\n",
      "                }\n",
      "              ],\n",
      "              \"citation_metadata\": null,\n",
      "              \"usage_metadata\": {\n",
      "                \"prompt_token_count\": 368,\n",
      "                \"candidates_token_count\": 14,\n",
      "                \"total_token_count\": 382\n",
      "              }\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-869cef2e-c550-46e5-8288-9d8040a16743-0\",\n",
      "            \"tool_calls\": [\n",
      "              {\n",
      "                \"name\": \"DynamicGraph\",\n",
      "                \"args\": {\n",
      "                  \"nodes\": [\n",
      "                    {\n",
      "                      \"id\": \"Current Professional Machine Learning Engineer Certification exam guide\",\n",
      "                      \"type\": \"Text\"\n",
      "                    }\n",
      "                  ]\n",
      "                },\n",
      "                \"id\": \"e1b7ed99-dc2f-49c4-9502-3f4b2d5a57c5\"\n",
      "              }\n",
      "            ],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<raw>] [1.26s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence > chain:RunnableLambda] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence > parser:PydanticToolsParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence > parser:PydanticToolsParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence] [2ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableLambda] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error>] [5ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error>] [8ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks] [12ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [1.28s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"A Professional Machine Learning Engineer builds, evaluates, productionizes, and optimizes ML models by using Google Cloud technologies and knowledge of proven models and techniques. The ML Engineer handles large, complex datasets and creates repeatable, reusable code. The ML Engineer considers responsible AI and fairness throughout the ML model development process, and collaborates closely with other job roles to ensure long-term success of ML-based applications. The ML Engineer has strong programming\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"A Professional Machine Learning Engineer builds, evaluates, productionizes, and optimizes ML models by using Google Cloud technologies and knowledge of proven models and techniques. The ML Engineer handles large, complex datasets and creates repeatable, reusable code. The ML Engineer considers responsible AI and fairness throughout the ML model development process, and collaborates closely with other job roles to ensure long-term success of ML-based applications. The ML Engineer has strong programming\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<raw>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<raw> > llm:ChatVertexAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: Extract all Entities\\nHuman: Tip: Make sure to answer in the correct format and do not include any explanations. Use the given format to extract information from the following input: A Professional Machine Learning Engineer builds, evaluates, productionizes, and optimizes ML models by using Google Cloud technologies and knowledge of proven models and techniques. The ML Engineer handles large, complex datasets and creates repeatable, reusable code. The ML Engineer considers responsible AI and fairness throughout the ML model development process, and collaborates closely with other job roles to ensure long-term success of ML-based applications. The ML Engineer has strong programming\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<raw> > llm:ChatVertexAI] [6.22s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"\",\n",
      "        \"generation_info\": {\n",
      "          \"is_blocked\": false,\n",
      "          \"safety_ratings\": [\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
      "              \"probability_label\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
      "              \"probability_label\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
      "              \"probability_label\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
      "              \"probability_label\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            }\n",
      "          ],\n",
      "          \"citation_metadata\": null,\n",
      "          \"usage_metadata\": {\n",
      "            \"prompt_token_count\": 446,\n",
      "            \"candidates_token_count\": 340,\n",
      "            \"total_token_count\": 786\n",
      "          }\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"function_call\": {\n",
      "                \"name\": \"DynamicGraph\",\n",
      "                \"arguments\": \"{\\\"nodes\\\": [{\\\"id\\\": \\\"Machine Learning Engineer\\\", \\\"type\\\": \\\"Person\\\"}, {\\\"id\\\": \\\"ML models\\\", \\\"type\\\": \\\"Object\\\"}, {\\\"type\\\": \\\"Object\\\", \\\"id\\\": \\\"Google Cloud technologies\\\"}, {\\\"id\\\": \\\"Proven Models and Techniques\\\", \\\"type\\\": \\\"Object\\\"}, {\\\"id\\\": \\\"Large Datasets\\\", \\\"type\\\": \\\"Object\\\"}, {\\\"id\\\": \\\"ML-based applications\\\", \\\"type\\\": \\\"Object\\\"}, {\\\"type\\\": \\\"Object\\\", \\\"id\\\": \\\"Other Job roles\\\"}, {\\\"type\\\": \\\"Object\\\", \\\"id\\\": \\\"Responsible AI\\\"}], \\\"relationships\\\": [{\\\"target_node_type\\\": \\\"Object\\\", \\\"type\\\": \\\"Builds\\\", \\\"source_node_type\\\": \\\"Person\\\", \\\"target_node_id\\\": \\\"ML models\\\", \\\"source_node_id\\\": \\\"Machine Learning Engineer\\\"}, {\\\"target_node_type\\\": \\\"Object\\\", \\\"source_node_type\\\": \\\"Person\\\", \\\"source_node_id\\\": \\\"Machine Learning Engineer\\\", \\\"target_node_id\\\": \\\"ML models\\\", \\\"type\\\": \\\"Evaluates\\\"}, {\\\"source_node_id\\\": \\\"Machine Learning Engineer\\\", \\\"type\\\": \\\"Productionizes\\\", \\\"target_node_type\\\": \\\"Object\\\", \\\"source_node_type\\\": \\\"Person\\\", \\\"target_node_id\\\": \\\"ML models\\\"}, {\\\"target_node_type\\\": \\\"Object\\\", \\\"source_node_id\\\": \\\"Machine Learning Engineer\\\", \\\"source_node_type\\\": \\\"Person\\\", \\\"type\\\": \\\"Optimizes\\\", \\\"target_node_id\\\": \\\"ML models\\\"}, {\\\"source_node_type\\\": \\\"Person\\\", \\\"source_node_id\\\": \\\"Machine Learning Engineer\\\", \\\"target_node_id\\\": \\\"Google Cloud technologies\\\", \\\"type\\\": \\\"Uses\\\", \\\"target_node_type\\\": \\\"Object\\\"}, {\\\"type\\\": \\\"Knowledge of\\\", \\\"source_node_id\\\": \\\"Machine Learning Engineer\\\", \\\"source_node_type\\\": \\\"Person\\\", \\\"target_node_id\\\": \\\"Proven Models and Techniques\\\", \\\"target_node_type\\\": \\\"Object\\\"}, {\\\"source_node_type\\\": \\\"Person\\\", \\\"source_node_id\\\": \\\"Machine Learning Engineer\\\", \\\"target_node_id\\\": \\\"Large Datasets\\\", \\\"target_node_type\\\": \\\"Object\\\", \\\"type\\\": \\\"Handles\\\"}, {\\\"source_node_id\\\": \\\"Machine Learning Engineer\\\", \\\"source_node_type\\\": \\\"Person\\\", \\\"type\\\": \\\"Collaborates with other job roles to ensure long-term success of\\\", \\\"target_node_id\\\": \\\"ML-based applications\\\", \\\"target_node_type\\\": \\\"Object\\\"}, {\\\"source_node_id\\\": \\\"Machine Learning Engineer\\\", \\\"target_node_id\\\": \\\"Responsible AI\\\", \\\"target_node_type\\\": \\\"Object\\\", \\\"type\\\": \\\"Considers throughout the ML model development process\\\", \\\"source_node_type\\\": \\\"Person\\\"}]}\"\n",
      "              }\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"is_blocked\": false,\n",
      "              \"safety_ratings\": [\n",
      "                {\n",
      "                  \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
      "                  \"probability_label\": \"NEGLIGIBLE\",\n",
      "                  \"blocked\": false\n",
      "                },\n",
      "                {\n",
      "                  \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
      "                  \"probability_label\": \"NEGLIGIBLE\",\n",
      "                  \"blocked\": false\n",
      "                },\n",
      "                {\n",
      "                  \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
      "                  \"probability_label\": \"NEGLIGIBLE\",\n",
      "                  \"blocked\": false\n",
      "                },\n",
      "                {\n",
      "                  \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
      "                  \"probability_label\": \"NEGLIGIBLE\",\n",
      "                  \"blocked\": false\n",
      "                }\n",
      "              ],\n",
      "              \"citation_metadata\": null,\n",
      "              \"usage_metadata\": {\n",
      "                \"prompt_token_count\": 446,\n",
      "                \"candidates_token_count\": 340,\n",
      "                \"total_token_count\": 786\n",
      "              }\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-030f7010-5cc0-4149-bc5f-1ced2342a095-0\",\n",
      "            \"tool_calls\": [\n",
      "              {\n",
      "                \"name\": \"DynamicGraph\",\n",
      "                \"args\": {\n",
      "                  \"nodes\": [\n",
      "                    {\n",
      "                      \"id\": \"Machine Learning Engineer\",\n",
      "                      \"type\": \"Person\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"ML models\",\n",
      "                      \"type\": \"Object\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"Object\",\n",
      "                      \"id\": \"Google Cloud technologies\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"Proven Models and Techniques\",\n",
      "                      \"type\": \"Object\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"Large Datasets\",\n",
      "                      \"type\": \"Object\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"ML-based applications\",\n",
      "                      \"type\": \"Object\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"Object\",\n",
      "                      \"id\": \"Other Job roles\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"Object\",\n",
      "                      \"id\": \"Responsible AI\"\n",
      "                    }\n",
      "                  ],\n",
      "                  \"relationships\": [\n",
      "                    {\n",
      "                      \"target_node_type\": \"Object\",\n",
      "                      \"type\": \"Builds\",\n",
      "                      \"source_node_type\": \"Person\",\n",
      "                      \"target_node_id\": \"ML models\",\n",
      "                      \"source_node_id\": \"Machine Learning Engineer\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"target_node_type\": \"Object\",\n",
      "                      \"source_node_type\": \"Person\",\n",
      "                      \"source_node_id\": \"Machine Learning Engineer\",\n",
      "                      \"target_node_id\": \"ML models\",\n",
      "                      \"type\": \"Evaluates\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"source_node_id\": \"Machine Learning Engineer\",\n",
      "                      \"type\": \"Productionizes\",\n",
      "                      \"target_node_type\": \"Object\",\n",
      "                      \"source_node_type\": \"Person\",\n",
      "                      \"target_node_id\": \"ML models\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"target_node_type\": \"Object\",\n",
      "                      \"source_node_id\": \"Machine Learning Engineer\",\n",
      "                      \"source_node_type\": \"Person\",\n",
      "                      \"type\": \"Optimizes\",\n",
      "                      \"target_node_id\": \"ML models\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"source_node_type\": \"Person\",\n",
      "                      \"source_node_id\": \"Machine Learning Engineer\",\n",
      "                      \"target_node_id\": \"Google Cloud technologies\",\n",
      "                      \"type\": \"Uses\",\n",
      "                      \"target_node_type\": \"Object\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"Knowledge of\",\n",
      "                      \"source_node_id\": \"Machine Learning Engineer\",\n",
      "                      \"source_node_type\": \"Person\",\n",
      "                      \"target_node_id\": \"Proven Models and Techniques\",\n",
      "                      \"target_node_type\": \"Object\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"source_node_type\": \"Person\",\n",
      "                      \"source_node_id\": \"Machine Learning Engineer\",\n",
      "                      \"target_node_id\": \"Large Datasets\",\n",
      "                      \"target_node_type\": \"Object\",\n",
      "                      \"type\": \"Handles\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"source_node_id\": \"Machine Learning Engineer\",\n",
      "                      \"source_node_type\": \"Person\",\n",
      "                      \"type\": \"Collaborates with other job roles to ensure long-term success of\",\n",
      "                      \"target_node_id\": \"ML-based applications\",\n",
      "                      \"target_node_type\": \"Object\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"source_node_id\": \"Machine Learning Engineer\",\n",
      "                      \"target_node_id\": \"Responsible AI\",\n",
      "                      \"target_node_type\": \"Object\",\n",
      "                      \"type\": \"Considers throughout the ML model development process\",\n",
      "                      \"source_node_type\": \"Person\"\n",
      "                    }\n",
      "                  ]\n",
      "                },\n",
      "                \"id\": \"99c15f71-8332-4879-a5d1-b166385ffa21\"\n",
      "              }\n",
      "            ],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<raw>] [6.22s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence > chain:RunnableLambda] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence > parser:PydanticToolsParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence > parser:PydanticToolsParser] [1ms] Exiting Parser run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence] [2ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableLambda] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error>] [6ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error>] [8ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks] [11ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [6.24s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"strong programming skills and experience with data platforms and distributed data processing tools. The ML Engineer is proficient in the areas of model architecture, data and ML pipeline creation, and metrics interpretation. The ML Engineer is familiar with foundational concepts of MLOps, application development, infrastructure management, data engineering, and data governance. The ML Engineer makes ML accessible and enables teams across the organization. By training, retraining, deploying, scheduling,\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"strong programming skills and experience with data platforms and distributed data processing tools. The ML Engineer is proficient in the areas of model architecture, data and ML pipeline creation, and metrics interpretation. The ML Engineer is familiar with foundational concepts of MLOps, application development, infrastructure management, data engineering, and data governance. The ML Engineer makes ML accessible and enables teams across the organization. By training, retraining, deploying, scheduling,\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<raw>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<raw> > llm:ChatVertexAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: Extract all Entities\\nHuman: Tip: Make sure to answer in the correct format and do not include any explanations. Use the given format to extract information from the following input: strong programming skills and experience with data platforms and distributed data processing tools. The ML Engineer is proficient in the areas of model architecture, data and ML pipeline creation, and metrics interpretation. The ML Engineer is familiar with foundational concepts of MLOps, application development, infrastructure management, data engineering, and data governance. The ML Engineer makes ML accessible and enables teams across the organization. By training, retraining, deploying, scheduling,\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<raw> > llm:ChatVertexAI] [6.02s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"\",\n",
      "        \"generation_info\": {\n",
      "          \"is_blocked\": false,\n",
      "          \"safety_ratings\": [\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
      "              \"probability_label\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
      "              \"probability_label\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
      "              \"probability_label\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
      "              \"probability_label\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            }\n",
      "          ],\n",
      "          \"citation_metadata\": null,\n",
      "          \"usage_metadata\": {\n",
      "            \"prompt_token_count\": 444,\n",
      "            \"candidates_token_count\": 360,\n",
      "            \"total_token_count\": 804\n",
      "          }\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"function_call\": {\n",
      "                \"name\": \"DynamicGraph\",\n",
      "                \"arguments\": \"{\\\"relationships\\\": [{\\\"source_node_id\\\": \\\"ML Engineer\\\", \\\"target_node_type\\\": \\\"Software\\\", \\\"type\\\": \\\"USES\\\", \\\"target_node_id\\\": \\\"data platforms\\\", \\\"source_node_type\\\": \\\"Person\\\"}, {\\\"target_node_id\\\": \\\"distributed data processing tools\\\", \\\"type\\\": \\\"USES\\\", \\\"source_node_id\\\": \\\"ML Engineer\\\", \\\"source_node_type\\\": \\\"Person\\\", \\\"target_node_type\\\": \\\"Software\\\"}, {\\\"source_node_id\\\": \\\"ML Engineer\\\", \\\"type\\\": \\\"CREATES\\\", \\\"source_node_type\\\": \\\"Person\\\", \\\"target_node_type\\\": \\\"Model\\\", \\\"target_node_id\\\": \\\"model architecture\\\"}, {\\\"type\\\": \\\"CREATES\\\", \\\"source_node_type\\\": \\\"Person\\\", \\\"target_node_id\\\": \\\"data and ML pipeline creation\\\", \\\"target_node_type\\\": \\\"Process\\\", \\\"source_node_id\\\": \\\"ML Engineer\\\"}, {\\\"source_node_type\\\": \\\"Person\\\", \\\"type\\\": \\\"PERFORMS\\\", \\\"source_node_id\\\": \\\"ML Engineer\\\", \\\"target_node_id\\\": \\\"metrics interpretation\\\", \\\"target_node_type\\\": \\\"Process\\\"}, {\\\"target_node_type\\\": \\\"Concept\\\", \\\"source_node_type\\\": \\\"Person\\\", \\\"source_node_id\\\": \\\"ML Engineer\\\", \\\"type\\\": \\\"UNDERSTANDS\\\", \\\"target_node_id\\\": \\\"MLOps\\\"}, {\\\"source_node_type\\\": \\\"Person\\\", \\\"source_node_id\\\": \\\"ML Engineer\\\", \\\"type\\\": \\\"PERFORMS\\\", \\\"target_node_id\\\": \\\"application development\\\", \\\"target_node_type\\\": \\\"Process\\\"}, {\\\"source_node_id\\\": \\\"ML Engineer\\\", \\\"source_node_type\\\": \\\"Person\\\", \\\"type\\\": \\\"PERFORMS\\\", \\\"target_node_id\\\": \\\"infrastructure management\\\", \\\"target_node_type\\\": \\\"Process\\\"}, {\\\"source_node_type\\\": \\\"Person\\\", \\\"source_node_id\\\": \\\"ML Engineer\\\", \\\"target_node_type\\\": \\\"Process\\\", \\\"type\\\": \\\"PERFORMS\\\", \\\"target_node_id\\\": \\\"data engineering\\\"}, {\\\"type\\\": \\\"PERFORMS\\\", \\\"source_node_id\\\": \\\"ML Engineer\\\", \\\"target_node_id\\\": \\\"data governance\\\", \\\"source_node_type\\\": \\\"Person\\\", \\\"target_node_type\\\": \\\"Process\\\"}], \\\"nodes\\\": [{\\\"type\\\": \\\"Person\\\", \\\"id\\\": \\\"ML Engineer\\\"}, {\\\"type\\\": \\\"Software\\\", \\\"id\\\": \\\"data platforms\\\"}, {\\\"id\\\": \\\"distributed data processing tools\\\", \\\"type\\\": \\\"Software\\\"}, {\\\"id\\\": \\\"model architecture\\\", \\\"type\\\": \\\"Model\\\"}, {\\\"id\\\": \\\"data and ML pipeline creation\\\", \\\"type\\\": \\\"Process\\\"}, {\\\"id\\\": \\\"metrics interpretation\\\", \\\"type\\\": \\\"Process\\\"}, {\\\"type\\\": \\\"Concept\\\", \\\"id\\\": \\\"MLOps\\\"}, {\\\"id\\\": \\\"application development\\\", \\\"type\\\": \\\"Process\\\"}, {\\\"type\\\": \\\"Process\\\", \\\"id\\\": \\\"infrastructure management\\\"}, {\\\"type\\\": \\\"Process\\\", \\\"id\\\": \\\"data engineering\\\"}, {\\\"id\\\": \\\"data governance\\\", \\\"type\\\": \\\"Process\\\"}]}\"\n",
      "              }\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"is_blocked\": false,\n",
      "              \"safety_ratings\": [\n",
      "                {\n",
      "                  \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
      "                  \"probability_label\": \"NEGLIGIBLE\",\n",
      "                  \"blocked\": false\n",
      "                },\n",
      "                {\n",
      "                  \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
      "                  \"probability_label\": \"NEGLIGIBLE\",\n",
      "                  \"blocked\": false\n",
      "                },\n",
      "                {\n",
      "                  \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
      "                  \"probability_label\": \"NEGLIGIBLE\",\n",
      "                  \"blocked\": false\n",
      "                },\n",
      "                {\n",
      "                  \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
      "                  \"probability_label\": \"NEGLIGIBLE\",\n",
      "                  \"blocked\": false\n",
      "                }\n",
      "              ],\n",
      "              \"citation_metadata\": null,\n",
      "              \"usage_metadata\": {\n",
      "                \"prompt_token_count\": 444,\n",
      "                \"candidates_token_count\": 360,\n",
      "                \"total_token_count\": 804\n",
      "              }\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-2ca7ccb1-49d3-471c-a467-721c697dba0d-0\",\n",
      "            \"tool_calls\": [\n",
      "              {\n",
      "                \"name\": \"DynamicGraph\",\n",
      "                \"args\": {\n",
      "                  \"relationships\": [\n",
      "                    {\n",
      "                      \"source_node_id\": \"ML Engineer\",\n",
      "                      \"target_node_type\": \"Software\",\n",
      "                      \"type\": \"USES\",\n",
      "                      \"target_node_id\": \"data platforms\",\n",
      "                      \"source_node_type\": \"Person\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"target_node_id\": \"distributed data processing tools\",\n",
      "                      \"type\": \"USES\",\n",
      "                      \"source_node_id\": \"ML Engineer\",\n",
      "                      \"source_node_type\": \"Person\",\n",
      "                      \"target_node_type\": \"Software\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"source_node_id\": \"ML Engineer\",\n",
      "                      \"type\": \"CREATES\",\n",
      "                      \"source_node_type\": \"Person\",\n",
      "                      \"target_node_type\": \"Model\",\n",
      "                      \"target_node_id\": \"model architecture\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"CREATES\",\n",
      "                      \"source_node_type\": \"Person\",\n",
      "                      \"target_node_id\": \"data and ML pipeline creation\",\n",
      "                      \"target_node_type\": \"Process\",\n",
      "                      \"source_node_id\": \"ML Engineer\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"source_node_type\": \"Person\",\n",
      "                      \"type\": \"PERFORMS\",\n",
      "                      \"source_node_id\": \"ML Engineer\",\n",
      "                      \"target_node_id\": \"metrics interpretation\",\n",
      "                      \"target_node_type\": \"Process\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"target_node_type\": \"Concept\",\n",
      "                      \"source_node_type\": \"Person\",\n",
      "                      \"source_node_id\": \"ML Engineer\",\n",
      "                      \"type\": \"UNDERSTANDS\",\n",
      "                      \"target_node_id\": \"MLOps\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"source_node_type\": \"Person\",\n",
      "                      \"source_node_id\": \"ML Engineer\",\n",
      "                      \"type\": \"PERFORMS\",\n",
      "                      \"target_node_id\": \"application development\",\n",
      "                      \"target_node_type\": \"Process\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"source_node_id\": \"ML Engineer\",\n",
      "                      \"source_node_type\": \"Person\",\n",
      "                      \"type\": \"PERFORMS\",\n",
      "                      \"target_node_id\": \"infrastructure management\",\n",
      "                      \"target_node_type\": \"Process\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"source_node_type\": \"Person\",\n",
      "                      \"source_node_id\": \"ML Engineer\",\n",
      "                      \"target_node_type\": \"Process\",\n",
      "                      \"type\": \"PERFORMS\",\n",
      "                      \"target_node_id\": \"data engineering\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"PERFORMS\",\n",
      "                      \"source_node_id\": \"ML Engineer\",\n",
      "                      \"target_node_id\": \"data governance\",\n",
      "                      \"source_node_type\": \"Person\",\n",
      "                      \"target_node_type\": \"Process\"\n",
      "                    }\n",
      "                  ],\n",
      "                  \"nodes\": [\n",
      "                    {\n",
      "                      \"type\": \"Person\",\n",
      "                      \"id\": \"ML Engineer\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"Software\",\n",
      "                      \"id\": \"data platforms\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"distributed data processing tools\",\n",
      "                      \"type\": \"Software\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"model architecture\",\n",
      "                      \"type\": \"Model\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"data and ML pipeline creation\",\n",
      "                      \"type\": \"Process\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"metrics interpretation\",\n",
      "                      \"type\": \"Process\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"Concept\",\n",
      "                      \"id\": \"MLOps\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"application development\",\n",
      "                      \"type\": \"Process\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"Process\",\n",
      "                      \"id\": \"infrastructure management\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"Process\",\n",
      "                      \"id\": \"data engineering\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"data governance\",\n",
      "                      \"type\": \"Process\"\n",
      "                    }\n",
      "                  ]\n",
      "                },\n",
      "                \"id\": \"fff867cd-9e09-4ee0-889f-cd52c2331a09\"\n",
      "              }\n",
      "            ],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<raw>] [6.02s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence > chain:RunnableLambda] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence > parser:PydanticToolsParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence > parser:PydanticToolsParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableLambda] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error>] [5ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error>] [7ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks] [10ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [6.04s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"scheduling, monitoring, and improving models, the ML Engineer designs and creates scalable, performant solutions.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"scheduling, monitoring, and improving models, the ML Engineer designs and creates scalable, performant solutions.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<raw>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<raw> > llm:ChatVertexAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: Extract all Entities\\nHuman: Tip: Make sure to answer in the correct format and do not include any explanations. Use the given format to extract information from the following input: scheduling, monitoring, and improving models, the ML Engineer designs and creates scalable, performant solutions.\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<raw> > llm:ChatVertexAI] [2.86s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"\",\n",
      "        \"generation_info\": {\n",
      "          \"is_blocked\": false,\n",
      "          \"safety_ratings\": [\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
      "              \"probability_label\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
      "              \"probability_label\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
      "              \"probability_label\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
      "              \"probability_label\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            }\n",
      "          ],\n",
      "          \"citation_metadata\": null,\n",
      "          \"usage_metadata\": {\n",
      "            \"prompt_token_count\": 380,\n",
      "            \"candidates_token_count\": 46,\n",
      "            \"total_token_count\": 426\n",
      "          }\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"function_call\": {\n",
      "                \"name\": \"DynamicGraph\",\n",
      "                \"arguments\": \"{\\\"relationships\\\": [{\\\"target_node_type\\\": \\\"Concept\\\", \\\"source_node_type\\\": \\\"Person\\\", \\\"target_node_id\\\": \\\"models\\\", \\\"type\\\": \\\"DESIGNS_AND_CREATES\\\", \\\"source_node_id\\\": \\\"ML Engineer\\\"}], \\\"nodes\\\": [{\\\"type\\\": \\\"Person\\\", \\\"id\\\": \\\"ML Engineer\\\"}, {\\\"type\\\": \\\"Concept\\\", \\\"id\\\": \\\"models\\\"}]}\"\n",
      "              }\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"is_blocked\": false,\n",
      "              \"safety_ratings\": [\n",
      "                {\n",
      "                  \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
      "                  \"probability_label\": \"NEGLIGIBLE\",\n",
      "                  \"blocked\": false\n",
      "                },\n",
      "                {\n",
      "                  \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
      "                  \"probability_label\": \"NEGLIGIBLE\",\n",
      "                  \"blocked\": false\n",
      "                },\n",
      "                {\n",
      "                  \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
      "                  \"probability_label\": \"NEGLIGIBLE\",\n",
      "                  \"blocked\": false\n",
      "                },\n",
      "                {\n",
      "                  \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
      "                  \"probability_label\": \"NEGLIGIBLE\",\n",
      "                  \"blocked\": false\n",
      "                }\n",
      "              ],\n",
      "              \"citation_metadata\": null,\n",
      "              \"usage_metadata\": {\n",
      "                \"prompt_token_count\": 380,\n",
      "                \"candidates_token_count\": 46,\n",
      "                \"total_token_count\": 426\n",
      "              }\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-bcda3cc4-bfc0-4eff-acf0-b979c09b8718-0\",\n",
      "            \"tool_calls\": [\n",
      "              {\n",
      "                \"name\": \"DynamicGraph\",\n",
      "                \"args\": {\n",
      "                  \"relationships\": [\n",
      "                    {\n",
      "                      \"target_node_type\": \"Concept\",\n",
      "                      \"source_node_type\": \"Person\",\n",
      "                      \"target_node_id\": \"models\",\n",
      "                      \"type\": \"DESIGNS_AND_CREATES\",\n",
      "                      \"source_node_id\": \"ML Engineer\"\n",
      "                    }\n",
      "                  ],\n",
      "                  \"nodes\": [\n",
      "                    {\n",
      "                      \"type\": \"Person\",\n",
      "                      \"id\": \"ML Engineer\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"Concept\",\n",
      "                      \"id\": \"models\"\n",
      "                    }\n",
      "                  ]\n",
      "                },\n",
      "                \"id\": \"c208c493-e73c-414b-b3e6-369946726cd4\"\n",
      "              }\n",
      "            ],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<raw>] [2.86s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence > chain:RunnableLambda] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence > parser:PydanticToolsParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence > parser:PydanticToolsParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence] [2ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableLambda] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error>] [5ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error>] [7ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks] [11ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [2.88s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"Note: The exam does not directly assess coding skill. If you have a minimum proficiency in Python and Cloud SQL, you should be able to interpret any questions with code snippets.\\nRegister now\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"Note: The exam does not directly assess coding skill. If you have a minimum proficiency in Python and Cloud SQL, you should be able to interpret any questions with code snippets.\\nRegister now\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<raw>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<raw> > llm:ChatVertexAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: Extract all Entities\\nHuman: Tip: Make sure to answer in the correct format and do not include any explanations. Use the given format to extract information from the following input: Note: The exam does not directly assess coding skill. If you have a minimum proficiency in Python and Cloud SQL, you should be able to interpret any questions with code snippets.\\nRegister now\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<raw> > llm:ChatVertexAI] [1.43s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"\",\n",
      "        \"generation_info\": {\n",
      "          \"is_blocked\": false,\n",
      "          \"safety_ratings\": [\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
      "              \"probability_label\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
      "              \"probability_label\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
      "              \"probability_label\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
      "              \"probability_label\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            }\n",
      "          ],\n",
      "          \"citation_metadata\": null,\n",
      "          \"usage_metadata\": {\n",
      "            \"prompt_token_count\": 398,\n",
      "            \"candidates_token_count\": 4,\n",
      "            \"total_token_count\": 402\n",
      "          }\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"function_call\": {\n",
      "                \"name\": \"DynamicGraph\",\n",
      "                \"arguments\": \"{\\\"nodes\\\": [], \\\"relationships\\\": []}\"\n",
      "              }\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"is_blocked\": false,\n",
      "              \"safety_ratings\": [\n",
      "                {\n",
      "                  \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
      "                  \"probability_label\": \"NEGLIGIBLE\",\n",
      "                  \"blocked\": false\n",
      "                },\n",
      "                {\n",
      "                  \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
      "                  \"probability_label\": \"NEGLIGIBLE\",\n",
      "                  \"blocked\": false\n",
      "                },\n",
      "                {\n",
      "                  \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
      "                  \"probability_label\": \"NEGLIGIBLE\",\n",
      "                  \"blocked\": false\n",
      "                },\n",
      "                {\n",
      "                  \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
      "                  \"probability_label\": \"NEGLIGIBLE\",\n",
      "                  \"blocked\": false\n",
      "                }\n",
      "              ],\n",
      "              \"citation_metadata\": null,\n",
      "              \"usage_metadata\": {\n",
      "                \"prompt_token_count\": 398,\n",
      "                \"candidates_token_count\": 4,\n",
      "                \"total_token_count\": 402\n",
      "              }\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-08359e08-1636-4a74-be99-b1bbe15d0b0f-0\",\n",
      "            \"tool_calls\": [\n",
      "              {\n",
      "                \"name\": \"DynamicGraph\",\n",
      "                \"args\": {\n",
      "                  \"nodes\": [],\n",
      "                  \"relationships\": []\n",
      "                },\n",
      "                \"id\": \"d78bba69-6df6-4466-81d2-f2aa73ac8c6a\"\n",
      "              }\n",
      "            ],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<raw>] [1.43s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence > chain:RunnableLambda] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence > parser:PydanticToolsParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence > parser:PydanticToolsParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence] [2ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableLambda] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error>] [7ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error>] [10ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks] [19ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [1.47s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"The Professional Machine Learning Engineer exam does not cover generative AI, as the tools used to develop generative AI-based solutions are evolving quickly. If you are interested in generative AI, please refer to the Introduction to Generative AI Learning Path (all audiences) or the Generative AI for Developers Learning Path (technical audience). If you are a partner, please refer to the Gen AI partner courses: Introduction to Generative AI Learning Path, Generative AI for ML Engineers, and Generative AI\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"The Professional Machine Learning Engineer exam does not cover generative AI, as the tools used to develop generative AI-based solutions are evolving quickly. If you are interested in generative AI, please refer to the Introduction to Generative AI Learning Path (all audiences) or the Generative AI for Developers Learning Path (technical audience). If you are a partner, please refer to the Gen AI partner courses: Introduction to Generative AI Learning Path, Generative AI for ML Engineers, and Generative AI\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<raw>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<raw> > llm:ChatVertexAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: Extract all Entities\\nHuman: Tip: Make sure to answer in the correct format and do not include any explanations. Use the given format to extract information from the following input: The Professional Machine Learning Engineer exam does not cover generative AI, as the tools used to develop generative AI-based solutions are evolving quickly. If you are interested in generative AI, please refer to the Introduction to Generative AI Learning Path (all audiences) or the Generative AI for Developers Learning Path (technical audience). If you are a partner, please refer to the Gen AI partner courses: Introduction to Generative AI Learning Path, Generative AI for ML Engineers, and Generative AI\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<raw> > llm:ChatVertexAI] [1.09s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"\",\n",
      "        \"generation_info\": {\n",
      "          \"is_blocked\": false,\n",
      "          \"safety_ratings\": [\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
      "              \"probability_label\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
      "              \"probability_label\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
      "              \"probability_label\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
      "              \"probability_label\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            }\n",
      "          ],\n",
      "          \"citation_metadata\": null,\n",
      "          \"usage_metadata\": {\n",
      "            \"prompt_token_count\": 457,\n",
      "            \"candidates_token_count\": 4,\n",
      "            \"total_token_count\": 461\n",
      "          }\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"function_call\": {\n",
      "                \"name\": \"DynamicGraph\",\n",
      "                \"arguments\": \"{\\\"nodes\\\": [], \\\"relationships\\\": []}\"\n",
      "              }\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"is_blocked\": false,\n",
      "              \"safety_ratings\": [\n",
      "                {\n",
      "                  \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
      "                  \"probability_label\": \"NEGLIGIBLE\",\n",
      "                  \"blocked\": false\n",
      "                },\n",
      "                {\n",
      "                  \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
      "                  \"probability_label\": \"NEGLIGIBLE\",\n",
      "                  \"blocked\": false\n",
      "                },\n",
      "                {\n",
      "                  \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
      "                  \"probability_label\": \"NEGLIGIBLE\",\n",
      "                  \"blocked\": false\n",
      "                },\n",
      "                {\n",
      "                  \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
      "                  \"probability_label\": \"NEGLIGIBLE\",\n",
      "                  \"blocked\": false\n",
      "                }\n",
      "              ],\n",
      "              \"citation_metadata\": null,\n",
      "              \"usage_metadata\": {\n",
      "                \"prompt_token_count\": 457,\n",
      "                \"candidates_token_count\": 4,\n",
      "                \"total_token_count\": 461\n",
      "              }\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-5c648920-5de9-4f52-b484-9da16bc9962c-0\",\n",
      "            \"tool_calls\": [\n",
      "              {\n",
      "                \"name\": \"DynamicGraph\",\n",
      "                \"args\": {\n",
      "                  \"nodes\": [],\n",
      "                  \"relationships\": []\n",
      "                },\n",
      "                \"id\": \"705e4db2-a536-41e3-a5f9-41b6e3b7463e\"\n",
      "              }\n",
      "            ],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<raw>] [1.09s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence > chain:RunnableLambda] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence > parser:PydanticToolsParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence > parser:PydanticToolsParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence] [2ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableLambda] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error>] [7ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error>] [11ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks] [15ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [1.12s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"and Generative AI for Developers.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"and Generative AI for Developers.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<raw>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<raw> > llm:ChatVertexAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: Extract all Entities\\nHuman: Tip: Make sure to answer in the correct format and do not include any explanations. Use the given format to extract information from the following input: and Generative AI for Developers.\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<raw> > llm:ChatVertexAI] [4.75s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"\",\n",
      "        \"generation_info\": {\n",
      "          \"is_blocked\": false,\n",
      "          \"safety_ratings\": [\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
      "              \"probability_label\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
      "              \"probability_label\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
      "              \"probability_label\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
      "              \"probability_label\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            }\n",
      "          ],\n",
      "          \"citation_metadata\": null,\n",
      "          \"usage_metadata\": {\n",
      "            \"prompt_token_count\": 367,\n",
      "            \"candidates_token_count\": 84,\n",
      "            \"total_token_count\": 451\n",
      "          }\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"function_call\": {\n",
      "                \"name\": \"DynamicGraph\",\n",
      "                \"arguments\": \"{\\\"nodes\\\": [{\\\"type\\\": \\\"Book\\\", \\\"id\\\": \\\"Generative AI for Developers\\\"}, {\\\"type\\\": \\\"Book\\\", \\\"id\\\": \\\"Book\\\"}, {\\\"type\\\": \\\"Topic\\\", \\\"id\\\": \\\"Generative AI\\\"}], \\\"relationships\\\": [{\\\"source_node_type\\\": \\\"Book\\\", \\\"type\\\": \\\"INSTANCE_OF\\\", \\\"target_node_id\\\": \\\"Book\\\", \\\"target_node_type\\\": \\\"Book\\\", \\\"source_node_id\\\": \\\"Generative AI for Developers\\\"}, {\\\"type\\\": \\\"CONCERNING\\\", \\\"source_node_type\\\": \\\"Book\\\", \\\"source_node_id\\\": \\\"Book\\\", \\\"target_node_id\\\": \\\"Generative AI\\\", \\\"target_node_type\\\": \\\"Topic\\\"}]}\"\n",
      "              }\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"is_blocked\": false,\n",
      "              \"safety_ratings\": [\n",
      "                {\n",
      "                  \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
      "                  \"probability_label\": \"NEGLIGIBLE\",\n",
      "                  \"blocked\": false\n",
      "                },\n",
      "                {\n",
      "                  \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
      "                  \"probability_label\": \"NEGLIGIBLE\",\n",
      "                  \"blocked\": false\n",
      "                },\n",
      "                {\n",
      "                  \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
      "                  \"probability_label\": \"NEGLIGIBLE\",\n",
      "                  \"blocked\": false\n",
      "                },\n",
      "                {\n",
      "                  \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
      "                  \"probability_label\": \"NEGLIGIBLE\",\n",
      "                  \"blocked\": false\n",
      "                }\n",
      "              ],\n",
      "              \"citation_metadata\": null,\n",
      "              \"usage_metadata\": {\n",
      "                \"prompt_token_count\": 367,\n",
      "                \"candidates_token_count\": 84,\n",
      "                \"total_token_count\": 451\n",
      "              }\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-cde182c0-abff-4eac-85b9-3a56e9a92f6b-0\",\n",
      "            \"tool_calls\": [\n",
      "              {\n",
      "                \"name\": \"DynamicGraph\",\n",
      "                \"args\": {\n",
      "                  \"nodes\": [\n",
      "                    {\n",
      "                      \"type\": \"Book\",\n",
      "                      \"id\": \"Generative AI for Developers\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"Book\",\n",
      "                      \"id\": \"Book\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"Topic\",\n",
      "                      \"id\": \"Generative AI\"\n",
      "                    }\n",
      "                  ],\n",
      "                  \"relationships\": [\n",
      "                    {\n",
      "                      \"source_node_type\": \"Book\",\n",
      "                      \"type\": \"INSTANCE_OF\",\n",
      "                      \"target_node_id\": \"Book\",\n",
      "                      \"target_node_type\": \"Book\",\n",
      "                      \"source_node_id\": \"Generative AI for Developers\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"CONCERNING\",\n",
      "                      \"source_node_type\": \"Book\",\n",
      "                      \"source_node_id\": \"Book\",\n",
      "                      \"target_node_id\": \"Generative AI\",\n",
      "                      \"target_node_type\": \"Topic\"\n",
      "                    }\n",
      "                  ]\n",
      "                },\n",
      "                \"id\": \"2871d0a9-7d64-43a1-afab-7113316147a1\"\n",
      "              }\n",
      "            ],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<raw>] [4.75s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence > chain:RunnableLambda] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence > parser:PydanticToolsParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence > parser:PydanticToolsParser] [1ms] Exiting Parser run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence] [2ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableLambda] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error>] [6ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error>] [9ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks] [15ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [4.78s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"Section 1: Architecting low-code ML solutions (~12% of the exam)\\n1.1 Developing ML models by using BigQuery ML. Considerations include:\\nBuilding the appropriate BigQuery ML model (e.g., linear and binary classification, regression, time-series, matrix factorization, boosted trees, autoencoders) based on the business problem\\nFeature engineering or selection by using BigQuery ML\\nGenerating predictions by using BigQuery ML\\n1.2 Building AI solutions by using ML APIs. Considerations include:\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"Section 1: Architecting low-code ML solutions (~12% of the exam)\\n1.1 Developing ML models by using BigQuery ML. Considerations include:\\nBuilding the appropriate BigQuery ML model (e.g., linear and binary classification, regression, time-series, matrix factorization, boosted trees, autoencoders) based on the business problem\\nFeature engineering or selection by using BigQuery ML\\nGenerating predictions by using BigQuery ML\\n1.2 Building AI solutions by using ML APIs. Considerations include:\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<raw>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<raw> > llm:ChatVertexAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: Extract all Entities\\nHuman: Tip: Make sure to answer in the correct format and do not include any explanations. Use the given format to extract information from the following input: Section 1: Architecting low-code ML solutions (~12% of the exam)\\n1.1 Developing ML models by using BigQuery ML. Considerations include:\\nBuilding the appropriate BigQuery ML model (e.g., linear and binary classification, regression, time-series, matrix factorization, boosted trees, autoencoders) based on the business problem\\nFeature engineering or selection by using BigQuery ML\\nGenerating predictions by using BigQuery ML\\n1.2 Building AI solutions by using ML APIs. Considerations include:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<raw> > llm:ChatVertexAI] [3.25s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"\",\n",
      "        \"generation_info\": {\n",
      "          \"is_blocked\": false,\n",
      "          \"safety_ratings\": [\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
      "              \"probability_label\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
      "              \"probability_label\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
      "              \"probability_label\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
      "              \"probability_label\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            }\n",
      "          ],\n",
      "          \"citation_metadata\": null,\n",
      "          \"usage_metadata\": {\n",
      "            \"prompt_token_count\": 467,\n",
      "            \"candidates_token_count\": 181,\n",
      "            \"total_token_count\": 648\n",
      "          }\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"function_call\": {\n",
      "                \"name\": \"DynamicGraph\",\n",
      "                \"arguments\": \"{\\\"relationships\\\": [{\\\"target_node_type\\\": \\\"ML Model\\\", \\\"type\\\": \\\"HAS\\\", \\\"target_node_id\\\": \\\"linear and binary classification, regression, time-series, matrix factorization, boosted trees, autoencoders\\\", \\\"source_node_type\\\": \\\"Cloud ML platform service\\\", \\\"source_node_id\\\": \\\"BigQuery ML\\\"}, {\\\"target_node_id\\\": \\\"Feature engineering or selection\\\", \\\"source_node_type\\\": \\\"ML Model\\\", \\\"source_node_id\\\": \\\"linear and binary classification, regression, time-series, matrix factorization, boosted trees, autoencoders\\\", \\\"target_node_type\\\": \\\"Data Mining\\\", \\\"type\\\": \\\"REQUIRES\\\"}, {\\\"source_node_id\\\": \\\"Feature engineering or selection\\\", \\\"source_node_type\\\": \\\"Data Mining\\\", \\\"type\\\": \\\"PRODUCES\\\", \\\"target_node_type\\\": \\\"Results\\\", \\\"target_node_id\\\": \\\"Predictions\\\"}], \\\"nodes\\\": [{\\\"type\\\": \\\"Cloud ML platform service\\\", \\\"id\\\": \\\"BigQuery ML\\\"}, {\\\"id\\\": \\\"linear and binary classification, regression, time-series, matrix factorization, boosted trees, autoencoders\\\", \\\"type\\\": \\\"ML Model\\\"}, {\\\"type\\\": \\\"Data Mining\\\", \\\"id\\\": \\\"Feature engineering or selection\\\"}, {\\\"id\\\": \\\"Predictions\\\", \\\"type\\\": \\\"Results\\\"}]}\"\n",
      "              }\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"is_blocked\": false,\n",
      "              \"safety_ratings\": [\n",
      "                {\n",
      "                  \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
      "                  \"probability_label\": \"NEGLIGIBLE\",\n",
      "                  \"blocked\": false\n",
      "                },\n",
      "                {\n",
      "                  \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
      "                  \"probability_label\": \"NEGLIGIBLE\",\n",
      "                  \"blocked\": false\n",
      "                },\n",
      "                {\n",
      "                  \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
      "                  \"probability_label\": \"NEGLIGIBLE\",\n",
      "                  \"blocked\": false\n",
      "                },\n",
      "                {\n",
      "                  \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
      "                  \"probability_label\": \"NEGLIGIBLE\",\n",
      "                  \"blocked\": false\n",
      "                }\n",
      "              ],\n",
      "              \"citation_metadata\": null,\n",
      "              \"usage_metadata\": {\n",
      "                \"prompt_token_count\": 467,\n",
      "                \"candidates_token_count\": 181,\n",
      "                \"total_token_count\": 648\n",
      "              }\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-de95370c-1c94-464d-b105-057e57f2f78e-0\",\n",
      "            \"tool_calls\": [\n",
      "              {\n",
      "                \"name\": \"DynamicGraph\",\n",
      "                \"args\": {\n",
      "                  \"relationships\": [\n",
      "                    {\n",
      "                      \"target_node_type\": \"ML Model\",\n",
      "                      \"type\": \"HAS\",\n",
      "                      \"target_node_id\": \"linear and binary classification, regression, time-series, matrix factorization, boosted trees, autoencoders\",\n",
      "                      \"source_node_type\": \"Cloud ML platform service\",\n",
      "                      \"source_node_id\": \"BigQuery ML\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"target_node_id\": \"Feature engineering or selection\",\n",
      "                      \"source_node_type\": \"ML Model\",\n",
      "                      \"source_node_id\": \"linear and binary classification, regression, time-series, matrix factorization, boosted trees, autoencoders\",\n",
      "                      \"target_node_type\": \"Data Mining\",\n",
      "                      \"type\": \"REQUIRES\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"source_node_id\": \"Feature engineering or selection\",\n",
      "                      \"source_node_type\": \"Data Mining\",\n",
      "                      \"type\": \"PRODUCES\",\n",
      "                      \"target_node_type\": \"Results\",\n",
      "                      \"target_node_id\": \"Predictions\"\n",
      "                    }\n",
      "                  ],\n",
      "                  \"nodes\": [\n",
      "                    {\n",
      "                      \"type\": \"Cloud ML platform service\",\n",
      "                      \"id\": \"BigQuery ML\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"linear and binary classification, regression, time-series, matrix factorization, boosted trees, autoencoders\",\n",
      "                      \"type\": \"ML Model\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"Data Mining\",\n",
      "                      \"id\": \"Feature engineering or selection\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"Predictions\",\n",
      "                      \"type\": \"Results\"\n",
      "                    }\n",
      "                  ]\n",
      "                },\n",
      "                \"id\": \"c5eb3637-30c1-417f-9a5e-86540ae6df55\"\n",
      "              }\n",
      "            ],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<raw>] [3.25s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence > chain:RunnableLambda] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence > parser:PydanticToolsParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence > parser:PydanticToolsParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence] [3ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableLambda] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error>] [6ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error>] [8ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks] [12ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [3.27s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"Building applications by using ML APIs (e.g., Cloud Vision API, Natural Language API, Cloud Speech API, Translation)\\nBuilding applications by using industry-specific APIs (e.g., Document AI API, Retail API)\\n1.3 Training models by using AutoML. Considerations include:\\nPreparing data for AutoML (e.g., feature selection, data labeling, Tabular Workflows on AutoML)\\nUsing available data (e.g., tabular, text, speech, images, videos) to train custom models\\nUsing AutoML for tabular data\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"Building applications by using ML APIs (e.g., Cloud Vision API, Natural Language API, Cloud Speech API, Translation)\\nBuilding applications by using industry-specific APIs (e.g., Document AI API, Retail API)\\n1.3 Training models by using AutoML. Considerations include:\\nPreparing data for AutoML (e.g., feature selection, data labeling, Tabular Workflows on AutoML)\\nUsing available data (e.g., tabular, text, speech, images, videos) to train custom models\\nUsing AutoML for tabular data\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<raw>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<raw> > llm:ChatVertexAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: Extract all Entities\\nHuman: Tip: Make sure to answer in the correct format and do not include any explanations. Use the given format to extract information from the following input: Building applications by using ML APIs (e.g., Cloud Vision API, Natural Language API, Cloud Speech API, Translation)\\nBuilding applications by using industry-specific APIs (e.g., Document AI API, Retail API)\\n1.3 Training models by using AutoML. Considerations include:\\nPreparing data for AutoML (e.g., feature selection, data labeling, Tabular Workflows on AutoML)\\nUsing available data (e.g., tabular, text, speech, images, videos) to train custom models\\nUsing AutoML for tabular data\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<raw> > llm:ChatVertexAI] [10.39s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"\",\n",
      "        \"generation_info\": {\n",
      "          \"is_blocked\": false,\n",
      "          \"safety_ratings\": [\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
      "              \"probability_label\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
      "              \"probability_label\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
      "              \"probability_label\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
      "              \"probability_label\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            }\n",
      "          ],\n",
      "          \"citation_metadata\": null,\n",
      "          \"usage_metadata\": {\n",
      "            \"prompt_token_count\": 475,\n",
      "            \"candidates_token_count\": 684,\n",
      "            \"total_token_count\": 1159\n",
      "          }\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"function_call\": {\n",
      "                \"name\": \"DynamicGraph\",\n",
      "                \"arguments\": \"{\\\"nodes\\\": [{\\\"type\\\": \\\"Technology\\\", \\\"id\\\": \\\"ML APIs\\\"}, {\\\"id\\\": \\\"Cloud Vision API\\\", \\\"type\\\": \\\"Technology\\\"}, {\\\"id\\\": \\\"Natural Language API\\\", \\\"type\\\": \\\"Technology\\\"}, {\\\"id\\\": \\\"Cloud Speech API\\\", \\\"type\\\": \\\"Technology\\\"}, {\\\"id\\\": \\\"Translation\\\", \\\"type\\\": \\\"Technology\\\"}, {\\\"type\\\": \\\"Technology\\\", \\\"id\\\": \\\"Industry-specific APIs\\\"}, {\\\"id\\\": \\\"Document AI API\\\", \\\"type\\\": \\\"Technology\\\"}, {\\\"id\\\": \\\"Retail API\\\", \\\"type\\\": \\\"Technology\\\"}, {\\\"id\\\": \\\"AutoML\\\", \\\"type\\\": \\\"Technology\\\"}, {\\\"type\\\": \\\"Technology\\\", \\\"id\\\": \\\"Training Models\\\"}, {\\\"id\\\": \\\"Feature Selection\\\", \\\"type\\\": \\\"Technology\\\"}, {\\\"id\\\": \\\"Data Labeling\\\", \\\"type\\\": \\\"Technology\\\"}, {\\\"type\\\": \\\"Technology\\\", \\\"id\\\": \\\"Tabular Workflows on AutoML\\\"}, {\\\"id\\\": \\\"Data\\\", \\\"type\\\": \\\"Data\\\"}, {\\\"type\\\": \\\"Data\\\", \\\"id\\\": \\\"Tabular\\\"}, {\\\"id\\\": \\\"Text\\\", \\\"type\\\": \\\"Data\\\"}, {\\\"id\\\": \\\"Speech\\\", \\\"type\\\": \\\"Data\\\"}, {\\\"id\\\": \\\"Images\\\", \\\"type\\\": \\\"Data\\\"}, {\\\"type\\\": \\\"Data\\\", \\\"id\\\": \\\"Videos\\\"}, {\\\"id\\\": \\\"Custom Models\\\", \\\"type\\\": \\\"Technology\\\"}], \\\"relationships\\\": [{\\\"type\\\": \\\"USED\\\", \\\"target_node_type\\\": \\\"Technology\\\", \\\"source_node_id\\\": \\\"Building applications\\\", \\\"target_node_id\\\": \\\"ML APIs\\\", \\\"source_node_type\\\": \\\"Task\\\"}, {\\\"source_node_id\\\": \\\"ML APIs\\\", \\\"target_node_type\\\": \\\"Technology\\\", \\\"type\\\": \\\"EXAMPLE\\\", \\\"target_node_id\\\": \\\"Cloud Vision API\\\", \\\"source_node_type\\\": \\\"Technology\\\"}, {\\\"source_node_id\\\": \\\"ML APIs\\\", \\\"target_node_type\\\": \\\"Technology\\\", \\\"target_node_id\\\": \\\"Natural Language API\\\", \\\"type\\\": \\\"EXAMPLE\\\", \\\"source_node_type\\\": \\\"Technology\\\"}, {\\\"source_node_id\\\": \\\"ML APIs\\\", \\\"target_node_type\\\": \\\"Technology\\\", \\\"type\\\": \\\"EXAMPLE\\\", \\\"source_node_type\\\": \\\"Technology\\\", \\\"target_node_id\\\": \\\"Cloud Speech API\\\"}, {\\\"source_node_type\\\": \\\"Technology\\\", \\\"source_node_id\\\": \\\"ML APIs\\\", \\\"target_node_id\\\": \\\"Translation\\\", \\\"target_node_type\\\": \\\"Technology\\\", \\\"type\\\": \\\"EXAMPLE\\\"}, {\\\"source_node_id\\\": \\\"Building applications\\\", \\\"target_node_type\\\": \\\"Technology\\\", \\\"type\\\": \\\"USED\\\", \\\"target_node_id\\\": \\\"Industry-specific APIs\\\", \\\"source_node_type\\\": \\\"Task\\\"}, {\\\"source_node_type\\\": \\\"Technology\\\", \\\"target_node_id\\\": \\\"Document AI API\\\", \\\"target_node_type\\\": \\\"Technology\\\", \\\"source_node_id\\\": \\\"Industry-specific APIs\\\", \\\"type\\\": \\\"EXAMPLE\\\"}, {\\\"target_node_id\\\": \\\"Retail API\\\", \\\"source_node_type\\\": \\\"Technology\\\", \\\"target_node_type\\\": \\\"Technology\\\", \\\"source_node_id\\\": \\\"Industry-specific APIs\\\", \\\"type\\\": \\\"EXAMPLE\\\"}, {\\\"type\\\": \\\"USED\\\", \\\"target_node_id\\\": \\\"AutoML\\\", \\\"source_node_type\\\": \\\"Task\\\", \\\"target_node_type\\\": \\\"Technology\\\", \\\"source_node_id\\\": \\\"1.3 Training models by using AutoML.\\\"}, {\\\"source_node_type\\\": \\\"Technology\\\", \\\"type\\\": \\\"EXAMPLE\\\", \\\"source_node_id\\\": \\\"AutoML\\\", \\\"target_node_type\\\": \\\"Technology\\\", \\\"target_node_id\\\": \\\"Training Models\\\"}, {\\\"source_node_type\\\": \\\"Technology\\\", \\\"type\\\": \\\"SUBTASK\\\", \\\"target_node_id\\\": \\\"Feature Selection\\\", \\\"source_node_id\\\": \\\"Training Models\\\", \\\"target_node_type\\\": \\\"Technology\\\"}, {\\\"source_node_type\\\": \\\"Technology\\\", \\\"type\\\": \\\"SUBTASK\\\", \\\"source_node_id\\\": \\\"Training Models\\\", \\\"target_node_type\\\": \\\"Technology\\\", \\\"target_node_id\\\": \\\"Data Labeling\\\"}, {\\\"source_node_id\\\": \\\"Training Models\\\", \\\"type\\\": \\\"SUBTASK\\\", \\\"target_node_id\\\": \\\"Tabular Workflows on AutoML\\\", \\\"target_node_type\\\": \\\"Technology\\\", \\\"source_node_type\\\": \\\"Technology\\\"}, {\\\"source_node_id\\\": \\\"Training Models\\\", \\\"target_node_type\\\": \\\"Data\\\", \\\"target_node_id\\\": \\\"Data\\\", \\\"type\\\": \\\"INPUT\\\", \\\"source_node_type\\\": \\\"Technology\\\"}, {\\\"target_node_id\\\": \\\"Tabular\\\", \\\"target_node_type\\\": \\\"Data\\\", \\\"source_node_id\\\": \\\"Data\\\", \\\"source_node_type\\\": \\\"Data\\\", \\\"type\\\": \\\"TYPE\\\"}, {\\\"target_node_id\\\": \\\"Text\\\", \\\"target_node_type\\\": \\\"Data\\\", \\\"source_node_id\\\": \\\"Data\\\", \\\"type\\\": \\\"TYPE\\\", \\\"source_node_type\\\": \\\"Data\\\"}, {\\\"source_node_type\\\": \\\"Data\\\", \\\"target_node_type\\\": \\\"Data\\\", \\\"type\\\": \\\"TYPE\\\", \\\"target_node_id\\\": \\\"Speech\\\", \\\"source_node_id\\\": \\\"Data\\\"}, {\\\"type\\\": \\\"TYPE\\\", \\\"source_node_id\\\": \\\"Data\\\", \\\"target_node_type\\\": \\\"Data\\\", \\\"source_node_type\\\": \\\"Data\\\", \\\"target_node_id\\\": \\\"Images\\\"}, {\\\"source_node_id\\\": \\\"Data\\\", \\\"source_node_type\\\": \\\"Data\\\", \\\"target_node_id\\\": \\\"Videos\\\", \\\"target_node_type\\\": \\\"Data\\\", \\\"type\\\": \\\"TYPE\\\"}, {\\\"source_node_id\\\": \\\"Training Models\\\", \\\"source_node_type\\\": \\\"Technology\\\", \\\"target_node_id\\\": \\\"Custom Models\\\", \\\"target_node_type\\\": \\\"Technology\\\", \\\"type\\\": \\\"OUTPUT\\\"}]}\"\n",
      "              }\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"is_blocked\": false,\n",
      "              \"safety_ratings\": [\n",
      "                {\n",
      "                  \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
      "                  \"probability_label\": \"NEGLIGIBLE\",\n",
      "                  \"blocked\": false\n",
      "                },\n",
      "                {\n",
      "                  \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
      "                  \"probability_label\": \"NEGLIGIBLE\",\n",
      "                  \"blocked\": false\n",
      "                },\n",
      "                {\n",
      "                  \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
      "                  \"probability_label\": \"NEGLIGIBLE\",\n",
      "                  \"blocked\": false\n",
      "                },\n",
      "                {\n",
      "                  \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
      "                  \"probability_label\": \"NEGLIGIBLE\",\n",
      "                  \"blocked\": false\n",
      "                }\n",
      "              ],\n",
      "              \"citation_metadata\": null,\n",
      "              \"usage_metadata\": {\n",
      "                \"prompt_token_count\": 475,\n",
      "                \"candidates_token_count\": 684,\n",
      "                \"total_token_count\": 1159\n",
      "              }\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-38894d9f-9740-452a-8cf5-a6b666dcc8c4-0\",\n",
      "            \"tool_calls\": [\n",
      "              {\n",
      "                \"name\": \"DynamicGraph\",\n",
      "                \"args\": {\n",
      "                  \"nodes\": [\n",
      "                    {\n",
      "                      \"type\": \"Technology\",\n",
      "                      \"id\": \"ML APIs\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"Cloud Vision API\",\n",
      "                      \"type\": \"Technology\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"Natural Language API\",\n",
      "                      \"type\": \"Technology\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"Cloud Speech API\",\n",
      "                      \"type\": \"Technology\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"Translation\",\n",
      "                      \"type\": \"Technology\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"Technology\",\n",
      "                      \"id\": \"Industry-specific APIs\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"Document AI API\",\n",
      "                      \"type\": \"Technology\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"Retail API\",\n",
      "                      \"type\": \"Technology\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"AutoML\",\n",
      "                      \"type\": \"Technology\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"Technology\",\n",
      "                      \"id\": \"Training Models\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"Feature Selection\",\n",
      "                      \"type\": \"Technology\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"Data Labeling\",\n",
      "                      \"type\": \"Technology\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"Technology\",\n",
      "                      \"id\": \"Tabular Workflows on AutoML\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"Data\",\n",
      "                      \"type\": \"Data\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"Data\",\n",
      "                      \"id\": \"Tabular\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"Text\",\n",
      "                      \"type\": \"Data\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"Speech\",\n",
      "                      \"type\": \"Data\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"Images\",\n",
      "                      \"type\": \"Data\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"Data\",\n",
      "                      \"id\": \"Videos\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"Custom Models\",\n",
      "                      \"type\": \"Technology\"\n",
      "                    }\n",
      "                  ],\n",
      "                  \"relationships\": [\n",
      "                    {\n",
      "                      \"type\": \"USED\",\n",
      "                      \"target_node_type\": \"Technology\",\n",
      "                      \"source_node_id\": \"Building applications\",\n",
      "                      \"target_node_id\": \"ML APIs\",\n",
      "                      \"source_node_type\": \"Task\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"source_node_id\": \"ML APIs\",\n",
      "                      \"target_node_type\": \"Technology\",\n",
      "                      \"type\": \"EXAMPLE\",\n",
      "                      \"target_node_id\": \"Cloud Vision API\",\n",
      "                      \"source_node_type\": \"Technology\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"source_node_id\": \"ML APIs\",\n",
      "                      \"target_node_type\": \"Technology\",\n",
      "                      \"target_node_id\": \"Natural Language API\",\n",
      "                      \"type\": \"EXAMPLE\",\n",
      "                      \"source_node_type\": \"Technology\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"source_node_id\": \"ML APIs\",\n",
      "                      \"target_node_type\": \"Technology\",\n",
      "                      \"type\": \"EXAMPLE\",\n",
      "                      \"source_node_type\": \"Technology\",\n",
      "                      \"target_node_id\": \"Cloud Speech API\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"source_node_type\": \"Technology\",\n",
      "                      \"source_node_id\": \"ML APIs\",\n",
      "                      \"target_node_id\": \"Translation\",\n",
      "                      \"target_node_type\": \"Technology\",\n",
      "                      \"type\": \"EXAMPLE\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"source_node_id\": \"Building applications\",\n",
      "                      \"target_node_type\": \"Technology\",\n",
      "                      \"type\": \"USED\",\n",
      "                      \"target_node_id\": \"Industry-specific APIs\",\n",
      "                      \"source_node_type\": \"Task\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"source_node_type\": \"Technology\",\n",
      "                      \"target_node_id\": \"Document AI API\",\n",
      "                      \"target_node_type\": \"Technology\",\n",
      "                      \"source_node_id\": \"Industry-specific APIs\",\n",
      "                      \"type\": \"EXAMPLE\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"target_node_id\": \"Retail API\",\n",
      "                      \"source_node_type\": \"Technology\",\n",
      "                      \"target_node_type\": \"Technology\",\n",
      "                      \"source_node_id\": \"Industry-specific APIs\",\n",
      "                      \"type\": \"EXAMPLE\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"USED\",\n",
      "                      \"target_node_id\": \"AutoML\",\n",
      "                      \"source_node_type\": \"Task\",\n",
      "                      \"target_node_type\": \"Technology\",\n",
      "                      \"source_node_id\": \"1.3 Training models by using AutoML.\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"source_node_type\": \"Technology\",\n",
      "                      \"type\": \"EXAMPLE\",\n",
      "                      \"source_node_id\": \"AutoML\",\n",
      "                      \"target_node_type\": \"Technology\",\n",
      "                      \"target_node_id\": \"Training Models\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"source_node_type\": \"Technology\",\n",
      "                      \"type\": \"SUBTASK\",\n",
      "                      \"target_node_id\": \"Feature Selection\",\n",
      "                      \"source_node_id\": \"Training Models\",\n",
      "                      \"target_node_type\": \"Technology\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"source_node_type\": \"Technology\",\n",
      "                      \"type\": \"SUBTASK\",\n",
      "                      \"source_node_id\": \"Training Models\",\n",
      "                      \"target_node_type\": \"Technology\",\n",
      "                      \"target_node_id\": \"Data Labeling\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"source_node_id\": \"Training Models\",\n",
      "                      \"type\": \"SUBTASK\",\n",
      "                      \"target_node_id\": \"Tabular Workflows on AutoML\",\n",
      "                      \"target_node_type\": \"Technology\",\n",
      "                      \"source_node_type\": \"Technology\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"source_node_id\": \"Training Models\",\n",
      "                      \"target_node_type\": \"Data\",\n",
      "                      \"target_node_id\": \"Data\",\n",
      "                      \"type\": \"INPUT\",\n",
      "                      \"source_node_type\": \"Technology\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"target_node_id\": \"Tabular\",\n",
      "                      \"target_node_type\": \"Data\",\n",
      "                      \"source_node_id\": \"Data\",\n",
      "                      \"source_node_type\": \"Data\",\n",
      "                      \"type\": \"TYPE\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"target_node_id\": \"Text\",\n",
      "                      \"target_node_type\": \"Data\",\n",
      "                      \"source_node_id\": \"Data\",\n",
      "                      \"type\": \"TYPE\",\n",
      "                      \"source_node_type\": \"Data\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"source_node_type\": \"Data\",\n",
      "                      \"target_node_type\": \"Data\",\n",
      "                      \"type\": \"TYPE\",\n",
      "                      \"target_node_id\": \"Speech\",\n",
      "                      \"source_node_id\": \"Data\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"TYPE\",\n",
      "                      \"source_node_id\": \"Data\",\n",
      "                      \"target_node_type\": \"Data\",\n",
      "                      \"source_node_type\": \"Data\",\n",
      "                      \"target_node_id\": \"Images\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"source_node_id\": \"Data\",\n",
      "                      \"source_node_type\": \"Data\",\n",
      "                      \"target_node_id\": \"Videos\",\n",
      "                      \"target_node_type\": \"Data\",\n",
      "                      \"type\": \"TYPE\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"source_node_id\": \"Training Models\",\n",
      "                      \"source_node_type\": \"Technology\",\n",
      "                      \"target_node_id\": \"Custom Models\",\n",
      "                      \"target_node_type\": \"Technology\",\n",
      "                      \"type\": \"OUTPUT\"\n",
      "                    }\n",
      "                  ]\n",
      "                },\n",
      "                \"id\": \"63545d08-241e-4e06-ab7e-2fd3bbfe7fdb\"\n",
      "              }\n",
      "            ],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<raw>] [10.39s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence > chain:RunnableLambda] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence > parser:PydanticToolsParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence > parser:PydanticToolsParser] [1ms] Exiting Parser run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence] [2ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableLambda] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error>] [5ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error>] [8ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks] [11ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [10.41s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"Creating forecasting models using AutoML\\nConfiguring and debugging trained models\\nSection 2: Collaborating within and across teams to manage data and models (~16% of the exam)\\n2.1 Exploring and preprocessing organization-wide data (e.g., Cloud Storage, BigQuery, Spanner, Cloud SQL, Apache Spark, Apache Hadoop). Considerations include:\\nOrganizing different types of data (e.g., tabular, text, speech, images, videos) for efficient training\\nManaging datasets in Vertex AI\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"Creating forecasting models using AutoML\\nConfiguring and debugging trained models\\nSection 2: Collaborating within and across teams to manage data and models (~16% of the exam)\\n2.1 Exploring and preprocessing organization-wide data (e.g., Cloud Storage, BigQuery, Spanner, Cloud SQL, Apache Spark, Apache Hadoop). Considerations include:\\nOrganizing different types of data (e.g., tabular, text, speech, images, videos) for efficient training\\nManaging datasets in Vertex AI\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<raw>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<raw> > llm:ChatVertexAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: Extract all Entities\\nHuman: Tip: Make sure to answer in the correct format and do not include any explanations. Use the given format to extract information from the following input: Creating forecasting models using AutoML\\nConfiguring and debugging trained models\\nSection 2: Collaborating within and across teams to manage data and models (~16% of the exam)\\n2.1 Exploring and preprocessing organization-wide data (e.g., Cloud Storage, BigQuery, Spanner, Cloud SQL, Apache Spark, Apache Hadoop). Considerations include:\\nOrganizing different types of data (e.g., tabular, text, speech, images, videos) for efficient training\\nManaging datasets in Vertex AI\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<raw> > llm:ChatVertexAI] [6.41s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"\",\n",
      "        \"generation_info\": {\n",
      "          \"is_blocked\": false,\n",
      "          \"safety_ratings\": [\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
      "              \"probability_label\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
      "              \"probability_label\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
      "              \"probability_label\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
      "              \"probability_label\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            }\n",
      "          ],\n",
      "          \"citation_metadata\": null,\n",
      "          \"usage_metadata\": {\n",
      "            \"prompt_token_count\": 463,\n",
      "            \"candidates_token_count\": 57,\n",
      "            \"total_token_count\": 520\n",
      "          }\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"function_call\": {\n",
      "                \"name\": \"DynamicGraph\",\n",
      "                \"arguments\": \"{\\\"relationships\\\": [{\\\"target_node_type\\\": \\\"Task\\\", \\\"source_node_type\\\": \\\"Task\\\", \\\"type\\\": \\\"RelatedTask\\\", \\\"source_node_id\\\": \\\"Creating forecasting models using AutoML\\\", \\\"target_node_id\\\": \\\"Configuring and debugging trained models\\\"}], \\\"nodes\\\": [{\\\"id\\\": \\\"Creating forecasting models using AutoML\\\", \\\"type\\\": \\\"Task\\\"}, {\\\"id\\\": \\\"Configuring and debugging trained models\\\", \\\"type\\\": \\\"Task\\\"}]}\"\n",
      "              }\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"is_blocked\": false,\n",
      "              \"safety_ratings\": [\n",
      "                {\n",
      "                  \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
      "                  \"probability_label\": \"NEGLIGIBLE\",\n",
      "                  \"blocked\": false\n",
      "                },\n",
      "                {\n",
      "                  \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
      "                  \"probability_label\": \"NEGLIGIBLE\",\n",
      "                  \"blocked\": false\n",
      "                },\n",
      "                {\n",
      "                  \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
      "                  \"probability_label\": \"NEGLIGIBLE\",\n",
      "                  \"blocked\": false\n",
      "                },\n",
      "                {\n",
      "                  \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
      "                  \"probability_label\": \"NEGLIGIBLE\",\n",
      "                  \"blocked\": false\n",
      "                }\n",
      "              ],\n",
      "              \"citation_metadata\": null,\n",
      "              \"usage_metadata\": {\n",
      "                \"prompt_token_count\": 463,\n",
      "                \"candidates_token_count\": 57,\n",
      "                \"total_token_count\": 520\n",
      "              }\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-5f295358-e492-4b79-a54e-388350f876ad-0\",\n",
      "            \"tool_calls\": [\n",
      "              {\n",
      "                \"name\": \"DynamicGraph\",\n",
      "                \"args\": {\n",
      "                  \"relationships\": [\n",
      "                    {\n",
      "                      \"target_node_type\": \"Task\",\n",
      "                      \"source_node_type\": \"Task\",\n",
      "                      \"type\": \"RelatedTask\",\n",
      "                      \"source_node_id\": \"Creating forecasting models using AutoML\",\n",
      "                      \"target_node_id\": \"Configuring and debugging trained models\"\n",
      "                    }\n",
      "                  ],\n",
      "                  \"nodes\": [\n",
      "                    {\n",
      "                      \"id\": \"Creating forecasting models using AutoML\",\n",
      "                      \"type\": \"Task\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"Configuring and debugging trained models\",\n",
      "                      \"type\": \"Task\"\n",
      "                    }\n",
      "                  ]\n",
      "                },\n",
      "                \"id\": \"97266bec-e2b4-43dc-9ca6-bf88da0c75b9\"\n",
      "              }\n",
      "            ],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<raw>] [6.41s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableLambda] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence > chain:RunnableLambda] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence > parser:PydanticToolsParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence > parser:PydanticToolsParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence] [2ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error>] [5ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error>] [8ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks] [12ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [6.44s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"Data preprocessing (e.g., Dataflow, TensorFlow Extended [TFX], BigQuery)\\nCreating and consolidating features in Vertex AI Feature Store\\nPrivacy implications of data usage and/or collection (e.g., handling sensitive data such as personally identifiable information [PII] and protected health information [PHI])\\n2.2 Model prototyping using Jupyter notebooks. Considerations include:\\nChoosing the appropriate Jupyter backend on Google Cloud (e.g., Vertex AI Workbench, notebooks on Dataproc)\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"Data preprocessing (e.g., Dataflow, TensorFlow Extended [TFX], BigQuery)\\nCreating and consolidating features in Vertex AI Feature Store\\nPrivacy implications of data usage and/or collection (e.g., handling sensitive data such as personally identifiable information [PII] and protected health information [PHI])\\n2.2 Model prototyping using Jupyter notebooks. Considerations include:\\nChoosing the appropriate Jupyter backend on Google Cloud (e.g., Vertex AI Workbench, notebooks on Dataproc)\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<raw>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<raw> > llm:ChatVertexAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: Extract all Entities\\nHuman: Tip: Make sure to answer in the correct format and do not include any explanations. Use the given format to extract information from the following input: Data preprocessing (e.g., Dataflow, TensorFlow Extended [TFX], BigQuery)\\nCreating and consolidating features in Vertex AI Feature Store\\nPrivacy implications of data usage and/or collection (e.g., handling sensitive data such as personally identifiable information [PII] and protected health information [PHI])\\n2.2 Model prototyping using Jupyter notebooks. Considerations include:\\nChoosing the appropriate Jupyter backend on Google Cloud (e.g., Vertex AI Workbench, notebooks on Dataproc)\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<raw> > llm:ChatVertexAI] [5.80s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"\",\n",
      "        \"generation_info\": {\n",
      "          \"is_blocked\": false,\n",
      "          \"safety_ratings\": [\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
      "              \"probability_label\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
      "              \"probability_label\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
      "              \"probability_label\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
      "              \"probability_label\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            }\n",
      "          ],\n",
      "          \"citation_metadata\": null,\n",
      "          \"usage_metadata\": {\n",
      "            \"prompt_token_count\": 460,\n",
      "            \"candidates_token_count\": 362,\n",
      "            \"total_token_count\": 822\n",
      "          }\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"function_call\": {\n",
      "                \"name\": \"DynamicGraph\",\n",
      "                \"arguments\": \"{\\\"nodes\\\": [{\\\"type\\\": \\\"Process\\\", \\\"id\\\": \\\"Data preprocessing\\\"}, {\\\"type\\\": \\\"Tool\\\", \\\"id\\\": \\\"Dataflow\\\"}, {\\\"type\\\": \\\"Tool\\\", \\\"id\\\": \\\"TensorFlow Extended (TFX)\\\"}, {\\\"id\\\": \\\"BigQuery\\\", \\\"type\\\": \\\"Tool\\\"}, {\\\"id\\\": \\\"Vertex AI Feature Store\\\", \\\"type\\\": \\\"Tool\\\"}, {\\\"type\\\": \\\"Process\\\", \\\"id\\\": \\\"Privacy implications of data usage and/or collection\\\"}, {\\\"type\\\": \\\"Process\\\", \\\"id\\\": \\\"Model prototyping\\\"}, {\\\"type\\\": \\\"Tool\\\", \\\"id\\\": \\\"Jupyter notebooks\\\"}, {\\\"type\\\": \\\"Tool\\\", \\\"id\\\": \\\"Vertex AI Workbench\\\"}, {\\\"type\\\": \\\"Tool\\\", \\\"id\\\": \\\"notebooks on Dataproc\\\"}], \\\"relationships\\\": [{\\\"target_node_type\\\": \\\"Tool\\\", \\\"source_node_id\\\": \\\"Data preprocessing\\\", \\\"target_node_id\\\": \\\"Dataflow\\\", \\\"type\\\": \\\"USES\\\", \\\"source_node_type\\\": \\\"Process\\\"}, {\\\"target_node_id\\\": \\\"TensorFlow Extended (TFX)\\\", \\\"source_node_id\\\": \\\"Data preprocessing\\\", \\\"type\\\": \\\"USES\\\", \\\"target_node_type\\\": \\\"Tool\\\", \\\"source_node_type\\\": \\\"Process\\\"}, {\\\"source_node_type\\\": \\\"Process\\\", \\\"target_node_type\\\": \\\"Tool\\\", \\\"type\\\": \\\"USES\\\", \\\"source_node_id\\\": \\\"Data preprocessing\\\", \\\"target_node_id\\\": \\\"BigQuery\\\"}, {\\\"type\\\": \\\"USES\\\", \\\"source_node_id\\\": \\\"Data preprocessing\\\", \\\"target_node_id\\\": \\\"Vertex AI Feature Store\\\", \\\"target_node_type\\\": \\\"Tool\\\", \\\"source_node_type\\\": \\\"Process\\\"}, {\\\"type\\\": \\\"AFFECTS\\\", \\\"source_node_id\\\": \\\"Privacy implications of data usage and/or collection\\\", \\\"source_node_type\\\": \\\"Process\\\", \\\"target_node_type\\\": \\\"Process\\\", \\\"target_node_id\\\": \\\"Data preprocessing\\\"}, {\\\"target_node_id\\\": \\\"Model prototyping\\\", \\\"type\\\": \\\"SUBPROCESS_OF\\\", \\\"source_node_type\\\": \\\"Process\\\", \\\"source_node_id\\\": \\\"2.2 Model prototyping\\\", \\\"target_node_type\\\": \\\"Process\\\"}, {\\\"source_node_type\\\": \\\"Process\\\", \\\"target_node_type\\\": \\\"Tool\\\", \\\"target_node_id\\\": \\\"Jupyter notebooks\\\", \\\"source_node_id\\\": \\\"Model prototyping\\\", \\\"type\\\": \\\"USES\\\"}, {\\\"target_node_type\\\": \\\"Tool\\\", \\\"source_node_type\\\": \\\"Process\\\", \\\"type\\\": \\\"USES\\\", \\\"target_node_id\\\": \\\"Vertex AI Workbench\\\", \\\"source_node_id\\\": \\\"2.2 Model prototyping\\\"}, {\\\"source_node_type\\\": \\\"Process\\\", \\\"target_node_type\\\": \\\"Tool\\\", \\\"source_node_id\\\": \\\"2.2 Model prototyping\\\", \\\"target_node_id\\\": \\\"notebooks on Dataproc\\\", \\\"type\\\": \\\"USES\\\"}]}\"\n",
      "              }\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"is_blocked\": false,\n",
      "              \"safety_ratings\": [\n",
      "                {\n",
      "                  \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
      "                  \"probability_label\": \"NEGLIGIBLE\",\n",
      "                  \"blocked\": false\n",
      "                },\n",
      "                {\n",
      "                  \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
      "                  \"probability_label\": \"NEGLIGIBLE\",\n",
      "                  \"blocked\": false\n",
      "                },\n",
      "                {\n",
      "                  \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
      "                  \"probability_label\": \"NEGLIGIBLE\",\n",
      "                  \"blocked\": false\n",
      "                },\n",
      "                {\n",
      "                  \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
      "                  \"probability_label\": \"NEGLIGIBLE\",\n",
      "                  \"blocked\": false\n",
      "                }\n",
      "              ],\n",
      "              \"citation_metadata\": null,\n",
      "              \"usage_metadata\": {\n",
      "                \"prompt_token_count\": 460,\n",
      "                \"candidates_token_count\": 362,\n",
      "                \"total_token_count\": 822\n",
      "              }\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-57e121a1-2c00-4ffa-ba75-9829c1addee8-0\",\n",
      "            \"tool_calls\": [\n",
      "              {\n",
      "                \"name\": \"DynamicGraph\",\n",
      "                \"args\": {\n",
      "                  \"nodes\": [\n",
      "                    {\n",
      "                      \"type\": \"Process\",\n",
      "                      \"id\": \"Data preprocessing\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"Tool\",\n",
      "                      \"id\": \"Dataflow\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"Tool\",\n",
      "                      \"id\": \"TensorFlow Extended (TFX)\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"BigQuery\",\n",
      "                      \"type\": \"Tool\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"Vertex AI Feature Store\",\n",
      "                      \"type\": \"Tool\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"Process\",\n",
      "                      \"id\": \"Privacy implications of data usage and/or collection\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"Process\",\n",
      "                      \"id\": \"Model prototyping\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"Tool\",\n",
      "                      \"id\": \"Jupyter notebooks\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"Tool\",\n",
      "                      \"id\": \"Vertex AI Workbench\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"Tool\",\n",
      "                      \"id\": \"notebooks on Dataproc\"\n",
      "                    }\n",
      "                  ],\n",
      "                  \"relationships\": [\n",
      "                    {\n",
      "                      \"target_node_type\": \"Tool\",\n",
      "                      \"source_node_id\": \"Data preprocessing\",\n",
      "                      \"target_node_id\": \"Dataflow\",\n",
      "                      \"type\": \"USES\",\n",
      "                      \"source_node_type\": \"Process\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"target_node_id\": \"TensorFlow Extended (TFX)\",\n",
      "                      \"source_node_id\": \"Data preprocessing\",\n",
      "                      \"type\": \"USES\",\n",
      "                      \"target_node_type\": \"Tool\",\n",
      "                      \"source_node_type\": \"Process\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"source_node_type\": \"Process\",\n",
      "                      \"target_node_type\": \"Tool\",\n",
      "                      \"type\": \"USES\",\n",
      "                      \"source_node_id\": \"Data preprocessing\",\n",
      "                      \"target_node_id\": \"BigQuery\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"USES\",\n",
      "                      \"source_node_id\": \"Data preprocessing\",\n",
      "                      \"target_node_id\": \"Vertex AI Feature Store\",\n",
      "                      \"target_node_type\": \"Tool\",\n",
      "                      \"source_node_type\": \"Process\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"AFFECTS\",\n",
      "                      \"source_node_id\": \"Privacy implications of data usage and/or collection\",\n",
      "                      \"source_node_type\": \"Process\",\n",
      "                      \"target_node_type\": \"Process\",\n",
      "                      \"target_node_id\": \"Data preprocessing\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"target_node_id\": \"Model prototyping\",\n",
      "                      \"type\": \"SUBPROCESS_OF\",\n",
      "                      \"source_node_type\": \"Process\",\n",
      "                      \"source_node_id\": \"2.2 Model prototyping\",\n",
      "                      \"target_node_type\": \"Process\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"source_node_type\": \"Process\",\n",
      "                      \"target_node_type\": \"Tool\",\n",
      "                      \"target_node_id\": \"Jupyter notebooks\",\n",
      "                      \"source_node_id\": \"Model prototyping\",\n",
      "                      \"type\": \"USES\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"target_node_type\": \"Tool\",\n",
      "                      \"source_node_type\": \"Process\",\n",
      "                      \"type\": \"USES\",\n",
      "                      \"target_node_id\": \"Vertex AI Workbench\",\n",
      "                      \"source_node_id\": \"2.2 Model prototyping\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"source_node_type\": \"Process\",\n",
      "                      \"target_node_type\": \"Tool\",\n",
      "                      \"source_node_id\": \"2.2 Model prototyping\",\n",
      "                      \"target_node_id\": \"notebooks on Dataproc\",\n",
      "                      \"type\": \"USES\"\n",
      "                    }\n",
      "                  ]\n",
      "                },\n",
      "                \"id\": \"8fd7664b-f706-43a0-b22e-933d5ba0221e\"\n",
      "              }\n",
      "            ],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<raw>] [5.81s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence > chain:RunnableLambda] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence > parser:PydanticToolsParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence > parser:PydanticToolsParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence] [2ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableLambda] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error>] [4ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error>] [8ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks] [11ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [5.83s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"Applying security best practices in Vertex AI Workbench\\nUsing Spark kernels\\nIntegration with code source repositories\\nDeveloping models in Vertex AI Workbench by using common frameworks (e.g., TensorFlow, PyTorch, sklearn, Spark, JAX)\\n2.3 Tracking and running ML experiments. Considerations include:\\nChoosing the appropriate Google Cloud environment for development and experimentation (e.g., Vertex AI Experiments, Kubeflow Pipelines, Vertex AI TensorBoard with TensorFlow and PyTorch) given the framework\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"Applying security best practices in Vertex AI Workbench\\nUsing Spark kernels\\nIntegration with code source repositories\\nDeveloping models in Vertex AI Workbench by using common frameworks (e.g., TensorFlow, PyTorch, sklearn, Spark, JAX)\\n2.3 Tracking and running ML experiments. Considerations include:\\nChoosing the appropriate Google Cloud environment for development and experimentation (e.g., Vertex AI Experiments, Kubeflow Pipelines, Vertex AI TensorBoard with TensorFlow and PyTorch) given the framework\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<raw>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<raw> > llm:ChatVertexAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: Extract all Entities\\nHuman: Tip: Make sure to answer in the correct format and do not include any explanations. Use the given format to extract information from the following input: Applying security best practices in Vertex AI Workbench\\nUsing Spark kernels\\nIntegration with code source repositories\\nDeveloping models in Vertex AI Workbench by using common frameworks (e.g., TensorFlow, PyTorch, sklearn, Spark, JAX)\\n2.3 Tracking and running ML experiments. Considerations include:\\nChoosing the appropriate Google Cloud environment for development and experimentation (e.g., Vertex AI Experiments, Kubeflow Pipelines, Vertex AI TensorBoard with TensorFlow and PyTorch) given the framework\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<raw> > llm:ChatVertexAI] [7.11s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"\",\n",
      "        \"generation_info\": {\n",
      "          \"is_blocked\": false,\n",
      "          \"safety_ratings\": [\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
      "              \"probability_label\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
      "              \"probability_label\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
      "              \"probability_label\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
      "              \"probability_label\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            }\n",
      "          ],\n",
      "          \"citation_metadata\": null,\n",
      "          \"usage_metadata\": {\n",
      "            \"prompt_token_count\": 460,\n",
      "            \"candidates_token_count\": 410,\n",
      "            \"total_token_count\": 870\n",
      "          }\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"function_call\": {\n",
      "                \"name\": \"DynamicGraph\",\n",
      "                \"arguments\": \"{\\\"nodes\\\": [{\\\"id\\\": \\\"Security\\\", \\\"type\\\": \\\"Topic\\\"}, {\\\"id\\\": \\\"Spark\\\", \\\"type\\\": \\\"Technology\\\"}, {\\\"type\\\": \\\"Infrastructure\\\", \\\"id\\\": \\\"Repositories\\\"}, {\\\"id\\\": \\\"TensorFlow\\\", \\\"type\\\": \\\"Framework\\\"}, {\\\"id\\\": \\\"PyTorch\\\", \\\"type\\\": \\\"Framework\\\"}, {\\\"id\\\": \\\"Sklearn\\\", \\\"type\\\": \\\"Framework\\\"}, {\\\"id\\\": \\\"JAX\\\", \\\"type\\\": \\\"Framework\\\"}, {\\\"id\\\": \\\"Vertex AI Workbench\\\", \\\"type\\\": \\\"Workbench\\\"}, {\\\"id\\\": \\\"ML Experiments\\\", \\\"type\\\": \\\"Topic\\\"}, {\\\"id\\\": \\\"Code\\\", \\\"type\\\": \\\"Resource\\\"}, {\\\"type\\\": \\\"Resource\\\", \\\"id\\\": \\\"Models\\\"}, {\\\"id\\\": \\\"Vertex AI Experiments\\\", \\\"type\\\": \\\"Environment\\\"}, {\\\"type\\\": \\\"Environment\\\", \\\"id\\\": \\\"Kubeflow Pipelines\\\"}, {\\\"id\\\": \\\"Vertex AI TensorBoard\\\", \\\"type\\\": \\\"Environment\\\"}], \\\"relationships\\\": [{\\\"source_node_id\\\": \\\"Security\\\", \\\"target_node_id\\\": \\\"Vertex AI Workbench\\\", \\\"source_node_type\\\": \\\"Topic\\\", \\\"type\\\": \\\"Best practices\\\", \\\"target_node_type\\\": \\\"Workbench\\\"}, {\\\"target_node_type\\\": \\\"Workbench\\\", \\\"source_node_type\\\": \\\"Technology\\\", \\\"target_node_id\\\": \\\"Vertex AI Workbench\\\", \\\"source_node_id\\\": \\\"Spark\\\", \\\"type\\\": \\\"Kernel support\\\"}, {\\\"source_node_id\\\": \\\"Vertex AI Workbench\\\", \\\"target_node_type\\\": \\\"Infrastructure\\\", \\\"source_node_type\\\": \\\"Workbench\\\", \\\"type\\\": \\\"Integration support\\\", \\\"target_node_id\\\": \\\"Repositories\\\"}, {\\\"target_node_type\\\": \\\"Framework\\\", \\\"source_node_id\\\": \\\"Vertex AI Workbench\\\", \\\"type\\\": \\\"Development support\\\", \\\"source_node_type\\\": \\\"Workbench\\\", \\\"target_node_id\\\": \\\"TensorFlow\\\"}, {\\\"source_node_type\\\": \\\"Workbench\\\", \\\"source_node_id\\\": \\\"Vertex AI Workbench\\\", \\\"type\\\": \\\"Development support\\\", \\\"target_node_type\\\": \\\"Framework\\\", \\\"target_node_id\\\": \\\"PyTorch\\\"}, {\\\"target_node_id\\\": \\\"Sklearn\\\", \\\"target_node_type\\\": \\\"Framework\\\", \\\"type\\\": \\\"Development support\\\", \\\"source_node_type\\\": \\\"Workbench\\\", \\\"source_node_id\\\": \\\"Vertex AI Workbench\\\"}, {\\\"source_node_id\\\": \\\"Vertex AI Workbench\\\", \\\"source_node_type\\\": \\\"Workbench\\\", \\\"target_node_type\\\": \\\"Framework\\\", \\\"target_node_id\\\": \\\"JAX\\\", \\\"type\\\": \\\"Development support\\\"}, {\\\"type\\\": \\\"Tracking support\\\", \\\"source_node_id\\\": \\\"Vertex AI Workbench\\\", \\\"target_node_type\\\": \\\"Topic\\\", \\\"target_node_id\\\": \\\"ML Experiments\\\", \\\"source_node_type\\\": \\\"Workbench\\\"}, {\\\"source_node_type\\\": \\\"Topic\\\", \\\"target_node_type\\\": \\\"Environment\\\", \\\"source_node_id\\\": \\\"ML Experiments\\\", \\\"target_node_id\\\": \\\"Vertex AI Experiments\\\", \\\"type\\\": \\\"Compatibility\\\"}, {\\\"type\\\": \\\"Compatibility\\\", \\\"source_node_type\\\": \\\"Topic\\\", \\\"source_node_id\\\": \\\"ML Experiments\\\", \\\"target_node_id\\\": \\\"Kubeflow Pipelines\\\", \\\"target_node_type\\\": \\\"Environment\\\"}, {\\\"type\\\": \\\"Compatibility\\\", \\\"target_node_id\\\": \\\"Vertex AI TensorBoard\\\", \\\"source_node_type\\\": \\\"Topic\\\", \\\"target_node_type\\\": \\\"Environment\\\", \\\"source_node_id\\\": \\\"ML Experiments\\\"}]}\"\n",
      "              }\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"is_blocked\": false,\n",
      "              \"safety_ratings\": [\n",
      "                {\n",
      "                  \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
      "                  \"probability_label\": \"NEGLIGIBLE\",\n",
      "                  \"blocked\": false\n",
      "                },\n",
      "                {\n",
      "                  \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
      "                  \"probability_label\": \"NEGLIGIBLE\",\n",
      "                  \"blocked\": false\n",
      "                },\n",
      "                {\n",
      "                  \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
      "                  \"probability_label\": \"NEGLIGIBLE\",\n",
      "                  \"blocked\": false\n",
      "                },\n",
      "                {\n",
      "                  \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
      "                  \"probability_label\": \"NEGLIGIBLE\",\n",
      "                  \"blocked\": false\n",
      "                }\n",
      "              ],\n",
      "              \"citation_metadata\": null,\n",
      "              \"usage_metadata\": {\n",
      "                \"prompt_token_count\": 460,\n",
      "                \"candidates_token_count\": 410,\n",
      "                \"total_token_count\": 870\n",
      "              }\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-2396d737-8836-4426-939e-89f9372fb0f0-0\",\n",
      "            \"tool_calls\": [\n",
      "              {\n",
      "                \"name\": \"DynamicGraph\",\n",
      "                \"args\": {\n",
      "                  \"nodes\": [\n",
      "                    {\n",
      "                      \"id\": \"Security\",\n",
      "                      \"type\": \"Topic\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"Spark\",\n",
      "                      \"type\": \"Technology\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"Infrastructure\",\n",
      "                      \"id\": \"Repositories\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"TensorFlow\",\n",
      "                      \"type\": \"Framework\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"PyTorch\",\n",
      "                      \"type\": \"Framework\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"Sklearn\",\n",
      "                      \"type\": \"Framework\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"JAX\",\n",
      "                      \"type\": \"Framework\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"Vertex AI Workbench\",\n",
      "                      \"type\": \"Workbench\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"ML Experiments\",\n",
      "                      \"type\": \"Topic\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"Code\",\n",
      "                      \"type\": \"Resource\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"Resource\",\n",
      "                      \"id\": \"Models\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"Vertex AI Experiments\",\n",
      "                      \"type\": \"Environment\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"Environment\",\n",
      "                      \"id\": \"Kubeflow Pipelines\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"Vertex AI TensorBoard\",\n",
      "                      \"type\": \"Environment\"\n",
      "                    }\n",
      "                  ],\n",
      "                  \"relationships\": [\n",
      "                    {\n",
      "                      \"source_node_id\": \"Security\",\n",
      "                      \"target_node_id\": \"Vertex AI Workbench\",\n",
      "                      \"source_node_type\": \"Topic\",\n",
      "                      \"type\": \"Best practices\",\n",
      "                      \"target_node_type\": \"Workbench\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"target_node_type\": \"Workbench\",\n",
      "                      \"source_node_type\": \"Technology\",\n",
      "                      \"target_node_id\": \"Vertex AI Workbench\",\n",
      "                      \"source_node_id\": \"Spark\",\n",
      "                      \"type\": \"Kernel support\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"source_node_id\": \"Vertex AI Workbench\",\n",
      "                      \"target_node_type\": \"Infrastructure\",\n",
      "                      \"source_node_type\": \"Workbench\",\n",
      "                      \"type\": \"Integration support\",\n",
      "                      \"target_node_id\": \"Repositories\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"target_node_type\": \"Framework\",\n",
      "                      \"source_node_id\": \"Vertex AI Workbench\",\n",
      "                      \"type\": \"Development support\",\n",
      "                      \"source_node_type\": \"Workbench\",\n",
      "                      \"target_node_id\": \"TensorFlow\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"source_node_type\": \"Workbench\",\n",
      "                      \"source_node_id\": \"Vertex AI Workbench\",\n",
      "                      \"type\": \"Development support\",\n",
      "                      \"target_node_type\": \"Framework\",\n",
      "                      \"target_node_id\": \"PyTorch\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"target_node_id\": \"Sklearn\",\n",
      "                      \"target_node_type\": \"Framework\",\n",
      "                      \"type\": \"Development support\",\n",
      "                      \"source_node_type\": \"Workbench\",\n",
      "                      \"source_node_id\": \"Vertex AI Workbench\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"source_node_id\": \"Vertex AI Workbench\",\n",
      "                      \"source_node_type\": \"Workbench\",\n",
      "                      \"target_node_type\": \"Framework\",\n",
      "                      \"target_node_id\": \"JAX\",\n",
      "                      \"type\": \"Development support\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"Tracking support\",\n",
      "                      \"source_node_id\": \"Vertex AI Workbench\",\n",
      "                      \"target_node_type\": \"Topic\",\n",
      "                      \"target_node_id\": \"ML Experiments\",\n",
      "                      \"source_node_type\": \"Workbench\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"source_node_type\": \"Topic\",\n",
      "                      \"target_node_type\": \"Environment\",\n",
      "                      \"source_node_id\": \"ML Experiments\",\n",
      "                      \"target_node_id\": \"Vertex AI Experiments\",\n",
      "                      \"type\": \"Compatibility\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"Compatibility\",\n",
      "                      \"source_node_type\": \"Topic\",\n",
      "                      \"source_node_id\": \"ML Experiments\",\n",
      "                      \"target_node_id\": \"Kubeflow Pipelines\",\n",
      "                      \"target_node_type\": \"Environment\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"Compatibility\",\n",
      "                      \"target_node_id\": \"Vertex AI TensorBoard\",\n",
      "                      \"source_node_type\": \"Topic\",\n",
      "                      \"target_node_type\": \"Environment\",\n",
      "                      \"source_node_id\": \"ML Experiments\"\n",
      "                    }\n",
      "                  ]\n",
      "                },\n",
      "                \"id\": \"9649d9c9-d274-4981-896a-d94e14c692dd\"\n",
      "              }\n",
      "            ],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<raw>] [7.11s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence > chain:RunnableLambda] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence > parser:PydanticToolsParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence > parser:PydanticToolsParser] [1ms] Exiting Parser run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence] [2ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableLambda] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error>] [5ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error>] [8ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks] [11ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [7.13s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"Section 3: Scaling prototypes into ML models (~18% of the exam)\\n3.1 Building models. Considerations include:\\nChoosing ML framework and model architecture\\nModeling techniques given interpretability requirements\\n3.2 Training models. Considerations include:\\nOrganizing training data (e.g., tabular, text, speech, images, videos) on Google Cloud (e.g., Cloud Storage, BigQuery)\\nIngestion of various file types (e.g., CSV, JSON, images, Hadoop, databases) into training\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"Section 3: Scaling prototypes into ML models (~18% of the exam)\\n3.1 Building models. Considerations include:\\nChoosing ML framework and model architecture\\nModeling techniques given interpretability requirements\\n3.2 Training models. Considerations include:\\nOrganizing training data (e.g., tabular, text, speech, images, videos) on Google Cloud (e.g., Cloud Storage, BigQuery)\\nIngestion of various file types (e.g., CSV, JSON, images, Hadoop, databases) into training\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<raw>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<raw> > llm:ChatVertexAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: Extract all Entities\\nHuman: Tip: Make sure to answer in the correct format and do not include any explanations. Use the given format to extract information from the following input: Section 3: Scaling prototypes into ML models (~18% of the exam)\\n3.1 Building models. Considerations include:\\nChoosing ML framework and model architecture\\nModeling techniques given interpretability requirements\\n3.2 Training models. Considerations include:\\nOrganizing training data (e.g., tabular, text, speech, images, videos) on Google Cloud (e.g., Cloud Storage, BigQuery)\\nIngestion of various file types (e.g., CSV, JSON, images, Hadoop, databases) into training\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<raw> > llm:ChatVertexAI] [9.23s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"\",\n",
      "        \"generation_info\": {\n",
      "          \"is_blocked\": false,\n",
      "          \"safety_ratings\": [\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
      "              \"probability_label\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
      "              \"probability_label\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
      "              \"probability_label\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
      "              \"probability_label\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            }\n",
      "          ],\n",
      "          \"citation_metadata\": null,\n",
      "          \"usage_metadata\": {\n",
      "            \"prompt_token_count\": 467,\n",
      "            \"candidates_token_count\": 573,\n",
      "            \"total_token_count\": 1040\n",
      "          }\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"function_call\": {\n",
      "                \"name\": \"DynamicGraph\",\n",
      "                \"arguments\": \"{\\\"nodes\\\": [{\\\"type\\\": \\\"Topic\\\", \\\"id\\\": \\\"Section 3\\\"}, {\\\"type\\\": \\\"Subtopic\\\", \\\"id\\\": \\\"Building models\\\"}, {\\\"type\\\": \\\"Subtopic\\\", \\\"id\\\": \\\"Training models\\\"}, {\\\"type\\\": \\\"Entity\\\", \\\"id\\\": \\\"ML framework\\\"}, {\\\"type\\\": \\\"Entity\\\", \\\"id\\\": \\\"Model architecture\\\"}, {\\\"type\\\": \\\"Entity\\\", \\\"id\\\": \\\"Interpretability\\\"}, {\\\"type\\\": \\\"Entity\\\", \\\"id\\\": \\\"Tabular data\\\"}, {\\\"type\\\": \\\"Entity\\\", \\\"id\\\": \\\"Text data\\\"}, {\\\"type\\\": \\\"Entity\\\", \\\"id\\\": \\\"Speech data\\\"}, {\\\"type\\\": \\\"Entity\\\", \\\"id\\\": \\\"Image data\\\"}, {\\\"id\\\": \\\"Video data\\\", \\\"type\\\": \\\"Entity\\\"}, {\\\"type\\\": \\\"Entity\\\", \\\"id\\\": \\\"Cloud Storage\\\"}, {\\\"type\\\": \\\"Entity\\\", \\\"id\\\": \\\"BigQuery\\\"}, {\\\"id\\\": \\\"CSV\\\", \\\"type\\\": \\\"Entity\\\"}, {\\\"type\\\": \\\"Entity\\\", \\\"id\\\": \\\"JSON\\\"}, {\\\"id\\\": \\\"Hadoop\\\", \\\"type\\\": \\\"Entity\\\"}, {\\\"id\\\": \\\"Databases\\\", \\\"type\\\": \\\"Entity\\\"}], \\\"relationships\\\": [{\\\"target_node_id\\\": \\\"Building models\\\", \\\"target_node_type\\\": \\\"Subtopic\\\", \\\"source_node_id\\\": \\\"Section 3\\\", \\\"type\\\": \\\"HAS_SUBTOPIC\\\", \\\"source_node_type\\\": \\\"Topic\\\"}, {\\\"source_node_id\\\": \\\"Section 3\\\", \\\"target_node_type\\\": \\\"Subtopic\\\", \\\"target_node_id\\\": \\\"Training models\\\", \\\"source_node_type\\\": \\\"Topic\\\", \\\"type\\\": \\\"HAS_SUBTOPIC\\\"}, {\\\"target_node_type\\\": \\\"Entity\\\", \\\"type\\\": \\\"CONSIDER\\\", \\\"source_node_id\\\": \\\"Building models\\\", \\\"source_node_type\\\": \\\"Subtopic\\\", \\\"target_node_id\\\": \\\"ML framework\\\"}, {\\\"target_node_type\\\": \\\"Entity\\\", \\\"source_node_id\\\": \\\"Building models\\\", \\\"type\\\": \\\"CONSIDER\\\", \\\"source_node_type\\\": \\\"Subtopic\\\", \\\"target_node_id\\\": \\\"Model architecture\\\"}, {\\\"target_node_type\\\": \\\"Entity\\\", \\\"source_node_type\\\": \\\"Subtopic\\\", \\\"target_node_id\\\": \\\"Interpretability\\\", \\\"source_node_id\\\": \\\"Building models\\\", \\\"type\\\": \\\"CONSIDER\\\"}, {\\\"target_node_id\\\": \\\"Tabular data\\\", \\\"type\\\": \\\"ORGANIZE\\\", \\\"source_node_id\\\": \\\"Training models\\\", \\\"target_node_type\\\": \\\"Entity\\\", \\\"source_node_type\\\": \\\"Subtopic\\\"}, {\\\"source_node_id\\\": \\\"Training models\\\", \\\"target_node_id\\\": \\\"Text data\\\", \\\"type\\\": \\\"ORGANIZE\\\", \\\"target_node_type\\\": \\\"Entity\\\", \\\"source_node_type\\\": \\\"Subtopic\\\"}, {\\\"source_node_id\\\": \\\"Training models\\\", \\\"target_node_type\\\": \\\"Entity\\\", \\\"type\\\": \\\"ORGANIZE\\\", \\\"target_node_id\\\": \\\"Speech data\\\", \\\"source_node_type\\\": \\\"Subtopic\\\"}, {\\\"source_node_type\\\": \\\"Subtopic\\\", \\\"target_node_id\\\": \\\"Image data\\\", \\\"type\\\": \\\"ORGANIZE\\\", \\\"target_node_type\\\": \\\"Entity\\\", \\\"source_node_id\\\": \\\"Training models\\\"}, {\\\"type\\\": \\\"ORGANIZE\\\", \\\"source_node_id\\\": \\\"Training models\\\", \\\"target_node_id\\\": \\\"Video data\\\", \\\"target_node_type\\\": \\\"Entity\\\", \\\"source_node_type\\\": \\\"Subtopic\\\"}, {\\\"source_node_id\\\": \\\"Training models\\\", \\\"source_node_type\\\": \\\"Subtopic\\\", \\\"type\\\": \\\"ON\\\", \\\"target_node_id\\\": \\\"Cloud Storage\\\", \\\"target_node_type\\\": \\\"Entity\\\"}, {\\\"target_node_type\\\": \\\"Entity\\\", \\\"target_node_id\\\": \\\"BigQuery\\\", \\\"source_node_id\\\": \\\"Training models\\\", \\\"source_node_type\\\": \\\"Subtopic\\\", \\\"type\\\": \\\"ON\\\"}, {\\\"source_node_id\\\": \\\"Training models\\\", \\\"target_node_type\\\": \\\"Entity\\\", \\\"source_node_type\\\": \\\"Subtopic\\\", \\\"target_node_id\\\": \\\"CSV\\\", \\\"type\\\": \\\"INGESTION\\\"}, {\\\"target_node_type\\\": \\\"Entity\\\", \\\"type\\\": \\\"INGESTION\\\", \\\"source_node_id\\\": \\\"Training models\\\", \\\"source_node_type\\\": \\\"Subtopic\\\", \\\"target_node_id\\\": \\\"JSON\\\"}, {\\\"target_node_id\\\": \\\"Hadoop\\\", \\\"source_node_type\\\": \\\"Subtopic\\\", \\\"target_node_type\\\": \\\"Entity\\\", \\\"type\\\": \\\"INGESTION\\\", \\\"source_node_id\\\": \\\"Training models\\\"}, {\\\"target_node_id\\\": \\\"Databases\\\", \\\"target_node_type\\\": \\\"Entity\\\", \\\"type\\\": \\\"INGESTION\\\", \\\"source_node_id\\\": \\\"Training models\\\", \\\"source_node_type\\\": \\\"Subtopic\\\"}]}\"\n",
      "              }\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"is_blocked\": false,\n",
      "              \"safety_ratings\": [\n",
      "                {\n",
      "                  \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
      "                  \"probability_label\": \"NEGLIGIBLE\",\n",
      "                  \"blocked\": false\n",
      "                },\n",
      "                {\n",
      "                  \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
      "                  \"probability_label\": \"NEGLIGIBLE\",\n",
      "                  \"blocked\": false\n",
      "                },\n",
      "                {\n",
      "                  \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
      "                  \"probability_label\": \"NEGLIGIBLE\",\n",
      "                  \"blocked\": false\n",
      "                },\n",
      "                {\n",
      "                  \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
      "                  \"probability_label\": \"NEGLIGIBLE\",\n",
      "                  \"blocked\": false\n",
      "                }\n",
      "              ],\n",
      "              \"citation_metadata\": null,\n",
      "              \"usage_metadata\": {\n",
      "                \"prompt_token_count\": 467,\n",
      "                \"candidates_token_count\": 573,\n",
      "                \"total_token_count\": 1040\n",
      "              }\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-b5bb8529-ad98-4962-be45-4bf5a03ec512-0\",\n",
      "            \"tool_calls\": [\n",
      "              {\n",
      "                \"name\": \"DynamicGraph\",\n",
      "                \"args\": {\n",
      "                  \"nodes\": [\n",
      "                    {\n",
      "                      \"type\": \"Topic\",\n",
      "                      \"id\": \"Section 3\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"Subtopic\",\n",
      "                      \"id\": \"Building models\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"Subtopic\",\n",
      "                      \"id\": \"Training models\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"Entity\",\n",
      "                      \"id\": \"ML framework\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"Entity\",\n",
      "                      \"id\": \"Model architecture\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"Entity\",\n",
      "                      \"id\": \"Interpretability\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"Entity\",\n",
      "                      \"id\": \"Tabular data\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"Entity\",\n",
      "                      \"id\": \"Text data\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"Entity\",\n",
      "                      \"id\": \"Speech data\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"Entity\",\n",
      "                      \"id\": \"Image data\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"Video data\",\n",
      "                      \"type\": \"Entity\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"Entity\",\n",
      "                      \"id\": \"Cloud Storage\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"Entity\",\n",
      "                      \"id\": \"BigQuery\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"CSV\",\n",
      "                      \"type\": \"Entity\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"Entity\",\n",
      "                      \"id\": \"JSON\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"Hadoop\",\n",
      "                      \"type\": \"Entity\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"Databases\",\n",
      "                      \"type\": \"Entity\"\n",
      "                    }\n",
      "                  ],\n",
      "                  \"relationships\": [\n",
      "                    {\n",
      "                      \"target_node_id\": \"Building models\",\n",
      "                      \"target_node_type\": \"Subtopic\",\n",
      "                      \"source_node_id\": \"Section 3\",\n",
      "                      \"type\": \"HAS_SUBTOPIC\",\n",
      "                      \"source_node_type\": \"Topic\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"source_node_id\": \"Section 3\",\n",
      "                      \"target_node_type\": \"Subtopic\",\n",
      "                      \"target_node_id\": \"Training models\",\n",
      "                      \"source_node_type\": \"Topic\",\n",
      "                      \"type\": \"HAS_SUBTOPIC\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"target_node_type\": \"Entity\",\n",
      "                      \"type\": \"CONSIDER\",\n",
      "                      \"source_node_id\": \"Building models\",\n",
      "                      \"source_node_type\": \"Subtopic\",\n",
      "                      \"target_node_id\": \"ML framework\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"target_node_type\": \"Entity\",\n",
      "                      \"source_node_id\": \"Building models\",\n",
      "                      \"type\": \"CONSIDER\",\n",
      "                      \"source_node_type\": \"Subtopic\",\n",
      "                      \"target_node_id\": \"Model architecture\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"target_node_type\": \"Entity\",\n",
      "                      \"source_node_type\": \"Subtopic\",\n",
      "                      \"target_node_id\": \"Interpretability\",\n",
      "                      \"source_node_id\": \"Building models\",\n",
      "                      \"type\": \"CONSIDER\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"target_node_id\": \"Tabular data\",\n",
      "                      \"type\": \"ORGANIZE\",\n",
      "                      \"source_node_id\": \"Training models\",\n",
      "                      \"target_node_type\": \"Entity\",\n",
      "                      \"source_node_type\": \"Subtopic\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"source_node_id\": \"Training models\",\n",
      "                      \"target_node_id\": \"Text data\",\n",
      "                      \"type\": \"ORGANIZE\",\n",
      "                      \"target_node_type\": \"Entity\",\n",
      "                      \"source_node_type\": \"Subtopic\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"source_node_id\": \"Training models\",\n",
      "                      \"target_node_type\": \"Entity\",\n",
      "                      \"type\": \"ORGANIZE\",\n",
      "                      \"target_node_id\": \"Speech data\",\n",
      "                      \"source_node_type\": \"Subtopic\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"source_node_type\": \"Subtopic\",\n",
      "                      \"target_node_id\": \"Image data\",\n",
      "                      \"type\": \"ORGANIZE\",\n",
      "                      \"target_node_type\": \"Entity\",\n",
      "                      \"source_node_id\": \"Training models\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"ORGANIZE\",\n",
      "                      \"source_node_id\": \"Training models\",\n",
      "                      \"target_node_id\": \"Video data\",\n",
      "                      \"target_node_type\": \"Entity\",\n",
      "                      \"source_node_type\": \"Subtopic\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"source_node_id\": \"Training models\",\n",
      "                      \"source_node_type\": \"Subtopic\",\n",
      "                      \"type\": \"ON\",\n",
      "                      \"target_node_id\": \"Cloud Storage\",\n",
      "                      \"target_node_type\": \"Entity\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"target_node_type\": \"Entity\",\n",
      "                      \"target_node_id\": \"BigQuery\",\n",
      "                      \"source_node_id\": \"Training models\",\n",
      "                      \"source_node_type\": \"Subtopic\",\n",
      "                      \"type\": \"ON\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"source_node_id\": \"Training models\",\n",
      "                      \"target_node_type\": \"Entity\",\n",
      "                      \"source_node_type\": \"Subtopic\",\n",
      "                      \"target_node_id\": \"CSV\",\n",
      "                      \"type\": \"INGESTION\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"target_node_type\": \"Entity\",\n",
      "                      \"type\": \"INGESTION\",\n",
      "                      \"source_node_id\": \"Training models\",\n",
      "                      \"source_node_type\": \"Subtopic\",\n",
      "                      \"target_node_id\": \"JSON\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"target_node_id\": \"Hadoop\",\n",
      "                      \"source_node_type\": \"Subtopic\",\n",
      "                      \"target_node_type\": \"Entity\",\n",
      "                      \"type\": \"INGESTION\",\n",
      "                      \"source_node_id\": \"Training models\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"target_node_id\": \"Databases\",\n",
      "                      \"target_node_type\": \"Entity\",\n",
      "                      \"type\": \"INGESTION\",\n",
      "                      \"source_node_id\": \"Training models\",\n",
      "                      \"source_node_type\": \"Subtopic\"\n",
      "                    }\n",
      "                  ]\n",
      "                },\n",
      "                \"id\": \"c8943521-4810-4631-af24-ca74aeba5412\"\n",
      "              }\n",
      "            ],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<raw>] [9.23s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence > chain:RunnableLambda] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence > parser:PydanticToolsParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence > parser:PydanticToolsParser] [1ms] Exiting Parser run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence] [2ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableLambda] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error>] [6ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error>] [8ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks] [11ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [9.26s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"Training using different SDKs (e.g., Vertex AI custom training, Kubeflow on Google Kubernetes Engine, AutoML, tabular workflows)\\nUsing distributed training to organize reliable pipelines\\nHyperparameter tuning\\nTroubleshooting ML model training failures\\n3.3 Choosing appropriate hardware for training. Considerations include:\\nEvaluation of compute and accelerator options (e.g., CPU, GPU, TPU, edge devices)\\nDistributed training with TPUs and GPUs (e.g., Reduction Server on Vertex AI, Horovod)\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"Training using different SDKs (e.g., Vertex AI custom training, Kubeflow on Google Kubernetes Engine, AutoML, tabular workflows)\\nUsing distributed training to organize reliable pipelines\\nHyperparameter tuning\\nTroubleshooting ML model training failures\\n3.3 Choosing appropriate hardware for training. Considerations include:\\nEvaluation of compute and accelerator options (e.g., CPU, GPU, TPU, edge devices)\\nDistributed training with TPUs and GPUs (e.g., Reduction Server on Vertex AI, Horovod)\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<raw>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<raw> > llm:ChatVertexAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: Extract all Entities\\nHuman: Tip: Make sure to answer in the correct format and do not include any explanations. Use the given format to extract information from the following input: Training using different SDKs (e.g., Vertex AI custom training, Kubeflow on Google Kubernetes Engine, AutoML, tabular workflows)\\nUsing distributed training to organize reliable pipelines\\nHyperparameter tuning\\nTroubleshooting ML model training failures\\n3.3 Choosing appropriate hardware for training. Considerations include:\\nEvaluation of compute and accelerator options (e.g., CPU, GPU, TPU, edge devices)\\nDistributed training with TPUs and GPUs (e.g., Reduction Server on Vertex AI, Horovod)\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<raw> > llm:ChatVertexAI] [15.93s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"\",\n",
      "        \"generation_info\": {\n",
      "          \"is_blocked\": false,\n",
      "          \"safety_ratings\": [\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
      "              \"probability_label\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
      "              \"probability_label\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
      "              \"probability_label\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
      "              \"probability_label\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            }\n",
      "          ],\n",
      "          \"citation_metadata\": null,\n",
      "          \"usage_metadata\": {\n",
      "            \"prompt_token_count\": 464,\n",
      "            \"candidates_token_count\": 1030,\n",
      "            \"total_token_count\": 1494\n",
      "          }\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"function_call\": {\n",
      "                \"name\": \"DynamicGraph\",\n",
      "                \"arguments\": \"{\\\"nodes\\\": [{\\\"type\\\": \\\"Process\\\", \\\"id\\\": \\\"Training\\\"}, {\\\"type\\\": \\\"Technology\\\", \\\"id\\\": \\\"SDKs\\\"}, {\\\"id\\\": \\\"Vertex AI\\\", \\\"type\\\": \\\"Technology\\\"}, {\\\"id\\\": \\\"Kubeflow\\\", \\\"type\\\": \\\"Technology\\\"}, {\\\"type\\\": \\\"Technology\\\", \\\"id\\\": \\\"Google Kubernetes Engine\\\"}, {\\\"id\\\": \\\"AutoML\\\", \\\"type\\\": \\\"Technology\\\"}, {\\\"type\\\": \\\"Field\\\", \\\"id\\\": \\\"Tabular\\\"}, {\\\"type\\\": \\\"Technology\\\", \\\"id\\\": \\\"Workflows\\\"}, {\\\"type\\\": \\\"Attribute\\\", \\\"id\\\": \\\"Distributed\\\"}, {\\\"id\\\": \\\"Pipelines\\\", \\\"type\\\": \\\"Technology\\\"}, {\\\"type\\\": \\\"Attribute\\\", \\\"id\\\": \\\"Reliable\\\"}, {\\\"type\\\": \\\"Field\\\", \\\"id\\\": \\\"Hyperparameter\\\"}, {\\\"id\\\": \\\"Tuning\\\", \\\"type\\\": \\\"Process\\\"}, {\\\"id\\\": \\\"Troubleshooting\\\", \\\"type\\\": \\\"Process\\\"}, {\\\"type\\\": \\\"Model\\\", \\\"id\\\": \\\"ML\\\"}, {\\\"id\\\": \\\"Model Training\\\", \\\"type\\\": \\\"Process\\\"}, {\\\"id\\\": \\\"Failures\\\", \\\"type\\\": \\\"Problem\\\"}, {\\\"id\\\": \\\"Hardware\\\", \\\"type\\\": \\\"Technology\\\"}, {\\\"type\\\": \\\"Process\\\", \\\"id\\\": \\\"Training\\\"}, {\\\"id\\\": \\\"Compute\\\", \\\"type\\\": \\\"Resource\\\"}, {\\\"id\\\": \\\"Accelerator\\\", \\\"type\\\": \\\"Resource\\\"}, {\\\"type\\\": \\\"Technology\\\", \\\"id\\\": \\\"CPU\\\"}, {\\\"id\\\": \\\"GPU\\\", \\\"type\\\": \\\"Technology\\\"}, {\\\"id\\\": \\\"TPU\\\", \\\"type\\\": \\\"Technology\\\"}, {\\\"type\\\": \\\"Attribute\\\", \\\"id\\\": \\\"Edge\\\"}, {\\\"id\\\": \\\"Devices\\\", \\\"type\\\": \\\"Product\\\"}, {\\\"id\\\": \\\"Distributed\\\", \\\"type\\\": \\\"Attribute\\\"}, {\\\"id\\\": \\\"Training\\\", \\\"type\\\": \\\"Process\\\"}, {\\\"id\\\": \\\"TPUs\\\", \\\"type\\\": \\\"Technology\\\"}, {\\\"type\\\": \\\"Technology\\\", \\\"id\\\": \\\"GPUs\\\"}, {\\\"id\\\": \\\"Reduction\\\", \\\"type\\\": \\\"Process\\\"}, {\\\"id\\\": \\\"Server\\\", \\\"type\\\": \\\"Product\\\"}, {\\\"id\\\": \\\"Vertex AI\\\", \\\"type\\\": \\\"Technology\\\"}, {\\\"type\\\": \\\"Technology\\\", \\\"id\\\": \\\"Horovod\\\"}], \\\"relationships\\\": [{\\\"target_node_type\\\": \\\"Technology\\\", \\\"source_node_id\\\": \\\"Training\\\", \\\"source_node_type\\\": \\\"Process\\\", \\\"target_node_id\\\": \\\"SDKs\\\", \\\"type\\\": \\\"USES\\\"}, {\\\"source_node_id\\\": \\\"SDKs\\\", \\\"type\\\": \\\"INCLUDES\\\", \\\"target_node_type\\\": \\\"Technology\\\", \\\"source_node_type\\\": \\\"Technology\\\", \\\"target_node_id\\\": \\\"Vertex AI\\\"}, {\\\"source_node_type\\\": \\\"Technology\\\", \\\"target_node_id\\\": \\\"Kubeflow\\\", \\\"target_node_type\\\": \\\"Technology\\\", \\\"type\\\": \\\"INCLUDES\\\", \\\"source_node_id\\\": \\\"SDKs\\\"}, {\\\"source_node_type\\\": \\\"Technology\\\", \\\"target_node_id\\\": \\\"Google Kubernetes Engine\\\", \\\"source_node_id\\\": \\\"Kubeflow\\\", \\\"type\\\": \\\"RUNS_ON\\\", \\\"target_node_type\\\": \\\"Technology\\\"}, {\\\"target_node_id\\\": \\\"AutoML\\\", \\\"source_node_type\\\": \\\"Technology\\\", \\\"type\\\": \\\"INCLUDES\\\", \\\"source_node_id\\\": \\\"SDKs\\\", \\\"target_node_type\\\": \\\"Technology\\\"}, {\\\"source_node_type\\\": \\\"Technology\\\", \\\"target_node_id\\\": \\\"Tabular\\\", \\\"source_node_id\\\": \\\"AutoML\\\", \\\"target_node_type\\\": \\\"Field\\\", \\\"type\\\": \\\"FOR\\\"}, {\\\"type\\\": \\\"USES\\\", \\\"source_node_type\\\": \\\"Technology\\\", \\\"source_node_id\\\": \\\"AutoML\\\", \\\"target_node_type\\\": \\\"Technology\\\", \\\"target_node_id\\\": \\\"Workflows\\\"}, {\\\"target_node_type\\\": \\\"Attribute\\\", \\\"target_node_id\\\": \\\"Distributed\\\", \\\"type\\\": \\\"SHOULD_BE\\\", \\\"source_node_id\\\": \\\"Training\\\", \\\"source_node_type\\\": \\\"Process\\\"}, {\\\"source_node_id\\\": \\\"Distributed\\\", \\\"type\\\": \\\"FOR\\\", \\\"target_node_type\\\": \\\"Technology\\\", \\\"source_node_type\\\": \\\"Attribute\\\", \\\"target_node_id\\\": \\\"Pipelines\\\"}, {\\\"source_node_type\\\": \\\"Technology\\\", \\\"source_node_id\\\": \\\"Pipelines\\\", \\\"target_node_type\\\": \\\"Attribute\\\", \\\"target_node_id\\\": \\\"Reliable\\\", \\\"type\\\": \\\"SHOULD_BE\\\"}, {\\\"target_node_id\\\": \\\"Hyperparameter\\\", \\\"source_node_type\\\": \\\"Process\\\", \\\"source_node_id\\\": \\\"Training\\\", \\\"type\\\": \\\"REQUIRES\\\", \\\"target_node_type\\\": \\\"Field\\\"}, {\\\"source_node_type\\\": \\\"Field\\\", \\\"target_node_type\\\": \\\"Process\\\", \\\"source_node_id\\\": \\\"Hyperparameter\\\", \\\"target_node_id\\\": \\\"Tuning\\\", \\\"type\\\": \\\"FOR\\\"}, {\\\"source_node_id\\\": \\\"Training\\\", \\\"target_node_type\\\": \\\"Process\\\", \\\"type\\\": \\\"REQUIRES\\\", \\\"source_node_type\\\": \\\"Process\\\", \\\"target_node_id\\\": \\\"Troubleshooting\\\"}, {\\\"type\\\": \\\"FOR\\\", \\\"target_node_id\\\": \\\"ML\\\", \\\"source_node_type\\\": \\\"Process\\\", \\\"source_node_id\\\": \\\"Troubleshooting\\\", \\\"target_node_type\\\": \\\"Model\\\"}, {\\\"source_node_id\\\": \\\"ML\\\", \\\"source_node_type\\\": \\\"Model\\\", \\\"target_node_type\\\": \\\"Process\\\", \\\"type\\\": \\\"DURING\\\", \\\"target_node_id\\\": \\\"Model Training\\\"}, {\\\"target_node_id\\\": \\\"Failures\\\", \\\"source_node_id\\\": \\\"Model Training\\\", \\\"type\\\": \\\"RESULTS_IN\\\", \\\"source_node_type\\\": \\\"Process\\\", \\\"target_node_type\\\": \\\"Problem\\\"}, {\\\"target_node_type\\\": \\\"Technology\\\", \\\"target_node_id\\\": \\\"Hardware\\\", \\\"type\\\": \\\"SHOULD_RUN_ON\\\", \\\"source_node_id\\\": \\\"Training\\\", \\\"source_node_type\\\": \\\"Process\\\"}, {\\\"source_node_id\\\": \\\"Hardware\\\", \\\"target_node_type\\\": \\\"Resource\\\", \\\"target_node_id\\\": \\\"Compute\\\", \\\"type\\\": \\\"SHOULD_HAVE\\\", \\\"source_node_type\\\": \\\"Technology\\\"}, {\\\"target_node_type\\\": \\\"Resource\\\", \\\"target_node_id\\\": \\\"Accelerator\\\", \\\"type\\\": \\\"OR\\\", \\\"source_node_id\\\": \\\"Compute\\\", \\\"source_node_type\\\": \\\"Resource\\\"}, {\\\"source_node_id\\\": \\\"Accelerator\\\", \\\"type\\\": \\\"INCLUDES\\\", \\\"source_node_type\\\": \\\"Resource\\\", \\\"target_node_id\\\": \\\"CPU\\\", \\\"target_node_type\\\": \\\"Technology\\\"}, {\\\"target_node_type\\\": \\\"Technology\\\", \\\"type\\\": \\\"INCLUDES\\\", \\\"source_node_type\\\": \\\"Resource\\\", \\\"target_node_id\\\": \\\"GPU\\\", \\\"source_node_id\\\": \\\"Accelerator\\\"}, {\\\"type\\\": \\\"INCLUDES\\\", \\\"target_node_type\\\": \\\"Technology\\\", \\\"source_node_type\\\": \\\"Resource\\\", \\\"source_node_id\\\": \\\"Accelerator\\\", \\\"target_node_id\\\": \\\"TPU\\\"}, {\\\"source_node_type\\\": \\\"Technology\\\", \\\"target_node_type\\\": \\\"Attribute\\\", \\\"source_node_id\\\": \\\"TPU\\\", \\\"target_node_id\\\": \\\"Edge\\\", \\\"type\\\": \\\"CAN_BE_USED_ON\\\"}, {\\\"target_node_type\\\": \\\"Product\\\", \\\"target_node_id\\\": \\\"Devices\\\", \\\"source_node_type\\\": \\\"Attribute\\\", \\\"source_node_id\\\": \\\"Edge\\\", \\\"type\\\": \\\"FOR\\\"}, {\\\"source_node_id\\\": \\\"Training\\\", \\\"source_node_type\\\": \\\"Process\\\", \\\"target_node_type\\\": \\\"Attribute\\\", \\\"target_node_id\\\": \\\"Distributed\\\", \\\"type\\\": \\\"CAN_BE_DONE_WITH\\\"}, {\\\"target_node_id\\\": \\\"TPUs\\\", \\\"source_node_type\\\": \\\"Attribute\\\", \\\"target_node_type\\\": \\\"Technology\\\", \\\"type\\\": \\\"USING\\\", \\\"source_node_id\\\": \\\"Distributed\\\"}, {\\\"type\\\": \\\"USING\\\", \\\"target_node_id\\\": \\\"GPUs\\\", \\\"target_node_type\\\": \\\"Technology\\\", \\\"source_node_type\\\": \\\"Attribute\\\", \\\"source_node_id\\\": \\\"Distributed\\\"}, {\\\"target_node_id\\\": \\\"Reduction\\\", \\\"target_node_type\\\": \\\"Process\\\", \\\"source_node_type\\\": \\\"Attribute\\\", \\\"source_node_id\\\": \\\"Distributed\\\", \\\"type\\\": \\\"WITH\\\"}, {\\\"target_node_type\\\": \\\"Product\\\", \\\"source_node_type\\\": \\\"Process\\\", \\\"target_node_id\\\": \\\"Server\\\", \\\"type\\\": \\\"ON\\\", \\\"source_node_id\\\": \\\"Reduction\\\"}, {\\\"type\\\": \\\"PROVIDED_BY\\\", \\\"source_node_id\\\": \\\"Server\\\", \\\"source_node_type\\\": \\\"Product\\\", \\\"target_node_id\\\": \\\"Vertex AI\\\", \\\"target_node_type\\\": \\\"Technology\\\"}, {\\\"target_node_id\\\": \\\"Horovod\\\", \\\"source_node_id\\\": \\\"Distributed\\\", \\\"source_node_type\\\": \\\"Attribute\\\", \\\"target_node_type\\\": \\\"Technology\\\", \\\"type\\\": \\\"OR\\\"}]}\"\n",
      "              }\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"is_blocked\": false,\n",
      "              \"safety_ratings\": [\n",
      "                {\n",
      "                  \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
      "                  \"probability_label\": \"NEGLIGIBLE\",\n",
      "                  \"blocked\": false\n",
      "                },\n",
      "                {\n",
      "                  \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
      "                  \"probability_label\": \"NEGLIGIBLE\",\n",
      "                  \"blocked\": false\n",
      "                },\n",
      "                {\n",
      "                  \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
      "                  \"probability_label\": \"NEGLIGIBLE\",\n",
      "                  \"blocked\": false\n",
      "                },\n",
      "                {\n",
      "                  \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
      "                  \"probability_label\": \"NEGLIGIBLE\",\n",
      "                  \"blocked\": false\n",
      "                }\n",
      "              ],\n",
      "              \"citation_metadata\": null,\n",
      "              \"usage_metadata\": {\n",
      "                \"prompt_token_count\": 464,\n",
      "                \"candidates_token_count\": 1030,\n",
      "                \"total_token_count\": 1494\n",
      "              }\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-f0026f8f-03db-4f1d-99d2-36895dc486b9-0\",\n",
      "            \"tool_calls\": [\n",
      "              {\n",
      "                \"name\": \"DynamicGraph\",\n",
      "                \"args\": {\n",
      "                  \"nodes\": [\n",
      "                    {\n",
      "                      \"type\": \"Process\",\n",
      "                      \"id\": \"Training\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"Technology\",\n",
      "                      \"id\": \"SDKs\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"Vertex AI\",\n",
      "                      \"type\": \"Technology\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"Kubeflow\",\n",
      "                      \"type\": \"Technology\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"Technology\",\n",
      "                      \"id\": \"Google Kubernetes Engine\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"AutoML\",\n",
      "                      \"type\": \"Technology\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"Field\",\n",
      "                      \"id\": \"Tabular\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"Technology\",\n",
      "                      \"id\": \"Workflows\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"Attribute\",\n",
      "                      \"id\": \"Distributed\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"Pipelines\",\n",
      "                      \"type\": \"Technology\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"Attribute\",\n",
      "                      \"id\": \"Reliable\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"Field\",\n",
      "                      \"id\": \"Hyperparameter\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"Tuning\",\n",
      "                      \"type\": \"Process\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"Troubleshooting\",\n",
      "                      \"type\": \"Process\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"Model\",\n",
      "                      \"id\": \"ML\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"Model Training\",\n",
      "                      \"type\": \"Process\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"Failures\",\n",
      "                      \"type\": \"Problem\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"Hardware\",\n",
      "                      \"type\": \"Technology\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"Process\",\n",
      "                      \"id\": \"Training\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"Compute\",\n",
      "                      \"type\": \"Resource\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"Accelerator\",\n",
      "                      \"type\": \"Resource\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"Technology\",\n",
      "                      \"id\": \"CPU\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"GPU\",\n",
      "                      \"type\": \"Technology\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"TPU\",\n",
      "                      \"type\": \"Technology\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"Attribute\",\n",
      "                      \"id\": \"Edge\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"Devices\",\n",
      "                      \"type\": \"Product\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"Distributed\",\n",
      "                      \"type\": \"Attribute\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"Training\",\n",
      "                      \"type\": \"Process\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"TPUs\",\n",
      "                      \"type\": \"Technology\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"Technology\",\n",
      "                      \"id\": \"GPUs\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"Reduction\",\n",
      "                      \"type\": \"Process\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"Server\",\n",
      "                      \"type\": \"Product\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"Vertex AI\",\n",
      "                      \"type\": \"Technology\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"Technology\",\n",
      "                      \"id\": \"Horovod\"\n",
      "                    }\n",
      "                  ],\n",
      "                  \"relationships\": [\n",
      "                    {\n",
      "                      \"target_node_type\": \"Technology\",\n",
      "                      \"source_node_id\": \"Training\",\n",
      "                      \"source_node_type\": \"Process\",\n",
      "                      \"target_node_id\": \"SDKs\",\n",
      "                      \"type\": \"USES\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"source_node_id\": \"SDKs\",\n",
      "                      \"type\": \"INCLUDES\",\n",
      "                      \"target_node_type\": \"Technology\",\n",
      "                      \"source_node_type\": \"Technology\",\n",
      "                      \"target_node_id\": \"Vertex AI\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"source_node_type\": \"Technology\",\n",
      "                      \"target_node_id\": \"Kubeflow\",\n",
      "                      \"target_node_type\": \"Technology\",\n",
      "                      \"type\": \"INCLUDES\",\n",
      "                      \"source_node_id\": \"SDKs\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"source_node_type\": \"Technology\",\n",
      "                      \"target_node_id\": \"Google Kubernetes Engine\",\n",
      "                      \"source_node_id\": \"Kubeflow\",\n",
      "                      \"type\": \"RUNS_ON\",\n",
      "                      \"target_node_type\": \"Technology\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"target_node_id\": \"AutoML\",\n",
      "                      \"source_node_type\": \"Technology\",\n",
      "                      \"type\": \"INCLUDES\",\n",
      "                      \"source_node_id\": \"SDKs\",\n",
      "                      \"target_node_type\": \"Technology\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"source_node_type\": \"Technology\",\n",
      "                      \"target_node_id\": \"Tabular\",\n",
      "                      \"source_node_id\": \"AutoML\",\n",
      "                      \"target_node_type\": \"Field\",\n",
      "                      \"type\": \"FOR\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"USES\",\n",
      "                      \"source_node_type\": \"Technology\",\n",
      "                      \"source_node_id\": \"AutoML\",\n",
      "                      \"target_node_type\": \"Technology\",\n",
      "                      \"target_node_id\": \"Workflows\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"target_node_type\": \"Attribute\",\n",
      "                      \"target_node_id\": \"Distributed\",\n",
      "                      \"type\": \"SHOULD_BE\",\n",
      "                      \"source_node_id\": \"Training\",\n",
      "                      \"source_node_type\": \"Process\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"source_node_id\": \"Distributed\",\n",
      "                      \"type\": \"FOR\",\n",
      "                      \"target_node_type\": \"Technology\",\n",
      "                      \"source_node_type\": \"Attribute\",\n",
      "                      \"target_node_id\": \"Pipelines\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"source_node_type\": \"Technology\",\n",
      "                      \"source_node_id\": \"Pipelines\",\n",
      "                      \"target_node_type\": \"Attribute\",\n",
      "                      \"target_node_id\": \"Reliable\",\n",
      "                      \"type\": \"SHOULD_BE\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"target_node_id\": \"Hyperparameter\",\n",
      "                      \"source_node_type\": \"Process\",\n",
      "                      \"source_node_id\": \"Training\",\n",
      "                      \"type\": \"REQUIRES\",\n",
      "                      \"target_node_type\": \"Field\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"source_node_type\": \"Field\",\n",
      "                      \"target_node_type\": \"Process\",\n",
      "                      \"source_node_id\": \"Hyperparameter\",\n",
      "                      \"target_node_id\": \"Tuning\",\n",
      "                      \"type\": \"FOR\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"source_node_id\": \"Training\",\n",
      "                      \"target_node_type\": \"Process\",\n",
      "                      \"type\": \"REQUIRES\",\n",
      "                      \"source_node_type\": \"Process\",\n",
      "                      \"target_node_id\": \"Troubleshooting\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"FOR\",\n",
      "                      \"target_node_id\": \"ML\",\n",
      "                      \"source_node_type\": \"Process\",\n",
      "                      \"source_node_id\": \"Troubleshooting\",\n",
      "                      \"target_node_type\": \"Model\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"source_node_id\": \"ML\",\n",
      "                      \"source_node_type\": \"Model\",\n",
      "                      \"target_node_type\": \"Process\",\n",
      "                      \"type\": \"DURING\",\n",
      "                      \"target_node_id\": \"Model Training\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"target_node_id\": \"Failures\",\n",
      "                      \"source_node_id\": \"Model Training\",\n",
      "                      \"type\": \"RESULTS_IN\",\n",
      "                      \"source_node_type\": \"Process\",\n",
      "                      \"target_node_type\": \"Problem\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"target_node_type\": \"Technology\",\n",
      "                      \"target_node_id\": \"Hardware\",\n",
      "                      \"type\": \"SHOULD_RUN_ON\",\n",
      "                      \"source_node_id\": \"Training\",\n",
      "                      \"source_node_type\": \"Process\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"source_node_id\": \"Hardware\",\n",
      "                      \"target_node_type\": \"Resource\",\n",
      "                      \"target_node_id\": \"Compute\",\n",
      "                      \"type\": \"SHOULD_HAVE\",\n",
      "                      \"source_node_type\": \"Technology\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"target_node_type\": \"Resource\",\n",
      "                      \"target_node_id\": \"Accelerator\",\n",
      "                      \"type\": \"OR\",\n",
      "                      \"source_node_id\": \"Compute\",\n",
      "                      \"source_node_type\": \"Resource\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"source_node_id\": \"Accelerator\",\n",
      "                      \"type\": \"INCLUDES\",\n",
      "                      \"source_node_type\": \"Resource\",\n",
      "                      \"target_node_id\": \"CPU\",\n",
      "                      \"target_node_type\": \"Technology\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"target_node_type\": \"Technology\",\n",
      "                      \"type\": \"INCLUDES\",\n",
      "                      \"source_node_type\": \"Resource\",\n",
      "                      \"target_node_id\": \"GPU\",\n",
      "                      \"source_node_id\": \"Accelerator\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"INCLUDES\",\n",
      "                      \"target_node_type\": \"Technology\",\n",
      "                      \"source_node_type\": \"Resource\",\n",
      "                      \"source_node_id\": \"Accelerator\",\n",
      "                      \"target_node_id\": \"TPU\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"source_node_type\": \"Technology\",\n",
      "                      \"target_node_type\": \"Attribute\",\n",
      "                      \"source_node_id\": \"TPU\",\n",
      "                      \"target_node_id\": \"Edge\",\n",
      "                      \"type\": \"CAN_BE_USED_ON\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"target_node_type\": \"Product\",\n",
      "                      \"target_node_id\": \"Devices\",\n",
      "                      \"source_node_type\": \"Attribute\",\n",
      "                      \"source_node_id\": \"Edge\",\n",
      "                      \"type\": \"FOR\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"source_node_id\": \"Training\",\n",
      "                      \"source_node_type\": \"Process\",\n",
      "                      \"target_node_type\": \"Attribute\",\n",
      "                      \"target_node_id\": \"Distributed\",\n",
      "                      \"type\": \"CAN_BE_DONE_WITH\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"target_node_id\": \"TPUs\",\n",
      "                      \"source_node_type\": \"Attribute\",\n",
      "                      \"target_node_type\": \"Technology\",\n",
      "                      \"type\": \"USING\",\n",
      "                      \"source_node_id\": \"Distributed\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"USING\",\n",
      "                      \"target_node_id\": \"GPUs\",\n",
      "                      \"target_node_type\": \"Technology\",\n",
      "                      \"source_node_type\": \"Attribute\",\n",
      "                      \"source_node_id\": \"Distributed\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"target_node_id\": \"Reduction\",\n",
      "                      \"target_node_type\": \"Process\",\n",
      "                      \"source_node_type\": \"Attribute\",\n",
      "                      \"source_node_id\": \"Distributed\",\n",
      "                      \"type\": \"WITH\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"target_node_type\": \"Product\",\n",
      "                      \"source_node_type\": \"Process\",\n",
      "                      \"target_node_id\": \"Server\",\n",
      "                      \"type\": \"ON\",\n",
      "                      \"source_node_id\": \"Reduction\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"PROVIDED_BY\",\n",
      "                      \"source_node_id\": \"Server\",\n",
      "                      \"source_node_type\": \"Product\",\n",
      "                      \"target_node_id\": \"Vertex AI\",\n",
      "                      \"target_node_type\": \"Technology\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"target_node_id\": \"Horovod\",\n",
      "                      \"source_node_id\": \"Distributed\",\n",
      "                      \"source_node_type\": \"Attribute\",\n",
      "                      \"target_node_type\": \"Technology\",\n",
      "                      \"type\": \"OR\"\n",
      "                    }\n",
      "                  ]\n",
      "                },\n",
      "                \"id\": \"3f8f4df3-231a-442f-babf-88f64853b821\"\n",
      "              }\n",
      "            ],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<raw>] [15.94s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence > chain:RunnableLambda] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence > parser:PydanticToolsParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence > parser:PydanticToolsParser] [1ms] Exiting Parser run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence] [2ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableLambda] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error>] [6ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error>] [9ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks] [13ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [15.96s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"Section 4: Serving and scaling models (~19% of the exam)\\n4.1 Serving models. Considerations include:\\nBatch and online inference (e.g., Vertex AI, Dataflow, BigQuery ML, Dataproc)\\nUsing different frameworks (e.g., PyTorch, XGBoost) to serve models\\nOrganizing a model registry\\nA/B testing different versions of a model\\n4.2 Scaling online model serving. Considerations include:\\nVertex AI Feature Store\\nVertex AI public and private endpoints\\nChoosing appropriate hardware (e.g., CPU, GPU, TPU, edge)\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"Section 4: Serving and scaling models (~19% of the exam)\\n4.1 Serving models. Considerations include:\\nBatch and online inference (e.g., Vertex AI, Dataflow, BigQuery ML, Dataproc)\\nUsing different frameworks (e.g., PyTorch, XGBoost) to serve models\\nOrganizing a model registry\\nA/B testing different versions of a model\\n4.2 Scaling online model serving. Considerations include:\\nVertex AI Feature Store\\nVertex AI public and private endpoints\\nChoosing appropriate hardware (e.g., CPU, GPU, TPU, edge)\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<raw>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<raw> > llm:ChatVertexAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: Extract all Entities\\nHuman: Tip: Make sure to answer in the correct format and do not include any explanations. Use the given format to extract information from the following input: Section 4: Serving and scaling models (~19% of the exam)\\n4.1 Serving models. Considerations include:\\nBatch and online inference (e.g., Vertex AI, Dataflow, BigQuery ML, Dataproc)\\nUsing different frameworks (e.g., PyTorch, XGBoost) to serve models\\nOrganizing a model registry\\nA/B testing different versions of a model\\n4.2 Scaling online model serving. Considerations include:\\nVertex AI Feature Store\\nVertex AI public and private endpoints\\nChoosing appropriate hardware (e.g., CPU, GPU, TPU, edge)\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<raw> > llm:ChatVertexAI] [9.42s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"\",\n",
      "        \"generation_info\": {\n",
      "          \"is_blocked\": false,\n",
      "          \"safety_ratings\": [\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
      "              \"probability_label\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
      "              \"probability_label\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
      "              \"probability_label\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
      "              \"probability_label\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            }\n",
      "          ],\n",
      "          \"citation_metadata\": null,\n",
      "          \"usage_metadata\": {\n",
      "            \"prompt_token_count\": 485,\n",
      "            \"candidates_token_count\": 501,\n",
      "            \"total_token_count\": 986\n",
      "          }\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"function_call\": {\n",
      "                \"name\": \"DynamicGraph\",\n",
      "                \"arguments\": \"{\\\"relationships\\\": [{\\\"source_node_id\\\": \\\"Section 4\\\", \\\"target_node_type\\\": \\\"Consideration\\\", \\\"type\\\": \\\"Contains\\\", \\\"target_node_id\\\": \\\"Batch and online inference\\\", \\\"source_node_type\\\": \\\"Section\\\"}, {\\\"type\\\": \\\"Contains\\\", \\\"target_node_id\\\": \\\"Vertex AI Feature Store\\\", \\\"source_node_type\\\": \\\"Section\\\", \\\"target_node_type\\\": \\\"Consideration\\\", \\\"source_node_id\\\": \\\"Section 4\\\"}, {\\\"source_node_type\\\": \\\"Section\\\", \\\"type\\\": \\\"Contains\\\", \\\"target_node_id\\\": \\\"Vertex AI public and private endpoints\\\", \\\"target_node_type\\\": \\\"Consideration\\\", \\\"source_node_id\\\": \\\"Section 4\\\"}, {\\\"target_node_id\\\": \\\"CPU\\\", \\\"target_node_type\\\": \\\"Hardware\\\", \\\"type\\\": \\\"Contains\\\", \\\"source_node_type\\\": \\\"Section\\\", \\\"source_node_id\\\": \\\"Section 4\\\"}, {\\\"source_node_id\\\": \\\"Section 4\\\", \\\"type\\\": \\\"Contains\\\", \\\"target_node_type\\\": \\\"Hardware\\\", \\\"source_node_type\\\": \\\"Section\\\", \\\"target_node_id\\\": \\\"GPU\\\"}, {\\\"target_node_type\\\": \\\"Hardware\\\", \\\"target_node_id\\\": \\\"TPU\\\", \\\"source_node_id\\\": \\\"Section 4\\\", \\\"type\\\": \\\"Contains\\\", \\\"source_node_type\\\": \\\"Section\\\"}, {\\\"type\\\": \\\"Contains\\\", \\\"target_node_type\\\": \\\"Hardware\\\", \\\"source_node_id\\\": \\\"Section 4\\\", \\\"target_node_id\\\": \\\"Edge\\\", \\\"source_node_type\\\": \\\"Section\\\"}, {\\\"target_node_id\\\": \\\"Vertex AI\\\", \\\"source_node_type\\\": \\\"Consideration\\\", \\\"source_node_id\\\": \\\"Batch and online inference\\\", \\\"target_node_type\\\": \\\"Framework\\\", \\\"type\\\": \\\"Uses\\\"}, {\\\"source_node_type\\\": \\\"Consideration\\\", \\\"target_node_id\\\": \\\"Dataflow\\\", \\\"type\\\": \\\"Uses\\\", \\\"target_node_type\\\": \\\"Framework\\\", \\\"source_node_id\\\": \\\"Batch and online inference\\\"}, {\\\"source_node_type\\\": \\\"Consideration\\\", \\\"type\\\": \\\"Uses\\\", \\\"source_node_id\\\": \\\"Batch and online inference\\\", \\\"target_node_type\\\": \\\"Framework\\\", \\\"target_node_id\\\": \\\"BigQuery ML\\\"}, {\\\"source_node_type\\\": \\\"Consideration\\\", \\\"target_node_id\\\": \\\"Dataproc\\\", \\\"source_node_id\\\": \\\"Batch and online inference\\\", \\\"target_node_type\\\": \\\"Framework\\\", \\\"type\\\": \\\"Uses\\\"}, {\\\"source_node_type\\\": \\\"Consideration\\\", \\\"target_node_id\\\": \\\"Vertex AI\\\", \\\"type\\\": \\\"Uses\\\", \\\"source_node_id\\\": \\\"Vertex AI Feature Store\\\", \\\"target_node_type\\\": \\\"Framework\\\"}, {\\\"source_node_id\\\": \\\"Vertex AI public and private endpoints\\\", \\\"target_node_type\\\": \\\"Framework\\\", \\\"target_node_id\\\": \\\"Vertex AI\\\", \\\"source_node_type\\\": \\\"Consideration\\\", \\\"type\\\": \\\"Uses\\\"}], \\\"nodes\\\": [{\\\"type\\\": \\\"Section\\\", \\\"id\\\": \\\"Section 4\\\"}, {\\\"id\\\": \\\"Batch and online inference\\\", \\\"type\\\": \\\"Consideration\\\"}, {\\\"id\\\": \\\"Vertex AI\\\", \\\"type\\\": \\\"Framework\\\"}, {\\\"type\\\": \\\"Framework\\\", \\\"id\\\": \\\"Dataflow\\\"}, {\\\"type\\\": \\\"Framework\\\", \\\"id\\\": \\\"BigQuery ML\\\"}, {\\\"type\\\": \\\"Framework\\\", \\\"id\\\": \\\"Dataproc\\\"}, {\\\"type\\\": \\\"Framework\\\", \\\"id\\\": \\\"PyTorch\\\"}, {\\\"type\\\": \\\"Framework\\\", \\\"id\\\": \\\"XGBoost\\\"}, {\\\"type\\\": \\\"Consideration\\\", \\\"id\\\": \\\"Model registry\\\"}, {\\\"type\\\": \\\"Consideration\\\", \\\"id\\\": \\\"A/B testing\\\"}, {\\\"type\\\": \\\"Consideration\\\", \\\"id\\\": \\\"Vertex AI Feature Store\\\"}, {\\\"type\\\": \\\"Consideration\\\", \\\"id\\\": \\\"Vertex AI public and private endpoints\\\"}, {\\\"id\\\": \\\"CPU\\\", \\\"type\\\": \\\"Hardware\\\"}, {\\\"id\\\": \\\"GPU\\\", \\\"type\\\": \\\"Hardware\\\"}, {\\\"id\\\": \\\"TPU\\\", \\\"type\\\": \\\"Hardware\\\"}, {\\\"id\\\": \\\"Edge\\\", \\\"type\\\": \\\"Hardware\\\"}]}\"\n",
      "              }\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"is_blocked\": false,\n",
      "              \"safety_ratings\": [\n",
      "                {\n",
      "                  \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
      "                  \"probability_label\": \"NEGLIGIBLE\",\n",
      "                  \"blocked\": false\n",
      "                },\n",
      "                {\n",
      "                  \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
      "                  \"probability_label\": \"NEGLIGIBLE\",\n",
      "                  \"blocked\": false\n",
      "                },\n",
      "                {\n",
      "                  \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
      "                  \"probability_label\": \"NEGLIGIBLE\",\n",
      "                  \"blocked\": false\n",
      "                },\n",
      "                {\n",
      "                  \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
      "                  \"probability_label\": \"NEGLIGIBLE\",\n",
      "                  \"blocked\": false\n",
      "                }\n",
      "              ],\n",
      "              \"citation_metadata\": null,\n",
      "              \"usage_metadata\": {\n",
      "                \"prompt_token_count\": 485,\n",
      "                \"candidates_token_count\": 501,\n",
      "                \"total_token_count\": 986\n",
      "              }\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-27976558-21df-4090-8788-8341a20f8f31-0\",\n",
      "            \"tool_calls\": [\n",
      "              {\n",
      "                \"name\": \"DynamicGraph\",\n",
      "                \"args\": {\n",
      "                  \"relationships\": [\n",
      "                    {\n",
      "                      \"source_node_id\": \"Section 4\",\n",
      "                      \"target_node_type\": \"Consideration\",\n",
      "                      \"type\": \"Contains\",\n",
      "                      \"target_node_id\": \"Batch and online inference\",\n",
      "                      \"source_node_type\": \"Section\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"Contains\",\n",
      "                      \"target_node_id\": \"Vertex AI Feature Store\",\n",
      "                      \"source_node_type\": \"Section\",\n",
      "                      \"target_node_type\": \"Consideration\",\n",
      "                      \"source_node_id\": \"Section 4\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"source_node_type\": \"Section\",\n",
      "                      \"type\": \"Contains\",\n",
      "                      \"target_node_id\": \"Vertex AI public and private endpoints\",\n",
      "                      \"target_node_type\": \"Consideration\",\n",
      "                      \"source_node_id\": \"Section 4\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"target_node_id\": \"CPU\",\n",
      "                      \"target_node_type\": \"Hardware\",\n",
      "                      \"type\": \"Contains\",\n",
      "                      \"source_node_type\": \"Section\",\n",
      "                      \"source_node_id\": \"Section 4\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"source_node_id\": \"Section 4\",\n",
      "                      \"type\": \"Contains\",\n",
      "                      \"target_node_type\": \"Hardware\",\n",
      "                      \"source_node_type\": \"Section\",\n",
      "                      \"target_node_id\": \"GPU\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"target_node_type\": \"Hardware\",\n",
      "                      \"target_node_id\": \"TPU\",\n",
      "                      \"source_node_id\": \"Section 4\",\n",
      "                      \"type\": \"Contains\",\n",
      "                      \"source_node_type\": \"Section\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"Contains\",\n",
      "                      \"target_node_type\": \"Hardware\",\n",
      "                      \"source_node_id\": \"Section 4\",\n",
      "                      \"target_node_id\": \"Edge\",\n",
      "                      \"source_node_type\": \"Section\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"target_node_id\": \"Vertex AI\",\n",
      "                      \"source_node_type\": \"Consideration\",\n",
      "                      \"source_node_id\": \"Batch and online inference\",\n",
      "                      \"target_node_type\": \"Framework\",\n",
      "                      \"type\": \"Uses\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"source_node_type\": \"Consideration\",\n",
      "                      \"target_node_id\": \"Dataflow\",\n",
      "                      \"type\": \"Uses\",\n",
      "                      \"target_node_type\": \"Framework\",\n",
      "                      \"source_node_id\": \"Batch and online inference\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"source_node_type\": \"Consideration\",\n",
      "                      \"type\": \"Uses\",\n",
      "                      \"source_node_id\": \"Batch and online inference\",\n",
      "                      \"target_node_type\": \"Framework\",\n",
      "                      \"target_node_id\": \"BigQuery ML\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"source_node_type\": \"Consideration\",\n",
      "                      \"target_node_id\": \"Dataproc\",\n",
      "                      \"source_node_id\": \"Batch and online inference\",\n",
      "                      \"target_node_type\": \"Framework\",\n",
      "                      \"type\": \"Uses\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"source_node_type\": \"Consideration\",\n",
      "                      \"target_node_id\": \"Vertex AI\",\n",
      "                      \"type\": \"Uses\",\n",
      "                      \"source_node_id\": \"Vertex AI Feature Store\",\n",
      "                      \"target_node_type\": \"Framework\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"source_node_id\": \"Vertex AI public and private endpoints\",\n",
      "                      \"target_node_type\": \"Framework\",\n",
      "                      \"target_node_id\": \"Vertex AI\",\n",
      "                      \"source_node_type\": \"Consideration\",\n",
      "                      \"type\": \"Uses\"\n",
      "                    }\n",
      "                  ],\n",
      "                  \"nodes\": [\n",
      "                    {\n",
      "                      \"type\": \"Section\",\n",
      "                      \"id\": \"Section 4\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"Batch and online inference\",\n",
      "                      \"type\": \"Consideration\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"Vertex AI\",\n",
      "                      \"type\": \"Framework\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"Framework\",\n",
      "                      \"id\": \"Dataflow\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"Framework\",\n",
      "                      \"id\": \"BigQuery ML\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"Framework\",\n",
      "                      \"id\": \"Dataproc\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"Framework\",\n",
      "                      \"id\": \"PyTorch\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"Framework\",\n",
      "                      \"id\": \"XGBoost\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"Consideration\",\n",
      "                      \"id\": \"Model registry\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"Consideration\",\n",
      "                      \"id\": \"A/B testing\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"Consideration\",\n",
      "                      \"id\": \"Vertex AI Feature Store\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"Consideration\",\n",
      "                      \"id\": \"Vertex AI public and private endpoints\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"CPU\",\n",
      "                      \"type\": \"Hardware\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"GPU\",\n",
      "                      \"type\": \"Hardware\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"TPU\",\n",
      "                      \"type\": \"Hardware\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"Edge\",\n",
      "                      \"type\": \"Hardware\"\n",
      "                    }\n",
      "                  ]\n",
      "                },\n",
      "                \"id\": \"ac033814-e4ff-4936-a311-b6f3e91871b7\"\n",
      "              }\n",
      "            ],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<raw>] [9.42s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence > chain:RunnableLambda] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence > parser:PydanticToolsParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence > parser:PydanticToolsParser] [1ms] Exiting Parser run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence] [3ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableLambda] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error>] [7ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error>] [9ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks] [12ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [9.45s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"Scaling the serving backend based on the throughput (e.g., Vertex AI Prediction, containerized serving)\\nTuning ML models for training and serving in production (e.g., simplification techniques, optimizing the ML solution for increased performance, latency, memory, throughput)\\nSection 5: Automating and orchestrating ML pipelines (~21% of the exam)\\n5.1 Developing end-to-end ML pipelines. Considerations include:\\nData and model validation\\nEnsuring consistent data pre-processing between training and serving\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"Scaling the serving backend based on the throughput (e.g., Vertex AI Prediction, containerized serving)\\nTuning ML models for training and serving in production (e.g., simplification techniques, optimizing the ML solution for increased performance, latency, memory, throughput)\\nSection 5: Automating and orchestrating ML pipelines (~21% of the exam)\\n5.1 Developing end-to-end ML pipelines. Considerations include:\\nData and model validation\\nEnsuring consistent data pre-processing between training and serving\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<raw>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<raw> > llm:ChatVertexAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: Extract all Entities\\nHuman: Tip: Make sure to answer in the correct format and do not include any explanations. Use the given format to extract information from the following input: Scaling the serving backend based on the throughput (e.g., Vertex AI Prediction, containerized serving)\\nTuning ML models for training and serving in production (e.g., simplification techniques, optimizing the ML solution for increased performance, latency, memory, throughput)\\nSection 5: Automating and orchestrating ML pipelines (~21% of the exam)\\n5.1 Developing end-to-end ML pipelines. Considerations include:\\nData and model validation\\nEnsuring consistent data pre-processing between training and serving\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<raw> > llm:ChatVertexAI] [6.04s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"\",\n",
      "        \"generation_info\": {\n",
      "          \"is_blocked\": false,\n",
      "          \"safety_ratings\": [\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
      "              \"probability_label\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
      "              \"probability_label\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
      "              \"probability_label\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
      "              \"probability_label\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            }\n",
      "          ],\n",
      "          \"citation_metadata\": null,\n",
      "          \"usage_metadata\": {\n",
      "            \"prompt_token_count\": 466,\n",
      "            \"candidates_token_count\": 331,\n",
      "            \"total_token_count\": 797\n",
      "          }\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"function_call\": {\n",
      "                \"name\": \"DynamicGraph\",\n",
      "                \"arguments\": \"{\\\"relationships\\\": [{\\\"source_node_id\\\": \\\"Scaling the serving backend based on the throughput\\\", \\\"target_node_type\\\": \\\"Technology\\\", \\\"target_node_id\\\": \\\"Vertex AI Prediction\\\", \\\"source_node_type\\\": \\\"Process\\\", \\\"type\\\": \\\"USES\\\"}, {\\\"source_node_type\\\": \\\"Process\\\", \\\"type\\\": \\\"USES\\\", \\\"target_node_type\\\": \\\"Technology\\\", \\\"source_node_id\\\": \\\"Scaling the serving backend based on the throughput\\\", \\\"target_node_id\\\": \\\"containerized serving\\\"}, {\\\"source_node_id\\\": \\\"Tuning ML models for training and serving in production\\\", \\\"target_node_id\\\": \\\"simplification techniques\\\", \\\"type\\\": \\\"USES\\\", \\\"source_node_type\\\": \\\"Process\\\", \\\"target_node_type\\\": \\\"Technology\\\"}, {\\\"target_node_id\\\": \\\"optimizing the ML solution for increased performance, latency, memory, throughput\\\", \\\"source_node_id\\\": \\\"Tuning ML models for training and serving in production\\\", \\\"source_node_type\\\": \\\"Process\\\", \\\"target_node_type\\\": \\\"Technology\\\", \\\"type\\\": \\\"USES\\\"}, {\\\"type\\\": \\\"PRODUCES\\\", \\\"target_node_id\\\": \\\"Data and model validation\\\", \\\"source_node_type\\\": \\\"Process\\\", \\\"source_node_id\\\": \\\"Developing end-to-end ML pipelines.\\\", \\\"target_node_type\\\": \\\"Concept\\\"}, {\\\"target_node_type\\\": \\\"Concept\\\", \\\"target_node_id\\\": \\\"Ensuring consistent data pre-processing between training and serving\\\", \\\"source_node_type\\\": \\\"Process\\\", \\\"source_node_id\\\": \\\"Developing end-to-end ML pipelines.\\\", \\\"type\\\": \\\"PRODUCES\\\"}], \\\"nodes\\\": [{\\\"type\\\": \\\"Process\\\", \\\"id\\\": \\\"Scaling the serving backend based on the throughput\\\"}, {\\\"type\\\": \\\"Process\\\", \\\"id\\\": \\\"Tuning ML models for training and serving in production\\\"}, {\\\"type\\\": \\\"Process\\\", \\\"id\\\": \\\"Developing end-to-end ML pipelines.\\\"}, {\\\"type\\\": \\\"Technology\\\", \\\"id\\\": \\\"Vertex AI Prediction\\\"}, {\\\"id\\\": \\\"containerized serving\\\", \\\"type\\\": \\\"Technology\\\"}, {\\\"id\\\": \\\"simplification techniques\\\", \\\"type\\\": \\\"Technology\\\"}, {\\\"id\\\": \\\"optimizing the ML solution for increased performance, latency, memory, throughput\\\", \\\"type\\\": \\\"Technology\\\"}, {\\\"id\\\": \\\"Data and model validation\\\", \\\"type\\\": \\\"Concept\\\"}, {\\\"id\\\": \\\"Ensuring consistent data pre-processing between training and serving\\\", \\\"type\\\": \\\"Concept\\\"}]}\"\n",
      "              }\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"is_blocked\": false,\n",
      "              \"safety_ratings\": [\n",
      "                {\n",
      "                  \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
      "                  \"probability_label\": \"NEGLIGIBLE\",\n",
      "                  \"blocked\": false\n",
      "                },\n",
      "                {\n",
      "                  \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
      "                  \"probability_label\": \"NEGLIGIBLE\",\n",
      "                  \"blocked\": false\n",
      "                },\n",
      "                {\n",
      "                  \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
      "                  \"probability_label\": \"NEGLIGIBLE\",\n",
      "                  \"blocked\": false\n",
      "                },\n",
      "                {\n",
      "                  \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
      "                  \"probability_label\": \"NEGLIGIBLE\",\n",
      "                  \"blocked\": false\n",
      "                }\n",
      "              ],\n",
      "              \"citation_metadata\": null,\n",
      "              \"usage_metadata\": {\n",
      "                \"prompt_token_count\": 466,\n",
      "                \"candidates_token_count\": 331,\n",
      "                \"total_token_count\": 797\n",
      "              }\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-069bd951-d094-45aa-b088-ceef1f7944f1-0\",\n",
      "            \"tool_calls\": [\n",
      "              {\n",
      "                \"name\": \"DynamicGraph\",\n",
      "                \"args\": {\n",
      "                  \"relationships\": [\n",
      "                    {\n",
      "                      \"source_node_id\": \"Scaling the serving backend based on the throughput\",\n",
      "                      \"target_node_type\": \"Technology\",\n",
      "                      \"target_node_id\": \"Vertex AI Prediction\",\n",
      "                      \"source_node_type\": \"Process\",\n",
      "                      \"type\": \"USES\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"source_node_type\": \"Process\",\n",
      "                      \"type\": \"USES\",\n",
      "                      \"target_node_type\": \"Technology\",\n",
      "                      \"source_node_id\": \"Scaling the serving backend based on the throughput\",\n",
      "                      \"target_node_id\": \"containerized serving\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"source_node_id\": \"Tuning ML models for training and serving in production\",\n",
      "                      \"target_node_id\": \"simplification techniques\",\n",
      "                      \"type\": \"USES\",\n",
      "                      \"source_node_type\": \"Process\",\n",
      "                      \"target_node_type\": \"Technology\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"target_node_id\": \"optimizing the ML solution for increased performance, latency, memory, throughput\",\n",
      "                      \"source_node_id\": \"Tuning ML models for training and serving in production\",\n",
      "                      \"source_node_type\": \"Process\",\n",
      "                      \"target_node_type\": \"Technology\",\n",
      "                      \"type\": \"USES\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"PRODUCES\",\n",
      "                      \"target_node_id\": \"Data and model validation\",\n",
      "                      \"source_node_type\": \"Process\",\n",
      "                      \"source_node_id\": \"Developing end-to-end ML pipelines.\",\n",
      "                      \"target_node_type\": \"Concept\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"target_node_type\": \"Concept\",\n",
      "                      \"target_node_id\": \"Ensuring consistent data pre-processing between training and serving\",\n",
      "                      \"source_node_type\": \"Process\",\n",
      "                      \"source_node_id\": \"Developing end-to-end ML pipelines.\",\n",
      "                      \"type\": \"PRODUCES\"\n",
      "                    }\n",
      "                  ],\n",
      "                  \"nodes\": [\n",
      "                    {\n",
      "                      \"type\": \"Process\",\n",
      "                      \"id\": \"Scaling the serving backend based on the throughput\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"Process\",\n",
      "                      \"id\": \"Tuning ML models for training and serving in production\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"Process\",\n",
      "                      \"id\": \"Developing end-to-end ML pipelines.\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"Technology\",\n",
      "                      \"id\": \"Vertex AI Prediction\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"containerized serving\",\n",
      "                      \"type\": \"Technology\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"simplification techniques\",\n",
      "                      \"type\": \"Technology\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"optimizing the ML solution for increased performance, latency, memory, throughput\",\n",
      "                      \"type\": \"Technology\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"Data and model validation\",\n",
      "                      \"type\": \"Concept\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"Ensuring consistent data pre-processing between training and serving\",\n",
      "                      \"type\": \"Concept\"\n",
      "                    }\n",
      "                  ]\n",
      "                },\n",
      "                \"id\": \"71353149-bcc1-4349-839e-c553abde6936\"\n",
      "              }\n",
      "            ],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<raw>] [6.05s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence > chain:RunnableLambda] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence > parser:PydanticToolsParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence > parser:PydanticToolsParser] [1ms] Exiting Parser run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableLambda] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error>] [5ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error>] [7ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks] [10ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [6.07s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"Hosting third-party pipelines on Google Cloud (e.g., MLFlow)\\nIdentifying components, parameters, triggers, and compute needs (e.g., Cloud Build, Cloud Run)\\nOrchestration framework (e.g., Kubeflow Pipelines, Vertex AI Pipelines, Cloud Composer)\\nHybrid or multicloud strategies\\nSystem design with TFX components or Kubeflow DSL (e.g., Dataflow)\\n5.2 Automating model retraining. Considerations include:\\nDetermining an appropriate retraining policy\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"Hosting third-party pipelines on Google Cloud (e.g., MLFlow)\\nIdentifying components, parameters, triggers, and compute needs (e.g., Cloud Build, Cloud Run)\\nOrchestration framework (e.g., Kubeflow Pipelines, Vertex AI Pipelines, Cloud Composer)\\nHybrid or multicloud strategies\\nSystem design with TFX components or Kubeflow DSL (e.g., Dataflow)\\n5.2 Automating model retraining. Considerations include:\\nDetermining an appropriate retraining policy\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<raw>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<raw> > llm:ChatVertexAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: Extract all Entities\\nHuman: Tip: Make sure to answer in the correct format and do not include any explanations. Use the given format to extract information from the following input: Hosting third-party pipelines on Google Cloud (e.g., MLFlow)\\nIdentifying components, parameters, triggers, and compute needs (e.g., Cloud Build, Cloud Run)\\nOrchestration framework (e.g., Kubeflow Pipelines, Vertex AI Pipelines, Cloud Composer)\\nHybrid or multicloud strategies\\nSystem design with TFX components or Kubeflow DSL (e.g., Dataflow)\\n5.2 Automating model retraining. Considerations include:\\nDetermining an appropriate retraining policy\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<raw> > llm:ChatVertexAI] [8.47s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"\",\n",
      "        \"generation_info\": {\n",
      "          \"is_blocked\": false,\n",
      "          \"safety_ratings\": [\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
      "              \"probability_label\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
      "              \"probability_label\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
      "              \"probability_label\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
      "              \"probability_label\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            }\n",
      "          ],\n",
      "          \"citation_metadata\": null,\n",
      "          \"usage_metadata\": {\n",
      "            \"prompt_token_count\": 465,\n",
      "            \"candidates_token_count\": 593,\n",
      "            \"total_token_count\": 1058\n",
      "          }\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"function_call\": {\n",
      "                \"name\": \"DynamicGraph\",\n",
      "                \"arguments\": \"{\\\"nodes\\\": [{\\\"type\\\": \\\"Cloud Platform\\\", \\\"id\\\": \\\"Google Cloud\\\"}, {\\\"type\\\": \\\"Third-party Pipeline\\\", \\\"id\\\": \\\"MLFlow\\\"}, {\\\"id\\\": \\\"Cloud Build\\\", \\\"type\\\": \\\"Build Tool\\\"}, {\\\"type\\\": \\\"Compute Resource\\\", \\\"id\\\": \\\"Cloud Run\\\"}, {\\\"id\\\": \\\"Kubeflow Pipelines\\\", \\\"type\\\": \\\"Orchestration Framework\\\"}, {\\\"id\\\": \\\"Vertex AI Pipelines\\\", \\\"type\\\": \\\"Orchestration Framework\\\"}, {\\\"type\\\": \\\"Orchestration Framework\\\", \\\"id\\\": \\\"Cloud Composer\\\"}, {\\\"type\\\": \\\"Deployment Strategy\\\", \\\"id\\\": \\\"Hybrid or Multicloud Strategies\\\"}, {\\\"id\\\": \\\"TFX Components\\\", \\\"type\\\": \\\"Machine Learning Framework\\\"}, {\\\"type\\\": \\\"Machine Learning Framework\\\", \\\"id\\\": \\\"Kubeflow DSL\\\"}, {\\\"id\\\": \\\"Dataflow\\\", \\\"type\\\": \\\"Data Processing Framework\\\"}, {\\\"id\\\": \\\"Model Retraining\\\", \\\"type\\\": \\\"Machine Learning Task\\\"}, {\\\"id\\\": \\\"Retraining Policy\\\", \\\"type\\\": \\\"Policy\\\"}], \\\"relationships\\\": [{\\\"type\\\": \\\"Hosting\\\", \\\"source_node_id\\\": \\\"Google Cloud\\\", \\\"source_node_type\\\": \\\"Cloud Platform\\\", \\\"target_node_type\\\": \\\"Third-party Pipeline\\\", \\\"target_node_id\\\": \\\"MLFlow\\\"}, {\\\"target_node_id\\\": \\\"Cloud Build\\\", \\\"source_node_id\\\": \\\"Google Cloud\\\", \\\"type\\\": \\\"Triggering\\\", \\\"target_node_type\\\": \\\"Build Tool\\\", \\\"source_node_type\\\": \\\"Cloud Platform\\\"}, {\\\"target_node_type\\\": \\\"Compute Resource\\\", \\\"target_node_id\\\": \\\"Cloud Run\\\", \\\"type\\\": \\\"Providing\\\", \\\"source_node_type\\\": \\\"Cloud Platform\\\", \\\"source_node_id\\\": \\\"Google Cloud\\\"}, {\\\"target_node_type\\\": \\\"Build Tool\\\", \\\"target_node_id\\\": \\\"Cloud Build\\\", \\\"source_node_id\\\": \\\"MLFlow\\\", \\\"type\\\": \\\"Running\\\", \\\"source_node_type\\\": \\\"Third-party Pipeline\\\"}, {\\\"source_node_id\\\": \\\"MLFlow\\\", \\\"target_node_type\\\": \\\"Compute Resource\\\", \\\"type\\\": \\\"Deploying\\\", \\\"target_node_id\\\": \\\"Cloud Run\\\", \\\"source_node_type\\\": \\\"Third-party Pipeline\\\"}, {\\\"target_node_id\\\": \\\"Kubeflow Pipelines\\\", \\\"target_node_type\\\": \\\"Orchestration Framework\\\", \\\"source_node_id\\\": \\\"Cloud Build\\\", \\\"source_node_type\\\": \\\"Build Tool\\\", \\\"type\\\": \\\"Triggering\\\"}, {\\\"target_node_id\\\": \\\"Vertex AI Pipelines\\\", \\\"target_node_type\\\": \\\"Orchestration Framework\\\", \\\"source_node_id\\\": \\\"Cloud Build\\\", \\\"source_node_type\\\": \\\"Build Tool\\\", \\\"type\\\": \\\"Triggering\\\"}, {\\\"target_node_id\\\": \\\"Cloud Composer\\\", \\\"source_node_type\\\": \\\"Build Tool\\\", \\\"source_node_id\\\": \\\"Cloud Build\\\", \\\"type\\\": \\\"Triggering\\\", \\\"target_node_type\\\": \\\"Orchestration Framework\\\"}, {\\\"source_node_type\\\": \\\"Orchestration Framework\\\", \\\"target_node_type\\\": \\\"Machine Learning Framework\\\", \\\"target_node_id\\\": \\\"TFX Components\\\", \\\"source_node_id\\\": \\\"Kubeflow Pipelines\\\", \\\"type\\\": \\\"Using\\\"}, {\\\"source_node_id\\\": \\\"Vertex AI Pipelines\\\", \\\"source_node_type\\\": \\\"Orchestration Framework\\\", \\\"target_node_id\\\": \\\"Kubeflow DSL\\\", \\\"type\\\": \\\"Using\\\", \\\"target_node_type\\\": \\\"Machine Learning Framework\\\"}, {\\\"target_node_type\\\": \\\"Data Processing Framework\\\", \\\"source_node_id\\\": \\\"Cloud Composer\\\", \\\"type\\\": \\\"Using\\\", \\\"source_node_type\\\": \\\"Orchestration Framework\\\", \\\"target_node_id\\\": \\\"Dataflow\\\"}, {\\\"source_node_id\\\": \\\"Model Retraining\\\", \\\"target_node_id\\\": \\\"Retraining Policy\\\", \\\"type\\\": \\\"Determining\\\", \\\"target_node_type\\\": \\\"Policy\\\", \\\"source_node_type\\\": \\\"Machine Learning Task\\\"}, {\\\"target_node_type\\\": \\\"Orchestration Framework\\\", \\\"source_node_id\\\": \\\"Retraining Policy\\\", \\\"type\\\": \\\"Triggering\\\", \\\"target_node_id\\\": \\\"Kubeflow Pipelines\\\", \\\"source_node_type\\\": \\\"Policy\\\"}, {\\\"type\\\": \\\"Triggering\\\", \\\"target_node_id\\\": \\\"Vertex AI Pipelines\\\", \\\"source_node_id\\\": \\\"Retraining Policy\\\", \\\"target_node_type\\\": \\\"Orchestration Framework\\\", \\\"source_node_type\\\": \\\"Policy\\\"}, {\\\"target_node_id\\\": \\\"Cloud Composer\\\", \\\"source_node_id\\\": \\\"Retraining Policy\\\", \\\"type\\\": \\\"Triggering\\\", \\\"target_node_type\\\": \\\"Orchestration Framework\\\", \\\"source_node_type\\\": \\\"Policy\\\"}]}\"\n",
      "              }\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"is_blocked\": false,\n",
      "              \"safety_ratings\": [\n",
      "                {\n",
      "                  \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
      "                  \"probability_label\": \"NEGLIGIBLE\",\n",
      "                  \"blocked\": false\n",
      "                },\n",
      "                {\n",
      "                  \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
      "                  \"probability_label\": \"NEGLIGIBLE\",\n",
      "                  \"blocked\": false\n",
      "                },\n",
      "                {\n",
      "                  \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
      "                  \"probability_label\": \"NEGLIGIBLE\",\n",
      "                  \"blocked\": false\n",
      "                },\n",
      "                {\n",
      "                  \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
      "                  \"probability_label\": \"NEGLIGIBLE\",\n",
      "                  \"blocked\": false\n",
      "                }\n",
      "              ],\n",
      "              \"citation_metadata\": null,\n",
      "              \"usage_metadata\": {\n",
      "                \"prompt_token_count\": 465,\n",
      "                \"candidates_token_count\": 593,\n",
      "                \"total_token_count\": 1058\n",
      "              }\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-8e9c9e77-a999-4553-91b2-c3222ad57e1a-0\",\n",
      "            \"tool_calls\": [\n",
      "              {\n",
      "                \"name\": \"DynamicGraph\",\n",
      "                \"args\": {\n",
      "                  \"nodes\": [\n",
      "                    {\n",
      "                      \"type\": \"Cloud Platform\",\n",
      "                      \"id\": \"Google Cloud\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"Third-party Pipeline\",\n",
      "                      \"id\": \"MLFlow\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"Cloud Build\",\n",
      "                      \"type\": \"Build Tool\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"Compute Resource\",\n",
      "                      \"id\": \"Cloud Run\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"Kubeflow Pipelines\",\n",
      "                      \"type\": \"Orchestration Framework\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"Vertex AI Pipelines\",\n",
      "                      \"type\": \"Orchestration Framework\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"Orchestration Framework\",\n",
      "                      \"id\": \"Cloud Composer\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"Deployment Strategy\",\n",
      "                      \"id\": \"Hybrid or Multicloud Strategies\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"TFX Components\",\n",
      "                      \"type\": \"Machine Learning Framework\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"Machine Learning Framework\",\n",
      "                      \"id\": \"Kubeflow DSL\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"Dataflow\",\n",
      "                      \"type\": \"Data Processing Framework\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"Model Retraining\",\n",
      "                      \"type\": \"Machine Learning Task\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"Retraining Policy\",\n",
      "                      \"type\": \"Policy\"\n",
      "                    }\n",
      "                  ],\n",
      "                  \"relationships\": [\n",
      "                    {\n",
      "                      \"type\": \"Hosting\",\n",
      "                      \"source_node_id\": \"Google Cloud\",\n",
      "                      \"source_node_type\": \"Cloud Platform\",\n",
      "                      \"target_node_type\": \"Third-party Pipeline\",\n",
      "                      \"target_node_id\": \"MLFlow\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"target_node_id\": \"Cloud Build\",\n",
      "                      \"source_node_id\": \"Google Cloud\",\n",
      "                      \"type\": \"Triggering\",\n",
      "                      \"target_node_type\": \"Build Tool\",\n",
      "                      \"source_node_type\": \"Cloud Platform\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"target_node_type\": \"Compute Resource\",\n",
      "                      \"target_node_id\": \"Cloud Run\",\n",
      "                      \"type\": \"Providing\",\n",
      "                      \"source_node_type\": \"Cloud Platform\",\n",
      "                      \"source_node_id\": \"Google Cloud\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"target_node_type\": \"Build Tool\",\n",
      "                      \"target_node_id\": \"Cloud Build\",\n",
      "                      \"source_node_id\": \"MLFlow\",\n",
      "                      \"type\": \"Running\",\n",
      "                      \"source_node_type\": \"Third-party Pipeline\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"source_node_id\": \"MLFlow\",\n",
      "                      \"target_node_type\": \"Compute Resource\",\n",
      "                      \"type\": \"Deploying\",\n",
      "                      \"target_node_id\": \"Cloud Run\",\n",
      "                      \"source_node_type\": \"Third-party Pipeline\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"target_node_id\": \"Kubeflow Pipelines\",\n",
      "                      \"target_node_type\": \"Orchestration Framework\",\n",
      "                      \"source_node_id\": \"Cloud Build\",\n",
      "                      \"source_node_type\": \"Build Tool\",\n",
      "                      \"type\": \"Triggering\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"target_node_id\": \"Vertex AI Pipelines\",\n",
      "                      \"target_node_type\": \"Orchestration Framework\",\n",
      "                      \"source_node_id\": \"Cloud Build\",\n",
      "                      \"source_node_type\": \"Build Tool\",\n",
      "                      \"type\": \"Triggering\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"target_node_id\": \"Cloud Composer\",\n",
      "                      \"source_node_type\": \"Build Tool\",\n",
      "                      \"source_node_id\": \"Cloud Build\",\n",
      "                      \"type\": \"Triggering\",\n",
      "                      \"target_node_type\": \"Orchestration Framework\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"source_node_type\": \"Orchestration Framework\",\n",
      "                      \"target_node_type\": \"Machine Learning Framework\",\n",
      "                      \"target_node_id\": \"TFX Components\",\n",
      "                      \"source_node_id\": \"Kubeflow Pipelines\",\n",
      "                      \"type\": \"Using\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"source_node_id\": \"Vertex AI Pipelines\",\n",
      "                      \"source_node_type\": \"Orchestration Framework\",\n",
      "                      \"target_node_id\": \"Kubeflow DSL\",\n",
      "                      \"type\": \"Using\",\n",
      "                      \"target_node_type\": \"Machine Learning Framework\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"target_node_type\": \"Data Processing Framework\",\n",
      "                      \"source_node_id\": \"Cloud Composer\",\n",
      "                      \"type\": \"Using\",\n",
      "                      \"source_node_type\": \"Orchestration Framework\",\n",
      "                      \"target_node_id\": \"Dataflow\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"source_node_id\": \"Model Retraining\",\n",
      "                      \"target_node_id\": \"Retraining Policy\",\n",
      "                      \"type\": \"Determining\",\n",
      "                      \"target_node_type\": \"Policy\",\n",
      "                      \"source_node_type\": \"Machine Learning Task\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"target_node_type\": \"Orchestration Framework\",\n",
      "                      \"source_node_id\": \"Retraining Policy\",\n",
      "                      \"type\": \"Triggering\",\n",
      "                      \"target_node_id\": \"Kubeflow Pipelines\",\n",
      "                      \"source_node_type\": \"Policy\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"Triggering\",\n",
      "                      \"target_node_id\": \"Vertex AI Pipelines\",\n",
      "                      \"source_node_id\": \"Retraining Policy\",\n",
      "                      \"target_node_type\": \"Orchestration Framework\",\n",
      "                      \"source_node_type\": \"Policy\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"target_node_id\": \"Cloud Composer\",\n",
      "                      \"source_node_id\": \"Retraining Policy\",\n",
      "                      \"type\": \"Triggering\",\n",
      "                      \"target_node_type\": \"Orchestration Framework\",\n",
      "                      \"source_node_type\": \"Policy\"\n",
      "                    }\n",
      "                  ]\n",
      "                },\n",
      "                \"id\": \"0ea42fe7-7213-462c-87c8-aceb9698c3f6\"\n",
      "              }\n",
      "            ],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<raw>] [8.47s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence > chain:RunnableLambda] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence > parser:PydanticToolsParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence > parser:PydanticToolsParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableLambda] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error>] [5ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error>] [7ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks] [10ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [8.49s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"Continuous integration and continuous delivery (CI/CD) model deployment (e.g., Cloud Build, Jenkins)\\n5.3 Tracking and auditing metadata. Considerations include: \\nTracking and comparing model artifacts and versions (e.g., Vertex AI Experiments, Vertex ML Metadata)\\nHooking into model and dataset versioning\\nModel and data lineage\\nSection 6: Monitoring ML solutions (~14% of the exam)\\n6.1 Identifying risks to ML solutions. Considerations include:\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"Continuous integration and continuous delivery (CI/CD) model deployment (e.g., Cloud Build, Jenkins)\\n5.3 Tracking and auditing metadata. Considerations include: \\nTracking and comparing model artifacts and versions (e.g., Vertex AI Experiments, Vertex ML Metadata)\\nHooking into model and dataset versioning\\nModel and data lineage\\nSection 6: Monitoring ML solutions (~14% of the exam)\\n6.1 Identifying risks to ML solutions. Considerations include:\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<raw>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<raw> > llm:ChatVertexAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: Extract all Entities\\nHuman: Tip: Make sure to answer in the correct format and do not include any explanations. Use the given format to extract information from the following input: Continuous integration and continuous delivery (CI/CD) model deployment (e.g., Cloud Build, Jenkins)\\n5.3 Tracking and auditing metadata. Considerations include: \\nTracking and comparing model artifacts and versions (e.g., Vertex AI Experiments, Vertex ML Metadata)\\nHooking into model and dataset versioning\\nModel and data lineage\\nSection 6: Monitoring ML solutions (~14% of the exam)\\n6.1 Identifying risks to ML solutions. Considerations include:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<raw> > llm:ChatVertexAI] [4.76s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"\",\n",
      "        \"generation_info\": {\n",
      "          \"is_blocked\": false,\n",
      "          \"safety_ratings\": [\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
      "              \"probability_label\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
      "              \"probability_label\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
      "              \"probability_label\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
      "              \"probability_label\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            }\n",
      "          ],\n",
      "          \"citation_metadata\": null,\n",
      "          \"usage_metadata\": {\n",
      "            \"prompt_token_count\": 459,\n",
      "            \"candidates_token_count\": 306,\n",
      "            \"total_token_count\": 765\n",
      "          }\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"function_call\": {\n",
      "                \"name\": \"DynamicGraph\",\n",
      "                \"arguments\": \"{\\\"nodes\\\": [{\\\"type\\\": \\\"Model deployment\\\", \\\"id\\\": \\\"Continuous integration and continuous delivery (CI/CD)\\\"}, {\\\"id\\\": \\\"Cloud Build\\\", \\\"type\\\": \\\"Model deployment\\\"}, {\\\"id\\\": \\\"Jenkins\\\", \\\"type\\\": \\\"Model deployment\\\"}, {\\\"type\\\": \\\"Model Artifact & Version Tracking\\\", \\\"id\\\": \\\"Vertex AI Experiments\\\"}, {\\\"type\\\": \\\"Model Artifact & Version Tracking\\\", \\\"id\\\": \\\"Vertex ML Metadata\\\"}, {\\\"id\\\": \\\"Model and dataset versioning\\\", \\\"type\\\": \\\"Model & Dataset Versioning\\\"}, {\\\"id\\\": \\\"Model and data lineage\\\", \\\"type\\\": \\\"Model & Data Lineage\\\"}], \\\"relationships\\\": [{\\\"type\\\": \\\"Examples of\\\", \\\"source_node_type\\\": \\\"Model deployment\\\", \\\"target_node_id\\\": \\\"Cloud Build\\\", \\\"target_node_type\\\": \\\"Model deployment\\\", \\\"source_node_id\\\": \\\"Continuous integration and continuous delivery (CI/CD)\\\"}, {\\\"target_node_id\\\": \\\"Jenkins\\\", \\\"target_node_type\\\": \\\"Model deployment\\\", \\\"type\\\": \\\"Examples of\\\", \\\"source_node_type\\\": \\\"Model deployment\\\", \\\"source_node_id\\\": \\\"Continuous integration and continuous delivery (CI/CD)\\\"}, {\\\"target_node_type\\\": \\\"Model Artifact & Version Tracking\\\", \\\"source_node_type\\\": \\\"Section\\\", \\\"source_node_id\\\": \\\"5.3 Tracking and auditing metadata\\\", \\\"type\\\": \\\"Examples of\\\", \\\"target_node_id\\\": \\\"Vertex AI Experiments\\\"}, {\\\"source_node_id\\\": \\\"5.3 Tracking and auditing metadata\\\", \\\"type\\\": \\\"Examples of\\\", \\\"source_node_type\\\": \\\"Section\\\", \\\"target_node_type\\\": \\\"Model Artifact & Version Tracking\\\", \\\"target_node_id\\\": \\\"Vertex ML Metadata\\\"}, {\\\"source_node_type\\\": \\\"Section\\\", \\\"target_node_id\\\": \\\"Model and dataset versioning\\\", \\\"source_node_id\\\": \\\"5.3 Tracking and auditing metadata\\\", \\\"target_node_type\\\": \\\"Model & Dataset Versioning\\\", \\\"type\\\": \\\"Examples of\\\"}, {\\\"target_node_id\\\": \\\"Model and data lineage\\\", \\\"source_node_type\\\": \\\"Section\\\", \\\"type\\\": \\\"Examples of\\\", \\\"source_node_id\\\": \\\"5.3 Tracking and auditing metadata\\\", \\\"target_node_type\\\": \\\"Model & Data Lineage\\\"}]}\"\n",
      "              }\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"is_blocked\": false,\n",
      "              \"safety_ratings\": [\n",
      "                {\n",
      "                  \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
      "                  \"probability_label\": \"NEGLIGIBLE\",\n",
      "                  \"blocked\": false\n",
      "                },\n",
      "                {\n",
      "                  \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
      "                  \"probability_label\": \"NEGLIGIBLE\",\n",
      "                  \"blocked\": false\n",
      "                },\n",
      "                {\n",
      "                  \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
      "                  \"probability_label\": \"NEGLIGIBLE\",\n",
      "                  \"blocked\": false\n",
      "                },\n",
      "                {\n",
      "                  \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
      "                  \"probability_label\": \"NEGLIGIBLE\",\n",
      "                  \"blocked\": false\n",
      "                }\n",
      "              ],\n",
      "              \"citation_metadata\": null,\n",
      "              \"usage_metadata\": {\n",
      "                \"prompt_token_count\": 459,\n",
      "                \"candidates_token_count\": 306,\n",
      "                \"total_token_count\": 765\n",
      "              }\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-f6e404bf-2836-4569-8ce9-81e2ee87f24f-0\",\n",
      "            \"tool_calls\": [\n",
      "              {\n",
      "                \"name\": \"DynamicGraph\",\n",
      "                \"args\": {\n",
      "                  \"nodes\": [\n",
      "                    {\n",
      "                      \"type\": \"Model deployment\",\n",
      "                      \"id\": \"Continuous integration and continuous delivery (CI/CD)\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"Cloud Build\",\n",
      "                      \"type\": \"Model deployment\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"Jenkins\",\n",
      "                      \"type\": \"Model deployment\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"Model Artifact & Version Tracking\",\n",
      "                      \"id\": \"Vertex AI Experiments\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"Model Artifact & Version Tracking\",\n",
      "                      \"id\": \"Vertex ML Metadata\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"Model and dataset versioning\",\n",
      "                      \"type\": \"Model & Dataset Versioning\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"Model and data lineage\",\n",
      "                      \"type\": \"Model & Data Lineage\"\n",
      "                    }\n",
      "                  ],\n",
      "                  \"relationships\": [\n",
      "                    {\n",
      "                      \"type\": \"Examples of\",\n",
      "                      \"source_node_type\": \"Model deployment\",\n",
      "                      \"target_node_id\": \"Cloud Build\",\n",
      "                      \"target_node_type\": \"Model deployment\",\n",
      "                      \"source_node_id\": \"Continuous integration and continuous delivery (CI/CD)\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"target_node_id\": \"Jenkins\",\n",
      "                      \"target_node_type\": \"Model deployment\",\n",
      "                      \"type\": \"Examples of\",\n",
      "                      \"source_node_type\": \"Model deployment\",\n",
      "                      \"source_node_id\": \"Continuous integration and continuous delivery (CI/CD)\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"target_node_type\": \"Model Artifact & Version Tracking\",\n",
      "                      \"source_node_type\": \"Section\",\n",
      "                      \"source_node_id\": \"5.3 Tracking and auditing metadata\",\n",
      "                      \"type\": \"Examples of\",\n",
      "                      \"target_node_id\": \"Vertex AI Experiments\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"source_node_id\": \"5.3 Tracking and auditing metadata\",\n",
      "                      \"type\": \"Examples of\",\n",
      "                      \"source_node_type\": \"Section\",\n",
      "                      \"target_node_type\": \"Model Artifact & Version Tracking\",\n",
      "                      \"target_node_id\": \"Vertex ML Metadata\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"source_node_type\": \"Section\",\n",
      "                      \"target_node_id\": \"Model and dataset versioning\",\n",
      "                      \"source_node_id\": \"5.3 Tracking and auditing metadata\",\n",
      "                      \"target_node_type\": \"Model & Dataset Versioning\",\n",
      "                      \"type\": \"Examples of\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"target_node_id\": \"Model and data lineage\",\n",
      "                      \"source_node_type\": \"Section\",\n",
      "                      \"type\": \"Examples of\",\n",
      "                      \"source_node_id\": \"5.3 Tracking and auditing metadata\",\n",
      "                      \"target_node_type\": \"Model & Data Lineage\"\n",
      "                    }\n",
      "                  ]\n",
      "                },\n",
      "                \"id\": \"f8e35e43-3a2e-473d-8333-818d73803e53\"\n",
      "              }\n",
      "            ],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<raw>] [4.76s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence > chain:RunnableLambda] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence > parser:PydanticToolsParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence > parser:PydanticToolsParser] [1ms] Exiting Parser run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence] [2ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableLambda] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error>] [4ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error>] [6ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks] [9ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [4.78s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"Building secure ML systems (e.g., protecting against unintentional exploitation of data or models, hacking)\\nAligning with Googles Responsible AI practices (e.g., biases)\\nAssessing ML solution readiness (e.g., data bias, fairness)\\nModel explainability on Vertex AI (e.g., Vertex AI Prediction)\\n6.2 Monitoring, testing, and troubleshooting ML solutions. Considerations include:\\nEstablishing continuous evaluation metrics (e.g., Vertex AI Model Monitoring, Explainable AI)\\nMonitoring for training-serving skew\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"Building secure ML systems (e.g., protecting against unintentional exploitation of data or models, hacking)\\nAligning with Googles Responsible AI practices (e.g., biases)\\nAssessing ML solution readiness (e.g., data bias, fairness)\\nModel explainability on Vertex AI (e.g., Vertex AI Prediction)\\n6.2 Monitoring, testing, and troubleshooting ML solutions. Considerations include:\\nEstablishing continuous evaluation metrics (e.g., Vertex AI Model Monitoring, Explainable AI)\\nMonitoring for training-serving skew\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<raw>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<raw> > llm:ChatVertexAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: Extract all Entities\\nHuman: Tip: Make sure to answer in the correct format and do not include any explanations. Use the given format to extract information from the following input: Building secure ML systems (e.g., protecting against unintentional exploitation of data or models, hacking)\\nAligning with Googles Responsible AI practices (e.g., biases)\\nAssessing ML solution readiness (e.g., data bias, fairness)\\nModel explainability on Vertex AI (e.g., Vertex AI Prediction)\\n6.2 Monitoring, testing, and troubleshooting ML solutions. Considerations include:\\nEstablishing continuous evaluation metrics (e.g., Vertex AI Model Monitoring, Explainable AI)\\nMonitoring for training-serving skew\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<raw> > llm:ChatVertexAI] [5.24s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"\",\n",
      "        \"generation_info\": {\n",
      "          \"is_blocked\": false,\n",
      "          \"safety_ratings\": [\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
      "              \"probability_label\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
      "              \"probability_label\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
      "              \"probability_label\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
      "              \"probability_label\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            }\n",
      "          ],\n",
      "          \"citation_metadata\": null,\n",
      "          \"usage_metadata\": {\n",
      "            \"prompt_token_count\": 471,\n",
      "            \"candidates_token_count\": 366,\n",
      "            \"total_token_count\": 837\n",
      "          }\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"function_call\": {\n",
      "                \"name\": \"DynamicGraph\",\n",
      "                \"arguments\": \"{\\\"relationships\\\": [{\\\"target_node_id\\\": \\\"Protecting against unintentional exploitation of data or models\\\", \\\"source_node_id\\\": \\\"Building secure ML systems\\\", \\\"type\\\": \\\"Subtopic\\\", \\\"source_node_type\\\": \\\"Entity\\\", \\\"target_node_type\\\": \\\"Entity\\\"}, {\\\"source_node_type\\\": \\\"Entity\\\", \\\"target_node_id\\\": \\\"Hacking\\\", \\\"target_node_type\\\": \\\"Entity\\\", \\\"type\\\": \\\"Subtopic\\\", \\\"source_node_id\\\": \\\"Building secure ML systems\\\"}, {\\\"target_node_id\\\": \\\"Biases\\\", \\\"source_node_type\\\": \\\"Entity\\\", \\\"source_node_id\\\": \\\"Aligning with Google\\\\u2019s Responsible AI practices\\\", \\\"type\\\": \\\"Subtopic\\\", \\\"target_node_type\\\": \\\"Entity\\\"}, {\\\"target_node_id\\\": \\\"Data bias\\\", \\\"target_node_type\\\": \\\"Entity\\\", \\\"source_node_id\\\": \\\"Assessing ML solution readiness\\\", \\\"source_node_type\\\": \\\"Entity\\\", \\\"type\\\": \\\"Subtopic\\\"}, {\\\"type\\\": \\\"Subtopic\\\", \\\"target_node_type\\\": \\\"Entity\\\", \\\"source_node_id\\\": \\\"Assessing ML solution readiness\\\", \\\"source_node_type\\\": \\\"Entity\\\", \\\"target_node_id\\\": \\\"Fairness\\\"}, {\\\"target_node_id\\\": \\\"Vertex AI Prediction\\\", \\\"source_node_type\\\": \\\"Entity\\\", \\\"source_node_id\\\": \\\"Model explainability on Vertex AI\\\", \\\"type\\\": \\\"Subtopic\\\", \\\"target_node_type\\\": \\\"Entity\\\"}, {\\\"source_node_type\\\": \\\"Entity\\\", \\\"source_node_id\\\": \\\"Monitoring, testing, and troubleshooting ML solutions\\\", \\\"target_node_id\\\": \\\"Continuous evaluation metrics\\\", \\\"target_node_type\\\": \\\"Entity\\\", \\\"type\\\": \\\"Subtopic\\\"}, {\\\"target_node_id\\\": \\\"Vertex AI Model Monitoring, Explainable AI\\\", \\\"type\\\": \\\"Subtopic\\\", \\\"source_node_type\\\": \\\"Entity\\\", \\\"source_node_id\\\": \\\"Monitoring, testing, and troubleshooting ML solutions\\\", \\\"target_node_type\\\": \\\"Entity\\\"}, {\\\"target_node_id\\\": \\\"Training-serving skew\\\", \\\"source_node_type\\\": \\\"Entity\\\", \\\"source_node_id\\\": \\\"Monitoring, testing, and troubleshooting ML solutions\\\", \\\"type\\\": \\\"Subtopic\\\", \\\"target_node_type\\\": \\\"Entity\\\"}], \\\"nodes\\\": [{\\\"id\\\": \\\"Building secure ML systems\\\", \\\"type\\\": \\\"Entity\\\"}, {\\\"id\\\": \\\"Aligning with Google\\\\u2019s Responsible AI practices\\\", \\\"type\\\": \\\"Entity\\\"}, {\\\"type\\\": \\\"Entity\\\", \\\"id\\\": \\\"Assessing ML solution readiness\\\"}, {\\\"type\\\": \\\"Entity\\\", \\\"id\\\": \\\"Model explainability on Vertex AI\\\"}, {\\\"type\\\": \\\"Entity\\\", \\\"id\\\": \\\"Monitoring, testing, and troubleshooting ML solutions\\\"}]}\"\n",
      "              }\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"is_blocked\": false,\n",
      "              \"safety_ratings\": [\n",
      "                {\n",
      "                  \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
      "                  \"probability_label\": \"NEGLIGIBLE\",\n",
      "                  \"blocked\": false\n",
      "                },\n",
      "                {\n",
      "                  \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
      "                  \"probability_label\": \"NEGLIGIBLE\",\n",
      "                  \"blocked\": false\n",
      "                },\n",
      "                {\n",
      "                  \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
      "                  \"probability_label\": \"NEGLIGIBLE\",\n",
      "                  \"blocked\": false\n",
      "                },\n",
      "                {\n",
      "                  \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
      "                  \"probability_label\": \"NEGLIGIBLE\",\n",
      "                  \"blocked\": false\n",
      "                }\n",
      "              ],\n",
      "              \"citation_metadata\": null,\n",
      "              \"usage_metadata\": {\n",
      "                \"prompt_token_count\": 471,\n",
      "                \"candidates_token_count\": 366,\n",
      "                \"total_token_count\": 837\n",
      "              }\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-42a021cd-828c-4580-a567-88b57522be65-0\",\n",
      "            \"tool_calls\": [\n",
      "              {\n",
      "                \"name\": \"DynamicGraph\",\n",
      "                \"args\": {\n",
      "                  \"relationships\": [\n",
      "                    {\n",
      "                      \"target_node_id\": \"Protecting against unintentional exploitation of data or models\",\n",
      "                      \"source_node_id\": \"Building secure ML systems\",\n",
      "                      \"type\": \"Subtopic\",\n",
      "                      \"source_node_type\": \"Entity\",\n",
      "                      \"target_node_type\": \"Entity\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"source_node_type\": \"Entity\",\n",
      "                      \"target_node_id\": \"Hacking\",\n",
      "                      \"target_node_type\": \"Entity\",\n",
      "                      \"type\": \"Subtopic\",\n",
      "                      \"source_node_id\": \"Building secure ML systems\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"target_node_id\": \"Biases\",\n",
      "                      \"source_node_type\": \"Entity\",\n",
      "                      \"source_node_id\": \"Aligning with Googles Responsible AI practices\",\n",
      "                      \"type\": \"Subtopic\",\n",
      "                      \"target_node_type\": \"Entity\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"target_node_id\": \"Data bias\",\n",
      "                      \"target_node_type\": \"Entity\",\n",
      "                      \"source_node_id\": \"Assessing ML solution readiness\",\n",
      "                      \"source_node_type\": \"Entity\",\n",
      "                      \"type\": \"Subtopic\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"Subtopic\",\n",
      "                      \"target_node_type\": \"Entity\",\n",
      "                      \"source_node_id\": \"Assessing ML solution readiness\",\n",
      "                      \"source_node_type\": \"Entity\",\n",
      "                      \"target_node_id\": \"Fairness\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"target_node_id\": \"Vertex AI Prediction\",\n",
      "                      \"source_node_type\": \"Entity\",\n",
      "                      \"source_node_id\": \"Model explainability on Vertex AI\",\n",
      "                      \"type\": \"Subtopic\",\n",
      "                      \"target_node_type\": \"Entity\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"source_node_type\": \"Entity\",\n",
      "                      \"source_node_id\": \"Monitoring, testing, and troubleshooting ML solutions\",\n",
      "                      \"target_node_id\": \"Continuous evaluation metrics\",\n",
      "                      \"target_node_type\": \"Entity\",\n",
      "                      \"type\": \"Subtopic\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"target_node_id\": \"Vertex AI Model Monitoring, Explainable AI\",\n",
      "                      \"type\": \"Subtopic\",\n",
      "                      \"source_node_type\": \"Entity\",\n",
      "                      \"source_node_id\": \"Monitoring, testing, and troubleshooting ML solutions\",\n",
      "                      \"target_node_type\": \"Entity\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"target_node_id\": \"Training-serving skew\",\n",
      "                      \"source_node_type\": \"Entity\",\n",
      "                      \"source_node_id\": \"Monitoring, testing, and troubleshooting ML solutions\",\n",
      "                      \"type\": \"Subtopic\",\n",
      "                      \"target_node_type\": \"Entity\"\n",
      "                    }\n",
      "                  ],\n",
      "                  \"nodes\": [\n",
      "                    {\n",
      "                      \"id\": \"Building secure ML systems\",\n",
      "                      \"type\": \"Entity\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"Aligning with Googles Responsible AI practices\",\n",
      "                      \"type\": \"Entity\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"Entity\",\n",
      "                      \"id\": \"Assessing ML solution readiness\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"Entity\",\n",
      "                      \"id\": \"Model explainability on Vertex AI\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"Entity\",\n",
      "                      \"id\": \"Monitoring, testing, and troubleshooting ML solutions\"\n",
      "                    }\n",
      "                  ]\n",
      "                },\n",
      "                \"id\": \"b5b8cc95-358b-4961-9369-dd573e04f68f\"\n",
      "              }\n",
      "            ],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<raw>] [5.24s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence > chain:RunnableLambda] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence > parser:PydanticToolsParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence > parser:PydanticToolsParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence] [2ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableLambda] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error>] [5ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error>] [10ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks] [19ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [5.27s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"Monitoring for feature attribution drift\\nMonitoring model performance against baselines, simpler models, and across the time dimension\\nCommon training and serving errors\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"Monitoring for feature attribution drift\\nMonitoring model performance against baselines, simpler models, and across the time dimension\\nCommon training and serving errors\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<raw>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<raw> > llm:ChatVertexAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: Extract all Entities\\nHuman: Tip: Make sure to answer in the correct format and do not include any explanations. Use the given format to extract information from the following input: Monitoring for feature attribution drift\\nMonitoring model performance against baselines, simpler models, and across the time dimension\\nCommon training and serving errors\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<raw> > llm:ChatVertexAI] [4.28s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"\",\n",
      "        \"generation_info\": {\n",
      "          \"is_blocked\": false,\n",
      "          \"safety_ratings\": [\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
      "              \"probability_label\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
      "              \"probability_label\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
      "              \"probability_label\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
      "              \"probability_label\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            }\n",
      "          ],\n",
      "          \"citation_metadata\": null,\n",
      "          \"usage_metadata\": {\n",
      "            \"prompt_token_count\": 387,\n",
      "            \"candidates_token_count\": 247,\n",
      "            \"total_token_count\": 634\n",
      "          }\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"function_call\": {\n",
      "                \"name\": \"DynamicGraph\",\n",
      "                \"arguments\": \"{\\\"nodes\\\": [{\\\"id\\\": \\\"Monitoring\\\", \\\"type\\\": \\\"Process\\\"}, {\\\"id\\\": \\\"Feature attribution drift\\\", \\\"type\\\": \\\"Concept\\\"}, {\\\"type\\\": \\\"Metric\\\", \\\"id\\\": \\\"Model performance\\\"}, {\\\"type\\\": \\\"Model\\\", \\\"id\\\": \\\"Baselines\\\"}, {\\\"id\\\": \\\"Simpler models\\\", \\\"type\\\": \\\"Model\\\"}, {\\\"type\\\": \\\"Dimension\\\", \\\"id\\\": \\\"Time dimension\\\"}, {\\\"type\\\": \\\"Error\\\", \\\"id\\\": \\\"Training errors\\\"}, {\\\"id\\\": \\\"Serving errors\\\", \\\"type\\\": \\\"Error\\\"}], \\\"relationships\\\": [{\\\"target_node_type\\\": \\\"Concept\\\", \\\"source_node_type\\\": \\\"Process\\\", \\\"type\\\": \\\"FOR\\\", \\\"target_node_id\\\": \\\"Feature attribution drift\\\", \\\"source_node_id\\\": \\\"Monitoring\\\"}, {\\\"target_node_id\\\": \\\"Model performance\\\", \\\"type\\\": \\\"EVALUATES\\\", \\\"target_node_type\\\": \\\"Metric\\\", \\\"source_node_type\\\": \\\"Process\\\", \\\"source_node_id\\\": \\\"Monitoring\\\"}, {\\\"target_node_id\\\": \\\"Baselines\\\", \\\"source_node_id\\\": \\\"Model performance\\\", \\\"type\\\": \\\"AGAINST\\\", \\\"target_node_type\\\": \\\"Model\\\", \\\"source_node_type\\\": \\\"Metric\\\"}, {\\\"target_node_type\\\": \\\"Model\\\", \\\"type\\\": \\\"AGAINST\\\", \\\"target_node_id\\\": \\\"Simpler models\\\", \\\"source_node_id\\\": \\\"Model performance\\\", \\\"source_node_type\\\": \\\"Metric\\\"}, {\\\"target_node_type\\\": \\\"Dimension\\\", \\\"target_node_id\\\": \\\"Time dimension\\\", \\\"type\\\": \\\"ACROSS\\\", \\\"source_node_type\\\": \\\"Metric\\\", \\\"source_node_id\\\": \\\"Model performance\\\"}, {\\\"source_node_id\\\": \\\"Monitoring\\\", \\\"target_node_id\\\": \\\"Training errors\\\", \\\"target_node_type\\\": \\\"Error\\\", \\\"type\\\": \\\"IDENTIFIES\\\", \\\"source_node_type\\\": \\\"Process\\\"}, {\\\"target_node_type\\\": \\\"Error\\\", \\\"source_node_type\\\": \\\"Process\\\", \\\"target_node_id\\\": \\\"Serving errors\\\", \\\"type\\\": \\\"IDENTIFIES\\\", \\\"source_node_id\\\": \\\"Monitoring\\\"}]}\"\n",
      "              }\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"is_blocked\": false,\n",
      "              \"safety_ratings\": [\n",
      "                {\n",
      "                  \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
      "                  \"probability_label\": \"NEGLIGIBLE\",\n",
      "                  \"blocked\": false\n",
      "                },\n",
      "                {\n",
      "                  \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
      "                  \"probability_label\": \"NEGLIGIBLE\",\n",
      "                  \"blocked\": false\n",
      "                },\n",
      "                {\n",
      "                  \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
      "                  \"probability_label\": \"NEGLIGIBLE\",\n",
      "                  \"blocked\": false\n",
      "                },\n",
      "                {\n",
      "                  \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
      "                  \"probability_label\": \"NEGLIGIBLE\",\n",
      "                  \"blocked\": false\n",
      "                }\n",
      "              ],\n",
      "              \"citation_metadata\": null,\n",
      "              \"usage_metadata\": {\n",
      "                \"prompt_token_count\": 387,\n",
      "                \"candidates_token_count\": 247,\n",
      "                \"total_token_count\": 634\n",
      "              }\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-5e2f58ad-273e-4460-8a3e-a35dd101d4bf-0\",\n",
      "            \"tool_calls\": [\n",
      "              {\n",
      "                \"name\": \"DynamicGraph\",\n",
      "                \"args\": {\n",
      "                  \"nodes\": [\n",
      "                    {\n",
      "                      \"id\": \"Monitoring\",\n",
      "                      \"type\": \"Process\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"Feature attribution drift\",\n",
      "                      \"type\": \"Concept\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"Metric\",\n",
      "                      \"id\": \"Model performance\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"Model\",\n",
      "                      \"id\": \"Baselines\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"Simpler models\",\n",
      "                      \"type\": \"Model\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"Dimension\",\n",
      "                      \"id\": \"Time dimension\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"type\": \"Error\",\n",
      "                      \"id\": \"Training errors\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"id\": \"Serving errors\",\n",
      "                      \"type\": \"Error\"\n",
      "                    }\n",
      "                  ],\n",
      "                  \"relationships\": [\n",
      "                    {\n",
      "                      \"target_node_type\": \"Concept\",\n",
      "                      \"source_node_type\": \"Process\",\n",
      "                      \"type\": \"FOR\",\n",
      "                      \"target_node_id\": \"Feature attribution drift\",\n",
      "                      \"source_node_id\": \"Monitoring\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"target_node_id\": \"Model performance\",\n",
      "                      \"type\": \"EVALUATES\",\n",
      "                      \"target_node_type\": \"Metric\",\n",
      "                      \"source_node_type\": \"Process\",\n",
      "                      \"source_node_id\": \"Monitoring\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"target_node_id\": \"Baselines\",\n",
      "                      \"source_node_id\": \"Model performance\",\n",
      "                      \"type\": \"AGAINST\",\n",
      "                      \"target_node_type\": \"Model\",\n",
      "                      \"source_node_type\": \"Metric\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"target_node_type\": \"Model\",\n",
      "                      \"type\": \"AGAINST\",\n",
      "                      \"target_node_id\": \"Simpler models\",\n",
      "                      \"source_node_id\": \"Model performance\",\n",
      "                      \"source_node_type\": \"Metric\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"target_node_type\": \"Dimension\",\n",
      "                      \"target_node_id\": \"Time dimension\",\n",
      "                      \"type\": \"ACROSS\",\n",
      "                      \"source_node_type\": \"Metric\",\n",
      "                      \"source_node_id\": \"Model performance\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"source_node_id\": \"Monitoring\",\n",
      "                      \"target_node_id\": \"Training errors\",\n",
      "                      \"target_node_type\": \"Error\",\n",
      "                      \"type\": \"IDENTIFIES\",\n",
      "                      \"source_node_type\": \"Process\"\n",
      "                    },\n",
      "                    {\n",
      "                      \"target_node_type\": \"Error\",\n",
      "                      \"source_node_type\": \"Process\",\n",
      "                      \"target_node_id\": \"Serving errors\",\n",
      "                      \"type\": \"IDENTIFIES\",\n",
      "                      \"source_node_id\": \"Monitoring\"\n",
      "                    }\n",
      "                  ]\n",
      "                },\n",
      "                \"id\": \"c48a2956-08e4-4efd-a201-754133f0a8f2\"\n",
      "              }\n",
      "            ],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableParallel<raw>] [4.28s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence > chain:RunnableLambda] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence > parser:PydanticToolsParser] Entering Parser run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence > parser:PydanticToolsParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableSequence] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableLambda] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error> > chain:RunnableLambda] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error> > chain:RunnableParallel<parsed,parsing_error>] [4ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks > chain:RunnableAssign<parsed,parsing_error>] [7ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:RunnableWithFallbacks] [10ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [4.30s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n"
     ]
    }
   ],
   "source": [
    "#graph_documents = llm_transformer.convert_to_graph_documents(documents)\n",
    "graph_documents = llm_transformer.convert_to_graph_documents(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e825ef-f8e9-40dc-9b4a-c0f3b31cb38d",
   "metadata": {},
   "source": [
    "Check content of **Graph Documents**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9276a593-f0a4-4a76-952b-f261dd51b268",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph_documents_len: 20\n",
      " \n",
      "graphdoc_idx: 0\n",
      "Len doc_page_content 71\n",
      "No. doc_metadata: 0\n",
      "No. nodes: 1\n",
      "Node: id='Current Professional Machine Learning Engineer Certification Exam Guide' type='Text'\n",
      "No. relationships: 0\n",
      " \n",
      "graphdoc_idx: 1\n",
      "Len doc_page_content 506\n",
      "No. doc_metadata: 0\n",
      "No. nodes: 8\n",
      "Node: id='Machine Learning Engineer' type='Person'\n",
      "Node: id='Ml Models' type='Object'\n",
      "Node: id='Google Cloud Technologies' type='Object'\n",
      "Node: id='Proven Models And Techniques' type='Object'\n",
      "Node: id='Large Datasets' type='Object'\n",
      "Node: id='Ml-Based Applications' type='Object'\n",
      "Node: id='Other Job Roles' type='Object'\n",
      "Node: id='Responsible Ai' type='Object'\n",
      "No. relationships: 9\n",
      "Relationship: source=Node(id='Machine Learning Engineer', type='Person') target=Node(id='Ml Models', type='Object') type='BUILDS'\n",
      "Relationship: source=Node(id='Machine Learning Engineer', type='Person') target=Node(id='Ml Models', type='Object') type='EVALUATES'\n",
      "Relationship: source=Node(id='Machine Learning Engineer', type='Person') target=Node(id='Ml Models', type='Object') type='PRODUCTIONIZES'\n",
      "Relationship: source=Node(id='Machine Learning Engineer', type='Person') target=Node(id='Ml Models', type='Object') type='OPTIMIZES'\n",
      "Relationship: source=Node(id='Machine Learning Engineer', type='Person') target=Node(id='Google Cloud Technologies', type='Object') type='USES'\n",
      "Relationship: source=Node(id='Machine Learning Engineer', type='Person') target=Node(id='Proven Models And Techniques', type='Object') type='KNOWLEDGE_OF'\n",
      "Relationship: source=Node(id='Machine Learning Engineer', type='Person') target=Node(id='Large Datasets', type='Object') type='HANDLES'\n",
      "Relationship: source=Node(id='Machine Learning Engineer', type='Person') target=Node(id='Ml-Based Applications', type='Object') type='COLLABORATES_WITH_OTHER_JOB_ROLES_TO_ENSURE_LONG-TERM_SUCCESS_OF'\n",
      "Relationship: source=Node(id='Machine Learning Engineer', type='Person') target=Node(id='Responsible Ai', type='Object') type='CONSIDERS_THROUGHOUT_THE_ML_MODEL_DEVELOPMENT_PROCESS'\n",
      " \n",
      "graphdoc_idx: 2\n",
      "Len doc_page_content 507\n",
      "No. doc_metadata: 0\n",
      "No. nodes: 11\n",
      "Node: id='Ml Engineer' type='Person'\n",
      "Node: id='Data Platforms' type='Software'\n",
      "Node: id='Distributed Data Processing Tools' type='Software'\n",
      "Node: id='Model Architecture' type='Model'\n",
      "Node: id='Data And Ml Pipeline Creation' type='Process'\n",
      "Node: id='Metrics Interpretation' type='Process'\n",
      "Node: id='Mlops' type='Concept'\n",
      "Node: id='Application Development' type='Process'\n",
      "Node: id='Infrastructure Management' type='Process'\n",
      "Node: id='Data Engineering' type='Process'\n",
      "Node: id='Data Governance' type='Process'\n",
      "No. relationships: 10\n",
      "Relationship: source=Node(id='Ml Engineer', type='Person') target=Node(id='Data Platforms', type='Software') type='USES'\n",
      "Relationship: source=Node(id='Ml Engineer', type='Person') target=Node(id='Distributed Data Processing Tools', type='Software') type='USES'\n",
      "Relationship: source=Node(id='Ml Engineer', type='Person') target=Node(id='Model Architecture', type='Model') type='CREATES'\n",
      "Relationship: source=Node(id='Ml Engineer', type='Person') target=Node(id='Data And Ml Pipeline Creation', type='Process') type='CREATES'\n",
      "Relationship: source=Node(id='Ml Engineer', type='Person') target=Node(id='Metrics Interpretation', type='Process') type='PERFORMS'\n",
      "Relationship: source=Node(id='Ml Engineer', type='Person') target=Node(id='Mlops', type='Concept') type='UNDERSTANDS'\n",
      "Relationship: source=Node(id='Ml Engineer', type='Person') target=Node(id='Application Development', type='Process') type='PERFORMS'\n",
      "Relationship: source=Node(id='Ml Engineer', type='Person') target=Node(id='Infrastructure Management', type='Process') type='PERFORMS'\n",
      "Relationship: source=Node(id='Ml Engineer', type='Person') target=Node(id='Data Engineering', type='Process') type='PERFORMS'\n",
      "Relationship: source=Node(id='Ml Engineer', type='Person') target=Node(id='Data Governance', type='Process') type='PERFORMS'\n",
      " \n",
      "graphdoc_idx: 3\n",
      "Len doc_page_content 113\n",
      "No. doc_metadata: 0\n",
      "No. nodes: 2\n",
      "Node: id='Ml Engineer' type='Person'\n",
      "Node: id='Models' type='Concept'\n",
      "No. relationships: 1\n",
      "Relationship: source=Node(id='Ml Engineer', type='Person') target=Node(id='Models', type='Concept') type='DESIGNS_AND_CREATES'\n",
      " \n",
      "graphdoc_idx: 4\n",
      "Len doc_page_content 191\n",
      "No. doc_metadata: 0\n",
      "No. nodes: 0\n",
      "No. relationships: 0\n",
      " \n",
      "graphdoc_idx: 5\n",
      "Len doc_page_content 511\n",
      "No. doc_metadata: 0\n",
      "No. nodes: 0\n",
      "No. relationships: 0\n",
      " \n",
      "graphdoc_idx: 6\n",
      "Len doc_page_content 33\n",
      "No. doc_metadata: 0\n",
      "No. nodes: 3\n",
      "Node: id='Generative Ai For Developers' type='Book'\n",
      "Node: id='Book' type='Book'\n",
      "Node: id='Generative Ai' type='Topic'\n",
      "No. relationships: 2\n",
      "Relationship: source=Node(id='Generative Ai For Developers', type='Book') target=Node(id='Book', type='Book') type='INSTANCE_OF'\n",
      "Relationship: source=Node(id='Book', type='Book') target=Node(id='Generative Ai', type='Topic') type='CONCERNING'\n",
      " \n",
      "graphdoc_idx: 7\n",
      "Len doc_page_content 491\n",
      "No. doc_metadata: 0\n",
      "No. nodes: 4\n",
      "Node: id='Bigquery Ml' type='Cloud ml platform service'\n",
      "Node: id='Linear And Binary Classification, Regression, Time-Series, Matrix Factorization, Boosted Trees, Autoencoders' type='Ml model'\n",
      "Node: id='Feature Engineering Or Selection' type='Data mining'\n",
      "Node: id='Predictions' type='Results'\n",
      "No. relationships: 3\n",
      "Relationship: source=Node(id='Bigquery Ml', type='Cloud ml platform service') target=Node(id='Linear And Binary Classification, Regression, Time-Series, Matrix Factorization, Boosted Trees, Autoencoders', type='Ml model') type='HAS'\n",
      "Relationship: source=Node(id='Linear And Binary Classification, Regression, Time-Series, Matrix Factorization, Boosted Trees, Autoencoders', type='Ml model') target=Node(id='Feature Engineering Or Selection', type='Data mining') type='REQUIRES'\n",
      "Relationship: source=Node(id='Feature Engineering Or Selection', type='Data mining') target=Node(id='Predictions', type='Results') type='PRODUCES'\n",
      " \n",
      "graphdoc_idx: 8\n",
      "Len doc_page_content 483\n",
      "No. doc_metadata: 0\n",
      "No. nodes: 20\n",
      "Node: id='Ml Apis' type='Technology'\n",
      "Node: id='Cloud Vision Api' type='Technology'\n",
      "Node: id='Natural Language Api' type='Technology'\n",
      "Node: id='Cloud Speech Api' type='Technology'\n",
      "Node: id='Translation' type='Technology'\n",
      "Node: id='Industry-Specific Apis' type='Technology'\n",
      "Node: id='Document Ai Api' type='Technology'\n",
      "Node: id='Retail Api' type='Technology'\n",
      "Node: id='Automl' type='Technology'\n",
      "Node: id='Training Models' type='Technology'\n",
      "Node: id='Feature Selection' type='Technology'\n",
      "Node: id='Data Labeling' type='Technology'\n",
      "Node: id='Tabular Workflows On Automl' type='Technology'\n",
      "Node: id='Data' type='Data'\n",
      "Node: id='Tabular' type='Data'\n",
      "Node: id='Text' type='Data'\n",
      "Node: id='Speech' type='Data'\n",
      "Node: id='Images' type='Data'\n",
      "Node: id='Videos' type='Data'\n",
      "Node: id='Custom Models' type='Technology'\n",
      "No. relationships: 20\n",
      "Relationship: source=Node(id='Building Applications', type='Task') target=Node(id='Ml Apis', type='Technology') type='USED'\n",
      "Relationship: source=Node(id='Ml Apis', type='Technology') target=Node(id='Cloud Vision Api', type='Technology') type='EXAMPLE'\n",
      "Relationship: source=Node(id='Ml Apis', type='Technology') target=Node(id='Natural Language Api', type='Technology') type='EXAMPLE'\n",
      "Relationship: source=Node(id='Ml Apis', type='Technology') target=Node(id='Cloud Speech Api', type='Technology') type='EXAMPLE'\n",
      "Relationship: source=Node(id='Ml Apis', type='Technology') target=Node(id='Translation', type='Technology') type='EXAMPLE'\n",
      "Relationship: source=Node(id='Building Applications', type='Task') target=Node(id='Industry-Specific Apis', type='Technology') type='USED'\n",
      "Relationship: source=Node(id='Industry-Specific Apis', type='Technology') target=Node(id='Document Ai Api', type='Technology') type='EXAMPLE'\n",
      "Relationship: source=Node(id='Industry-Specific Apis', type='Technology') target=Node(id='Retail Api', type='Technology') type='EXAMPLE'\n",
      "Relationship: source=Node(id='1.3 Training Models By Using Automl.', type='Task') target=Node(id='Automl', type='Technology') type='USED'\n",
      "Relationship: source=Node(id='Automl', type='Technology') target=Node(id='Training Models', type='Technology') type='EXAMPLE'\n",
      "Relationship: source=Node(id='Training Models', type='Technology') target=Node(id='Feature Selection', type='Technology') type='SUBTASK'\n",
      "Relationship: source=Node(id='Training Models', type='Technology') target=Node(id='Data Labeling', type='Technology') type='SUBTASK'\n",
      "Relationship: source=Node(id='Training Models', type='Technology') target=Node(id='Tabular Workflows On Automl', type='Technology') type='SUBTASK'\n",
      "Relationship: source=Node(id='Training Models', type='Technology') target=Node(id='Data', type='Data') type='INPUT'\n",
      "Relationship: source=Node(id='Data', type='Data') target=Node(id='Tabular', type='Data') type='TYPE'\n",
      "Relationship: source=Node(id='Data', type='Data') target=Node(id='Text', type='Data') type='TYPE'\n",
      "Relationship: source=Node(id='Data', type='Data') target=Node(id='Speech', type='Data') type='TYPE'\n",
      "Relationship: source=Node(id='Data', type='Data') target=Node(id='Images', type='Data') type='TYPE'\n",
      "Relationship: source=Node(id='Data', type='Data') target=Node(id='Videos', type='Data') type='TYPE'\n",
      "Relationship: source=Node(id='Training Models', type='Technology') target=Node(id='Custom Models', type='Technology') type='OUTPUT'\n",
      " \n",
      "graphdoc_idx: 9\n",
      "Len doc_page_content 471\n",
      "No. doc_metadata: 0\n",
      "No. nodes: 2\n",
      "Node: id='Creating Forecasting Models Using Automl' type='Task'\n",
      "Node: id='Configuring And Debugging Trained Models' type='Task'\n",
      "No. relationships: 1\n",
      "Relationship: source=Node(id='Creating Forecasting Models Using Automl', type='Task') target=Node(id='Configuring And Debugging Trained Models', type='Task') type='RELATEDTASK'\n",
      " \n",
      "graphdoc_idx: 10\n",
      "Len doc_page_content 488\n",
      "No. doc_metadata: 0\n",
      "No. nodes: 10\n",
      "Node: id='Data Preprocessing' type='Process'\n",
      "Node: id='Dataflow' type='Tool'\n",
      "Node: id='Tensorflow Extended (Tfx)' type='Tool'\n",
      "Node: id='Bigquery' type='Tool'\n",
      "Node: id='Vertex Ai Feature Store' type='Tool'\n",
      "Node: id='Privacy Implications Of Data Usage And/Or Collection' type='Process'\n",
      "Node: id='Model Prototyping' type='Process'\n",
      "Node: id='Jupyter Notebooks' type='Tool'\n",
      "Node: id='Vertex Ai Workbench' type='Tool'\n",
      "Node: id='Notebooks On Dataproc' type='Tool'\n",
      "No. relationships: 9\n",
      "Relationship: source=Node(id='Data Preprocessing', type='Process') target=Node(id='Dataflow', type='Tool') type='USES'\n",
      "Relationship: source=Node(id='Data Preprocessing', type='Process') target=Node(id='Tensorflow Extended (Tfx)', type='Tool') type='USES'\n",
      "Relationship: source=Node(id='Data Preprocessing', type='Process') target=Node(id='Bigquery', type='Tool') type='USES'\n",
      "Relationship: source=Node(id='Data Preprocessing', type='Process') target=Node(id='Vertex Ai Feature Store', type='Tool') type='USES'\n",
      "Relationship: source=Node(id='Privacy Implications Of Data Usage And/Or Collection', type='Process') target=Node(id='Data Preprocessing', type='Process') type='AFFECTS'\n",
      "Relationship: source=Node(id='2.2 Model Prototyping', type='Process') target=Node(id='Model Prototyping', type='Process') type='SUBPROCESS_OF'\n",
      "Relationship: source=Node(id='Model Prototyping', type='Process') target=Node(id='Jupyter Notebooks', type='Tool') type='USES'\n",
      "Relationship: source=Node(id='2.2 Model Prototyping', type='Process') target=Node(id='Vertex Ai Workbench', type='Tool') type='USES'\n",
      "Relationship: source=Node(id='2.2 Model Prototyping', type='Process') target=Node(id='Notebooks On Dataproc', type='Tool') type='USES'\n",
      " \n",
      "graphdoc_idx: 11\n",
      "Len doc_page_content 506\n",
      "No. doc_metadata: 0\n",
      "No. nodes: 14\n",
      "Node: id='Security' type='Topic'\n",
      "Node: id='Spark' type='Technology'\n",
      "Node: id='Repositories' type='Infrastructure'\n",
      "Node: id='Tensorflow' type='Framework'\n",
      "Node: id='Pytorch' type='Framework'\n",
      "Node: id='Sklearn' type='Framework'\n",
      "Node: id='Jax' type='Framework'\n",
      "Node: id='Vertex Ai Workbench' type='Workbench'\n",
      "Node: id='Ml Experiments' type='Topic'\n",
      "Node: id='Code' type='Resource'\n",
      "Node: id='Models' type='Resource'\n",
      "Node: id='Vertex Ai Experiments' type='Environment'\n",
      "Node: id='Kubeflow Pipelines' type='Environment'\n",
      "Node: id='Vertex Ai Tensorboard' type='Environment'\n",
      "No. relationships: 11\n",
      "Relationship: source=Node(id='Security', type='Topic') target=Node(id='Vertex Ai Workbench', type='Workbench') type='BEST_PRACTICES'\n",
      "Relationship: source=Node(id='Spark', type='Technology') target=Node(id='Vertex Ai Workbench', type='Workbench') type='KERNEL_SUPPORT'\n",
      "Relationship: source=Node(id='Vertex Ai Workbench', type='Workbench') target=Node(id='Repositories', type='Infrastructure') type='INTEGRATION_SUPPORT'\n",
      "Relationship: source=Node(id='Vertex Ai Workbench', type='Workbench') target=Node(id='Tensorflow', type='Framework') type='DEVELOPMENT_SUPPORT'\n",
      "Relationship: source=Node(id='Vertex Ai Workbench', type='Workbench') target=Node(id='Pytorch', type='Framework') type='DEVELOPMENT_SUPPORT'\n",
      "Relationship: source=Node(id='Vertex Ai Workbench', type='Workbench') target=Node(id='Sklearn', type='Framework') type='DEVELOPMENT_SUPPORT'\n",
      "Relationship: source=Node(id='Vertex Ai Workbench', type='Workbench') target=Node(id='Jax', type='Framework') type='DEVELOPMENT_SUPPORT'\n",
      "Relationship: source=Node(id='Vertex Ai Workbench', type='Workbench') target=Node(id='Ml Experiments', type='Topic') type='TRACKING_SUPPORT'\n",
      "Relationship: source=Node(id='Ml Experiments', type='Topic') target=Node(id='Vertex Ai Experiments', type='Environment') type='COMPATIBILITY'\n",
      "Relationship: source=Node(id='Ml Experiments', type='Topic') target=Node(id='Kubeflow Pipelines', type='Environment') type='COMPATIBILITY'\n",
      "Relationship: source=Node(id='Ml Experiments', type='Topic') target=Node(id='Vertex Ai Tensorboard', type='Environment') type='COMPATIBILITY'\n",
      " \n",
      "graphdoc_idx: 12\n",
      "Len doc_page_content 464\n",
      "No. doc_metadata: 0\n",
      "No. nodes: 17\n",
      "Node: id='Section 3' type='Topic'\n",
      "Node: id='Building Models' type='Subtopic'\n",
      "Node: id='Training Models' type='Subtopic'\n",
      "Node: id='Ml Framework' type='Entity'\n",
      "Node: id='Model Architecture' type='Entity'\n",
      "Node: id='Interpretability' type='Entity'\n",
      "Node: id='Tabular Data' type='Entity'\n",
      "Node: id='Text Data' type='Entity'\n",
      "Node: id='Speech Data' type='Entity'\n",
      "Node: id='Image Data' type='Entity'\n",
      "Node: id='Video Data' type='Entity'\n",
      "Node: id='Cloud Storage' type='Entity'\n",
      "Node: id='Bigquery' type='Entity'\n",
      "Node: id='Csv' type='Entity'\n",
      "Node: id='Json' type='Entity'\n",
      "Node: id='Hadoop' type='Entity'\n",
      "Node: id='Databases' type='Entity'\n",
      "No. relationships: 16\n",
      "Relationship: source=Node(id='Section 3', type='Topic') target=Node(id='Building Models', type='Subtopic') type='HAS_SUBTOPIC'\n",
      "Relationship: source=Node(id='Section 3', type='Topic') target=Node(id='Training Models', type='Subtopic') type='HAS_SUBTOPIC'\n",
      "Relationship: source=Node(id='Building Models', type='Subtopic') target=Node(id='Ml Framework', type='Entity') type='CONSIDER'\n",
      "Relationship: source=Node(id='Building Models', type='Subtopic') target=Node(id='Model Architecture', type='Entity') type='CONSIDER'\n",
      "Relationship: source=Node(id='Building Models', type='Subtopic') target=Node(id='Interpretability', type='Entity') type='CONSIDER'\n",
      "Relationship: source=Node(id='Training Models', type='Subtopic') target=Node(id='Tabular Data', type='Entity') type='ORGANIZE'\n",
      "Relationship: source=Node(id='Training Models', type='Subtopic') target=Node(id='Text Data', type='Entity') type='ORGANIZE'\n",
      "Relationship: source=Node(id='Training Models', type='Subtopic') target=Node(id='Speech Data', type='Entity') type='ORGANIZE'\n",
      "Relationship: source=Node(id='Training Models', type='Subtopic') target=Node(id='Image Data', type='Entity') type='ORGANIZE'\n",
      "Relationship: source=Node(id='Training Models', type='Subtopic') target=Node(id='Video Data', type='Entity') type='ORGANIZE'\n",
      "Relationship: source=Node(id='Training Models', type='Subtopic') target=Node(id='Cloud Storage', type='Entity') type='ON'\n",
      "Relationship: source=Node(id='Training Models', type='Subtopic') target=Node(id='Bigquery', type='Entity') type='ON'\n",
      "Relationship: source=Node(id='Training Models', type='Subtopic') target=Node(id='Csv', type='Entity') type='INGESTION'\n",
      "Relationship: source=Node(id='Training Models', type='Subtopic') target=Node(id='Json', type='Entity') type='INGESTION'\n",
      "Relationship: source=Node(id='Training Models', type='Subtopic') target=Node(id='Hadoop', type='Entity') type='INGESTION'\n",
      "Relationship: source=Node(id='Training Models', type='Subtopic') target=Node(id='Databases', type='Entity') type='INGESTION'\n",
      " \n",
      "graphdoc_idx: 13\n",
      "Len doc_page_content 492\n",
      "No. doc_metadata: 0\n",
      "No. nodes: 34\n",
      "Node: id='Training' type='Process'\n",
      "Node: id='Sdks' type='Technology'\n",
      "Node: id='Vertex Ai' type='Technology'\n",
      "Node: id='Kubeflow' type='Technology'\n",
      "Node: id='Google Kubernetes Engine' type='Technology'\n",
      "Node: id='Automl' type='Technology'\n",
      "Node: id='Tabular' type='Field'\n",
      "Node: id='Workflows' type='Technology'\n",
      "Node: id='Distributed' type='Attribute'\n",
      "Node: id='Pipelines' type='Technology'\n",
      "Node: id='Reliable' type='Attribute'\n",
      "Node: id='Hyperparameter' type='Field'\n",
      "Node: id='Tuning' type='Process'\n",
      "Node: id='Troubleshooting' type='Process'\n",
      "Node: id='Ml' type='Model'\n",
      "Node: id='Model Training' type='Process'\n",
      "Node: id='Failures' type='Problem'\n",
      "Node: id='Hardware' type='Technology'\n",
      "Node: id='Training' type='Process'\n",
      "Node: id='Compute' type='Resource'\n",
      "Node: id='Accelerator' type='Resource'\n",
      "Node: id='Cpu' type='Technology'\n",
      "Node: id='Gpu' type='Technology'\n",
      "Node: id='Tpu' type='Technology'\n",
      "Node: id='Edge' type='Attribute'\n",
      "Node: id='Devices' type='Product'\n",
      "Node: id='Distributed' type='Attribute'\n",
      "Node: id='Training' type='Process'\n",
      "Node: id='Tpus' type='Technology'\n",
      "Node: id='Gpus' type='Technology'\n",
      "Node: id='Reduction' type='Process'\n",
      "Node: id='Server' type='Product'\n",
      "Node: id='Vertex Ai' type='Technology'\n",
      "Node: id='Horovod' type='Technology'\n",
      "No. relationships: 31\n",
      "Relationship: source=Node(id='Training', type='Process') target=Node(id='Sdks', type='Technology') type='USES'\n",
      "Relationship: source=Node(id='Sdks', type='Technology') target=Node(id='Vertex Ai', type='Technology') type='INCLUDES'\n",
      "Relationship: source=Node(id='Sdks', type='Technology') target=Node(id='Kubeflow', type='Technology') type='INCLUDES'\n",
      "Relationship: source=Node(id='Kubeflow', type='Technology') target=Node(id='Google Kubernetes Engine', type='Technology') type='RUNS_ON'\n",
      "Relationship: source=Node(id='Sdks', type='Technology') target=Node(id='Automl', type='Technology') type='INCLUDES'\n",
      "Relationship: source=Node(id='Automl', type='Technology') target=Node(id='Tabular', type='Field') type='FOR'\n",
      "Relationship: source=Node(id='Automl', type='Technology') target=Node(id='Workflows', type='Technology') type='USES'\n",
      "Relationship: source=Node(id='Training', type='Process') target=Node(id='Distributed', type='Attribute') type='SHOULD_BE'\n",
      "Relationship: source=Node(id='Distributed', type='Attribute') target=Node(id='Pipelines', type='Technology') type='FOR'\n",
      "Relationship: source=Node(id='Pipelines', type='Technology') target=Node(id='Reliable', type='Attribute') type='SHOULD_BE'\n",
      "Relationship: source=Node(id='Training', type='Process') target=Node(id='Hyperparameter', type='Field') type='REQUIRES'\n",
      "Relationship: source=Node(id='Hyperparameter', type='Field') target=Node(id='Tuning', type='Process') type='FOR'\n",
      "Relationship: source=Node(id='Training', type='Process') target=Node(id='Troubleshooting', type='Process') type='REQUIRES'\n",
      "Relationship: source=Node(id='Troubleshooting', type='Process') target=Node(id='Ml', type='Model') type='FOR'\n",
      "Relationship: source=Node(id='Ml', type='Model') target=Node(id='Model Training', type='Process') type='DURING'\n",
      "Relationship: source=Node(id='Model Training', type='Process') target=Node(id='Failures', type='Problem') type='RESULTS_IN'\n",
      "Relationship: source=Node(id='Training', type='Process') target=Node(id='Hardware', type='Technology') type='SHOULD_RUN_ON'\n",
      "Relationship: source=Node(id='Hardware', type='Technology') target=Node(id='Compute', type='Resource') type='SHOULD_HAVE'\n",
      "Relationship: source=Node(id='Compute', type='Resource') target=Node(id='Accelerator', type='Resource') type='OR'\n",
      "Relationship: source=Node(id='Accelerator', type='Resource') target=Node(id='Cpu', type='Technology') type='INCLUDES'\n",
      "Relationship: source=Node(id='Accelerator', type='Resource') target=Node(id='Gpu', type='Technology') type='INCLUDES'\n",
      "Relationship: source=Node(id='Accelerator', type='Resource') target=Node(id='Tpu', type='Technology') type='INCLUDES'\n",
      "Relationship: source=Node(id='Tpu', type='Technology') target=Node(id='Edge', type='Attribute') type='CAN_BE_USED_ON'\n",
      "Relationship: source=Node(id='Edge', type='Attribute') target=Node(id='Devices', type='Product') type='FOR'\n",
      "Relationship: source=Node(id='Training', type='Process') target=Node(id='Distributed', type='Attribute') type='CAN_BE_DONE_WITH'\n",
      "Relationship: source=Node(id='Distributed', type='Attribute') target=Node(id='Tpus', type='Technology') type='USING'\n",
      "Relationship: source=Node(id='Distributed', type='Attribute') target=Node(id='Gpus', type='Technology') type='USING'\n",
      "Relationship: source=Node(id='Distributed', type='Attribute') target=Node(id='Reduction', type='Process') type='WITH'\n",
      "Relationship: source=Node(id='Reduction', type='Process') target=Node(id='Server', type='Product') type='ON'\n",
      "Relationship: source=Node(id='Server', type='Product') target=Node(id='Vertex Ai', type='Technology') type='PROVIDED_BY'\n",
      "Relationship: source=Node(id='Distributed', type='Attribute') target=Node(id='Horovod', type='Technology') type='OR'\n",
      " \n",
      "graphdoc_idx: 14\n",
      "Len doc_page_content 495\n",
      "No. doc_metadata: 0\n",
      "No. nodes: 16\n",
      "Node: id='Section 4' type='Section'\n",
      "Node: id='Batch And Online Inference' type='Consideration'\n",
      "Node: id='Vertex Ai' type='Framework'\n",
      "Node: id='Dataflow' type='Framework'\n",
      "Node: id='Bigquery Ml' type='Framework'\n",
      "Node: id='Dataproc' type='Framework'\n",
      "Node: id='Pytorch' type='Framework'\n",
      "Node: id='Xgboost' type='Framework'\n",
      "Node: id='Model Registry' type='Consideration'\n",
      "Node: id='A/B Testing' type='Consideration'\n",
      "Node: id='Vertex Ai Feature Store' type='Consideration'\n",
      "Node: id='Vertex Ai Public And Private Endpoints' type='Consideration'\n",
      "Node: id='Cpu' type='Hardware'\n",
      "Node: id='Gpu' type='Hardware'\n",
      "Node: id='Tpu' type='Hardware'\n",
      "Node: id='Edge' type='Hardware'\n",
      "No. relationships: 13\n",
      "Relationship: source=Node(id='Section 4', type='Section') target=Node(id='Batch And Online Inference', type='Consideration') type='CONTAINS'\n",
      "Relationship: source=Node(id='Section 4', type='Section') target=Node(id='Vertex Ai Feature Store', type='Consideration') type='CONTAINS'\n",
      "Relationship: source=Node(id='Section 4', type='Section') target=Node(id='Vertex Ai Public And Private Endpoints', type='Consideration') type='CONTAINS'\n",
      "Relationship: source=Node(id='Section 4', type='Section') target=Node(id='Cpu', type='Hardware') type='CONTAINS'\n",
      "Relationship: source=Node(id='Section 4', type='Section') target=Node(id='Gpu', type='Hardware') type='CONTAINS'\n",
      "Relationship: source=Node(id='Section 4', type='Section') target=Node(id='Tpu', type='Hardware') type='CONTAINS'\n",
      "Relationship: source=Node(id='Section 4', type='Section') target=Node(id='Edge', type='Hardware') type='CONTAINS'\n",
      "Relationship: source=Node(id='Batch And Online Inference', type='Consideration') target=Node(id='Vertex Ai', type='Framework') type='USES'\n",
      "Relationship: source=Node(id='Batch And Online Inference', type='Consideration') target=Node(id='Dataflow', type='Framework') type='USES'\n",
      "Relationship: source=Node(id='Batch And Online Inference', type='Consideration') target=Node(id='Bigquery Ml', type='Framework') type='USES'\n",
      "Relationship: source=Node(id='Batch And Online Inference', type='Consideration') target=Node(id='Dataproc', type='Framework') type='USES'\n",
      "Relationship: source=Node(id='Vertex Ai Feature Store', type='Consideration') target=Node(id='Vertex Ai', type='Framework') type='USES'\n",
      "Relationship: source=Node(id='Vertex Ai Public And Private Endpoints', type='Consideration') target=Node(id='Vertex Ai', type='Framework') type='USES'\n",
      " \n",
      "graphdoc_idx: 15\n",
      "Len doc_page_content 507\n",
      "No. doc_metadata: 0\n",
      "No. nodes: 9\n",
      "Node: id='Scaling The Serving Backend Based On The Throughput' type='Process'\n",
      "Node: id='Tuning Ml Models For Training And Serving In Production' type='Process'\n",
      "Node: id='Developing End-To-End Ml Pipelines.' type='Process'\n",
      "Node: id='Vertex Ai Prediction' type='Technology'\n",
      "Node: id='Containerized Serving' type='Technology'\n",
      "Node: id='Simplification Techniques' type='Technology'\n",
      "Node: id='Optimizing The Ml Solution For Increased Performance, Latency, Memory, Throughput' type='Technology'\n",
      "Node: id='Data And Model Validation' type='Concept'\n",
      "Node: id='Ensuring Consistent Data Pre-Processing Between Training And Serving' type='Concept'\n",
      "No. relationships: 6\n",
      "Relationship: source=Node(id='Scaling The Serving Backend Based On The Throughput', type='Process') target=Node(id='Vertex Ai Prediction', type='Technology') type='USES'\n",
      "Relationship: source=Node(id='Scaling The Serving Backend Based On The Throughput', type='Process') target=Node(id='Containerized Serving', type='Technology') type='USES'\n",
      "Relationship: source=Node(id='Tuning Ml Models For Training And Serving In Production', type='Process') target=Node(id='Simplification Techniques', type='Technology') type='USES'\n",
      "Relationship: source=Node(id='Tuning Ml Models For Training And Serving In Production', type='Process') target=Node(id='Optimizing The Ml Solution For Increased Performance, Latency, Memory, Throughput', type='Technology') type='USES'\n",
      "Relationship: source=Node(id='Developing End-To-End Ml Pipelines.', type='Process') target=Node(id='Data And Model Validation', type='Concept') type='PRODUCES'\n",
      "Relationship: source=Node(id='Developing End-To-End Ml Pipelines.', type='Process') target=Node(id='Ensuring Consistent Data Pre-Processing Between Training And Serving', type='Concept') type='PRODUCES'\n",
      " \n",
      "graphdoc_idx: 16\n",
      "Len doc_page_content 444\n",
      "No. doc_metadata: 0\n",
      "No. nodes: 13\n",
      "Node: id='Google Cloud' type='Cloud platform'\n",
      "Node: id='Mlflow' type='Third-party pipeline'\n",
      "Node: id='Cloud Build' type='Build tool'\n",
      "Node: id='Cloud Run' type='Compute resource'\n",
      "Node: id='Kubeflow Pipelines' type='Orchestration framework'\n",
      "Node: id='Vertex Ai Pipelines' type='Orchestration framework'\n",
      "Node: id='Cloud Composer' type='Orchestration framework'\n",
      "Node: id='Hybrid Or Multicloud Strategies' type='Deployment strategy'\n",
      "Node: id='Tfx Components' type='Machine learning framework'\n",
      "Node: id='Kubeflow Dsl' type='Machine learning framework'\n",
      "Node: id='Dataflow' type='Data processing framework'\n",
      "Node: id='Model Retraining' type='Machine learning task'\n",
      "Node: id='Retraining Policy' type='Policy'\n",
      "No. relationships: 15\n",
      "Relationship: source=Node(id='Google Cloud', type='Cloud platform') target=Node(id='Mlflow', type='Third-party pipeline') type='HOSTING'\n",
      "Relationship: source=Node(id='Google Cloud', type='Cloud platform') target=Node(id='Cloud Build', type='Build tool') type='TRIGGERING'\n",
      "Relationship: source=Node(id='Google Cloud', type='Cloud platform') target=Node(id='Cloud Run', type='Compute resource') type='PROVIDING'\n",
      "Relationship: source=Node(id='Mlflow', type='Third-party pipeline') target=Node(id='Cloud Build', type='Build tool') type='RUNNING'\n",
      "Relationship: source=Node(id='Mlflow', type='Third-party pipeline') target=Node(id='Cloud Run', type='Compute resource') type='DEPLOYING'\n",
      "Relationship: source=Node(id='Cloud Build', type='Build tool') target=Node(id='Kubeflow Pipelines', type='Orchestration framework') type='TRIGGERING'\n",
      "Relationship: source=Node(id='Cloud Build', type='Build tool') target=Node(id='Vertex Ai Pipelines', type='Orchestration framework') type='TRIGGERING'\n",
      "Relationship: source=Node(id='Cloud Build', type='Build tool') target=Node(id='Cloud Composer', type='Orchestration framework') type='TRIGGERING'\n",
      "Relationship: source=Node(id='Kubeflow Pipelines', type='Orchestration framework') target=Node(id='Tfx Components', type='Machine learning framework') type='USING'\n",
      "Relationship: source=Node(id='Vertex Ai Pipelines', type='Orchestration framework') target=Node(id='Kubeflow Dsl', type='Machine learning framework') type='USING'\n",
      "Relationship: source=Node(id='Cloud Composer', type='Orchestration framework') target=Node(id='Dataflow', type='Data processing framework') type='USING'\n",
      "Relationship: source=Node(id='Model Retraining', type='Machine learning task') target=Node(id='Retraining Policy', type='Policy') type='DETERMINING'\n",
      "Relationship: source=Node(id='Retraining Policy', type='Policy') target=Node(id='Kubeflow Pipelines', type='Orchestration framework') type='TRIGGERING'\n",
      "Relationship: source=Node(id='Retraining Policy', type='Policy') target=Node(id='Vertex Ai Pipelines', type='Orchestration framework') type='TRIGGERING'\n",
      "Relationship: source=Node(id='Retraining Policy', type='Policy') target=Node(id='Cloud Composer', type='Orchestration framework') type='TRIGGERING'\n",
      " \n",
      "graphdoc_idx: 17\n",
      "Len doc_page_content 445\n",
      "No. doc_metadata: 0\n",
      "No. nodes: 7\n",
      "Node: id='Continuous Integration And Continuous Delivery (Ci/Cd)' type='Model deployment'\n",
      "Node: id='Cloud Build' type='Model deployment'\n",
      "Node: id='Jenkins' type='Model deployment'\n",
      "Node: id='Vertex Ai Experiments' type='Model artifact & version tracking'\n",
      "Node: id='Vertex Ml Metadata' type='Model artifact & version tracking'\n",
      "Node: id='Model And Dataset Versioning' type='Model & dataset versioning'\n",
      "Node: id='Model And Data Lineage' type='Model & data lineage'\n",
      "No. relationships: 6\n",
      "Relationship: source=Node(id='Continuous Integration And Continuous Delivery (Ci/Cd)', type='Model deployment') target=Node(id='Cloud Build', type='Model deployment') type='EXAMPLES_OF'\n",
      "Relationship: source=Node(id='Continuous Integration And Continuous Delivery (Ci/Cd)', type='Model deployment') target=Node(id='Jenkins', type='Model deployment') type='EXAMPLES_OF'\n",
      "Relationship: source=Node(id='5.3 Tracking And Auditing Metadata', type='Section') target=Node(id='Vertex Ai Experiments', type='Model artifact & version tracking') type='EXAMPLES_OF'\n",
      "Relationship: source=Node(id='5.3 Tracking And Auditing Metadata', type='Section') target=Node(id='Vertex Ml Metadata', type='Model artifact & version tracking') type='EXAMPLES_OF'\n",
      "Relationship: source=Node(id='5.3 Tracking And Auditing Metadata', type='Section') target=Node(id='Model And Dataset Versioning', type='Model & dataset versioning') type='EXAMPLES_OF'\n",
      "Relationship: source=Node(id='5.3 Tracking And Auditing Metadata', type='Section') target=Node(id='Model And Data Lineage', type='Model & data lineage') type='EXAMPLES_OF'\n",
      " \n",
      "graphdoc_idx: 18\n",
      "Len doc_page_content 507\n",
      "No. doc_metadata: 0\n",
      "No. nodes: 5\n",
      "Node: id='Building Secure Ml Systems' type='Entity'\n",
      "Node: id='Aligning With GoogleS Responsible Ai Practices' type='Entity'\n",
      "Node: id='Assessing Ml Solution Readiness' type='Entity'\n",
      "Node: id='Model Explainability On Vertex Ai' type='Entity'\n",
      "Node: id='Monitoring, Testing, And Troubleshooting Ml Solutions' type='Entity'\n",
      "No. relationships: 9\n",
      "Relationship: source=Node(id='Building Secure Ml Systems', type='Entity') target=Node(id='Protecting Against Unintentional Exploitation Of Data Or Models', type='Entity') type='SUBTOPIC'\n",
      "Relationship: source=Node(id='Building Secure Ml Systems', type='Entity') target=Node(id='Hacking', type='Entity') type='SUBTOPIC'\n",
      "Relationship: source=Node(id='Aligning With GoogleS Responsible Ai Practices', type='Entity') target=Node(id='Biases', type='Entity') type='SUBTOPIC'\n",
      "Relationship: source=Node(id='Assessing Ml Solution Readiness', type='Entity') target=Node(id='Data Bias', type='Entity') type='SUBTOPIC'\n",
      "Relationship: source=Node(id='Assessing Ml Solution Readiness', type='Entity') target=Node(id='Fairness', type='Entity') type='SUBTOPIC'\n",
      "Relationship: source=Node(id='Model Explainability On Vertex Ai', type='Entity') target=Node(id='Vertex Ai Prediction', type='Entity') type='SUBTOPIC'\n",
      "Relationship: source=Node(id='Monitoring, Testing, And Troubleshooting Ml Solutions', type='Entity') target=Node(id='Continuous Evaluation Metrics', type='Entity') type='SUBTOPIC'\n",
      "Relationship: source=Node(id='Monitoring, Testing, And Troubleshooting Ml Solutions', type='Entity') target=Node(id='Vertex Ai Model Monitoring, Explainable Ai', type='Entity') type='SUBTOPIC'\n",
      "Relationship: source=Node(id='Monitoring, Testing, And Troubleshooting Ml Solutions', type='Entity') target=Node(id='Training-Serving Skew', type='Entity') type='SUBTOPIC'\n",
      " \n",
      "graphdoc_idx: 19\n",
      "Len doc_page_content 169\n",
      "No. doc_metadata: 0\n",
      "No. nodes: 8\n",
      "Node: id='Monitoring' type='Process'\n",
      "Node: id='Feature Attribution Drift' type='Concept'\n",
      "Node: id='Model Performance' type='Metric'\n",
      "Node: id='Baselines' type='Model'\n",
      "Node: id='Simpler Models' type='Model'\n",
      "Node: id='Time Dimension' type='Dimension'\n",
      "Node: id='Training Errors' type='Error'\n",
      "Node: id='Serving Errors' type='Error'\n",
      "No. relationships: 7\n",
      "Relationship: source=Node(id='Monitoring', type='Process') target=Node(id='Feature Attribution Drift', type='Concept') type='FOR'\n",
      "Relationship: source=Node(id='Monitoring', type='Process') target=Node(id='Model Performance', type='Metric') type='EVALUATES'\n",
      "Relationship: source=Node(id='Model Performance', type='Metric') target=Node(id='Baselines', type='Model') type='AGAINST'\n",
      "Relationship: source=Node(id='Model Performance', type='Metric') target=Node(id='Simpler Models', type='Model') type='AGAINST'\n",
      "Relationship: source=Node(id='Model Performance', type='Metric') target=Node(id='Time Dimension', type='Dimension') type='ACROSS'\n",
      "Relationship: source=Node(id='Monitoring', type='Process') target=Node(id='Training Errors', type='Error') type='IDENTIFIES'\n",
      "Relationship: source=Node(id='Monitoring', type='Process') target=Node(id='Serving Errors', type='Error') type='IDENTIFIES'\n"
     ]
    }
   ],
   "source": [
    "print_graph_documents(graph_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7550372a-5e4c-4719-966f-58bb04d19ccd",
   "metadata": {},
   "source": [
    "**Enter Node4J**\n",
    "\n",
    "Node4J Connectivity\n",
    "\n",
    "Requires singing up for free version.\n",
    "\n",
    "DB Will be stopped if not recently used and will require resuming else will fail. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e2c285-73ed-41c7-ac46-eea0d3aec3b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "\n",
    "os.environ[\"NEO4J_URI\"] = \"neo4j+s://a657168d.databases.neo4j.io\"\n",
    "os.environ[\"NEO4J_USERNAME\"] = \"neo4j\"\n",
    "os.environ[\"NEO4J_PASSWORD\"] = \"VM3A9Mz6usNT99nLs_lqQssfVK8JxeD81DnEiXlDkZU\"\n",
    "\n",
    "graph = Neo4jGraph()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48151b0d-29cd-4c1b-b572-bab3a3049f9d",
   "metadata": {},
   "source": [
    "**Add to GraphDB**\n",
    "\n",
    "This statement loads Nodes & Relatonships into Node4J\n",
    "\n",
    "Thence they can be viewed/manipulated directly on the DB. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3082a075-0722-49d0-98c8-e9b908b52284",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "graph.add_graph_documents(graph_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3a3d52-26bb-4b2c-aa37-1930fcb38f95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m120",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m120"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
