{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This needs to be executed in a GCP Notebook, and so checked in/out fo GitHub. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Ingest Website to Graph DB***"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "**Upgrade to Python 3.11**\n",
    "Run commands in terminal as per URL below: \n",
    "https://mikaelahonen.com/en/data/vertex-ai-python-version/#:~:text=Open%20Vertex%20AI%20notebook%20with%20new%20Python%20version&text=Either%20launch%20a%20new%20notebook,package%20versions%20in%20the%20notebooks  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Here are the Commands*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deactivate the existing Python environment\n",
    "conda deactivate\n",
    "#Create new Python environment using Python version 3.11\n",
    "conda create -n python311 python=3.11 -y\n",
    "#Active the new environment\n",
    "conda activate python311\n",
    "#This enables pip to install to conda environment\n",
    "conda install pip\n",
    "#Verify that you use conda pip to install\n",
    "which -a pip\n",
    "#Install Python packages from requirements.txt file - Make sure you are in the same folder - skip this\n",
    "pip install --user -r requirements.txt\n",
    "#Install ipykernel if it was not requirements.txt\n",
    "pip install ipykernel\n",
    "#Install the kernel so it becomes available in notebooks\n",
    "ipython kernel install --name python311 --display-name \"Python 3.11\"  --user"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "**Check Python Version**\n",
    "* Expect 3.11.9 *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "**Check Kernel Info**\n",
    "* Expect 3.11.9 *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import platform\n",
    "print(platform.python_version())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the installation path of langchain is in your Python path. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/opt/conda/envs/python311/lib/python311.zip', '/opt/conda/envs/python311/lib/python3.11', '/opt/conda/envs/python311/lib/python3.11/lib-dynload', '', '/opt/conda/envs/python311/lib/python3.11/site-packages']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**H/L Installation**\n",
    "Install langchain and associated packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /opt/conda/envs/python311/lib/python3.11/site-packages (0.1.17)\n",
      "Requirement already satisfied: langchain-utils in /opt/conda/envs/python311/lib/python3.11/site-packages (0.1.1)\n",
      "Requirement already satisfied: langchain-openai in /opt/conda/envs/python311/lib/python3.11/site-packages (0.1.5)\n",
      "Requirement already satisfied: playwright in /opt/conda/envs/python311/lib/python3.11/site-packages (1.43.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/envs/python311/lib/python3.11/site-packages (4.12.3)\n",
      "Collecting html2text\n",
      "  Downloading html2text-2024.2.26.tar.gz (56 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /opt/conda/envs/python311/lib/python3.11/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/envs/python311/lib/python3.11/site-packages (from langchain) (1.4.52)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/envs/python311/lib/python3.11/site-packages (from langchain) (3.9.5)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/envs/python311/lib/python3.11/site-packages (from langchain) (0.5.14)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/envs/python311/lib/python3.11/site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.36 in /opt/conda/envs/python311/lib/python3.11/site-packages (from langchain) (0.0.36)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.48 in /opt/conda/envs/python311/lib/python3.11/site-packages (from langchain) (0.1.48)\n",
      "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /opt/conda/envs/python311/lib/python3.11/site-packages (from langchain) (0.0.1)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /opt/conda/envs/python311/lib/python3.11/site-packages (from langchain) (0.1.52)\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/conda/envs/python311/lib/python3.11/site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/conda/envs/python311/lib/python3.11/site-packages (from langchain) (1.10.15)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/conda/envs/python311/lib/python3.11/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/conda/envs/python311/lib/python3.11/site-packages (from langchain) (8.2.3)\n",
      "Collecting langchain\n",
      "  Using cached langchain-0.0.135-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: pytube<13.0.0,>=12.1.3 in /opt/conda/envs/python311/lib/python3.11/site-packages (from langchain-utils) (12.1.3)\n",
      "Requirement already satisfied: youtube-transcript-api<0.6.0,>=0.5.0 in /opt/conda/envs/python311/lib/python3.11/site-packages (from langchain-utils) (0.5.0)\n",
      "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /opt/conda/envs/python311/lib/python3.11/site-packages (from langchain) (1.2.4)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.10.0 in /opt/conda/envs/python311/lib/python3.11/site-packages (from langchain-openai) (1.25.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.5.2 in /opt/conda/envs/python311/lib/python3.11/site-packages (from langchain-openai) (0.6.0)\n",
      "Requirement already satisfied: greenlet==3.0.3 in /opt/conda/envs/python311/lib/python3.11/site-packages (from playwright) (3.0.3)\n",
      "Requirement already satisfied: pyee==11.1.0 in /opt/conda/envs/python311/lib/python3.11/site-packages (from playwright) (11.1.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/envs/python311/lib/python3.11/site-packages (from pyee==11.1.0->playwright) (4.11.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/envs/python311/lib/python3.11/site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/envs/python311/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/envs/python311/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/envs/python311/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/envs/python311/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/envs/python311/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/envs/python311/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/envs/python311/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /opt/conda/envs/python311/lib/python3.11/site-packages (from langchain-core<0.2.0,>=0.1.48->langchain) (23.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/envs/python311/lib/python3.11/site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (4.3.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/envs/python311/lib/python3.11/site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/envs/python311/lib/python3.11/site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (0.27.0)\n",
      "Requirement already satisfied: sniffio in /opt/conda/envs/python311/lib/python3.11/site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /opt/conda/envs/python311/lib/python3.11/site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (4.66.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/envs/python311/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/python311/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/envs/python311/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/python311/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/conda/envs/python311/lib/python3.11/site-packages (from tiktoken<1,>=0.5.2->langchain-openai) (2024.4.28)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/envs/python311/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/envs/python311/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/envs/python311/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/envs/python311/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/envs/python311/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "Using cached langchain-0.0.135-py3-none-any.whl (511 kB)\n",
      "Building wheels for collected packages: html2text\n",
      "  Building wheel for html2text (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for html2text: filename=html2text-2024.2.26-py3-none-any.whl size=33111 sha256=2e59475de36f9238a97630ce894f19dfe259332c31c1643d6ccdf23dc0bfa06b\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/23/58/7c/d9c8c4d924a1ac2b621add1b2c1d30b639629a33cfdfde6a45\n",
      "Successfully built html2text\n",
      "Installing collected packages: html2text, langchain\n",
      "  Attempting uninstall: langchain\n",
      "    Found existing installation: langchain 0.1.17\n",
      "    Uninstalling langchain-0.1.17:\n",
      "      Successfully uninstalled langchain-0.1.17\n",
      "Successfully installed html2text-2024.2.26 langchain-0.0.135\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain langchain-utils langchain-openai langchain playwright beautifulsoup4 html2text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure that langchain is installed and up-to-date by running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /opt/conda/envs/python311/lib/python3.11/site-packages (0.0.135)\n",
      "Collecting langchain\n",
      "  Using cached langchain-0.1.17-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/envs/python311/lib/python3.11/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/envs/python311/lib/python3.11/site-packages (from langchain) (1.4.52)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/envs/python311/lib/python3.11/site-packages (from langchain) (3.9.5)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/envs/python311/lib/python3.11/site-packages (from langchain) (0.5.14)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/envs/python311/lib/python3.11/site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.36 in /opt/conda/envs/python311/lib/python3.11/site-packages (from langchain) (0.0.36)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.48 in /opt/conda/envs/python311/lib/python3.11/site-packages (from langchain) (0.1.48)\n",
      "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /opt/conda/envs/python311/lib/python3.11/site-packages (from langchain) (0.0.1)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /opt/conda/envs/python311/lib/python3.11/site-packages (from langchain) (0.1.52)\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/conda/envs/python311/lib/python3.11/site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/conda/envs/python311/lib/python3.11/site-packages (from langchain) (1.10.15)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/conda/envs/python311/lib/python3.11/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/conda/envs/python311/lib/python3.11/site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/envs/python311/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/envs/python311/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/envs/python311/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/envs/python311/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/envs/python311/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/envs/python311/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/envs/python311/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/envs/python311/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /opt/conda/envs/python311/lib/python3.11/site-packages (from langchain-core<0.2.0,>=0.1.48->langchain) (23.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/envs/python311/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.2)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/envs/python311/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/envs/python311/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/python311/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/envs/python311/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/python311/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/envs/python311/lib/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/envs/python311/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "Using cached langchain-0.1.17-py3-none-any.whl (867 kB)\n",
      "Installing collected packages: langchain\n",
      "  Attempting uninstall: langchain\n",
      "    Found existing installation: langchain 0.0.135\n",
      "    Uninstalling langchain-0.0.135:\n",
      "      Successfully uninstalled langchain-0.0.135\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-utils 0.1.1 requires langchain<0.0.136,>=0.0.135, but you have langchain 0.1.17 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed langchain-0.1.17\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m  WARNING: The scripts pyrsa-decrypt, pyrsa-encrypt, pyrsa-keygen, pyrsa-priv2pub, pyrsa-sign and pyrsa-verify are installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script tb-gcp-uploader is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q --upgrade --user google-cloud-aiplatform==1.36.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: langchain\n",
      "Version: 0.1.17\n",
      "Summary: Building applications with LLMs through composability\n",
      "Home-page: https://github.com/langchain-ai/langchain\n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: /opt/conda/envs/python311/lib/python3.11/site-packages\n",
      "Requires: aiohttp, dataclasses-json, jsonpatch, langchain-community, langchain-core, langchain-text-splitters, langsmith, numpy, pydantic, PyYAML, requests, SQLAlchemy, tenacity\n",
      "Required-by: langchain-utils\n"
     ]
    }
   ],
   "source": [
    "!pip show langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: langchain-utils\n",
      "Version: 0.1.1\n",
      "Summary: \n",
      "Home-page: https://github.com/tddschn/langchain-utils\n",
      "Author: Teddy Xinyuan Chen\n",
      "Author-email: 45612704+tddschn@users.noreply.github.com\n",
      "License: MIT\n",
      "Location: /opt/conda/envs/python311/lib/python3.11/site-packages\n",
      "Requires: langchain, pytube, youtube-transcript-api\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show langchain-utils"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "**H/L Imports**\n",
    "\n",
    "This is a combination of all langchain examples\n",
    "\n",
    "*incomplete/missing installation of:*\n",
    "\n",
    "langchain.agents\n",
    "\n",
    "langchain.loader\n",
    "\n",
    "langchain.splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ipywidgets\n",
      "  Downloading ipywidgets-8.1.2-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: comm>=0.1.3 in /opt/conda/envs/python311/lib/python3.11/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /opt/conda/envs/python311/lib/python3.11/site-packages (from ipywidgets) (8.24.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/envs/python311/lib/python3.11/site-packages (from ipywidgets) (5.14.3)\n",
      "Collecting widgetsnbextension~=4.0.10 (from ipywidgets)\n",
      "  Downloading widgetsnbextension-4.0.10-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab-widgets~=3.0.10 (from ipywidgets)\n",
      "  Downloading jupyterlab_widgets-3.0.10-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: decorator in /opt/conda/envs/python311/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/envs/python311/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/envs/python311/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /opt/conda/envs/python311/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/conda/envs/python311/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (2.17.2)\n",
      "Requirement already satisfied: stack-data in /opt/conda/envs/python311/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6 in /opt/conda/envs/python311/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (4.11.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/envs/python311/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/conda/envs/python311/lib/python3.11/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/envs/python311/lib/python3.11/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/envs/python311/lib/python3.11/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/conda/envs/python311/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/conda/envs/python311/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /opt/conda/envs/python311/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/envs/python311/lib/python3.11/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n",
      "Downloading ipywidgets-8.1.2-py3-none-any.whl (139 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.4/139.4 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jupyterlab_widgets-3.0.10-py3-none-any.whl (215 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m215.0/215.0 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading widgetsnbextension-4.0.10-py3-none-any.whl (2.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m86.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: widgetsnbextension, jupyterlab-widgets, ipywidgets\n",
      "Successfully installed ipywidgets-8.1.2 jupyterlab-widgets-3.0.10 widgetsnbextension-4.0.10\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import langchain\n",
    "import html2text\n",
    "# from langchain.document_loaders import AsyncHtmlLoader # cannot import name 'AsyncHtmlLoader' from 'langchain.document_loaders' \n",
    "# from langchain.document_transformers import Html2TextTransformer # No module named 'langchain.document_transformers'\n",
    "# from langchain.agents import Text2TextAgent # cannot import name 'Text2TextAgent' from 'langchain.agents'\n",
    "# from langchain.loader import TextLoader # No module named 'langchain.loader'\n",
    "# from langchain.splitter import CharacterTextSplitter # \n",
    "import requests\n",
    "import itertools\n",
    "import numpy as np\n",
    "# import pandas as pd # ModuleNotFoundError: No module named 'pandas'\n",
    "import numpy.linalg\n",
    "import vertexai\n",
    "\n",
    "from google.api_core import retry\n",
    "from vertexai.language_models import TextEmbeddingModel, TextGenerationModel\n",
    "from tqdm.auto import tqdm\n",
    "from bs4 import BeautifulSoup, Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Test Source Data - GCP AI Exam Guide  \n",
    "gcp_ai_examguide_url = 'https://cloud.google.com/learn/certification/guides/machine-learning-engineer'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1 - Text Ingestion from Web site"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installation: from https://medium.datadriveninvestor.com/unlock-web-data-with-efficiency-master-web-scraping-with-langchain-python-1b19220ecbb4 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L/L Imports: from https://medium.datadriveninvestor.com/unlock-web-data-with-efficiency-master-web-scraping-with-langchain-python-1b19220ecbb4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Execute Code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load and split documents\n",
    "loader = TextLoader(gcp_ai_examguide_url)\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(chunk_size=1000)\n",
    "docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installation: from https://dev.to/ranjancse/web-scraping-with-langchain-and-html2text-5edl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q langchain playwright beautifulsoup4 html2text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H/L IMport: from https://dev.to/ranjancse/web-scraping-with-langchain-and-html2text-5edl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import html2text\n",
    "from langchain.document_loaders import AsyncHtmlLoader\n",
    "from langchain.document_transformers import Html2TextTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code Snippet: from https://dev.to/ranjancse/web-scraping-with-langchain-and-html2text-5edl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def do_webscraping(link):\n",
    "    try:\n",
    "        urls = [link]\n",
    "        loader = AsyncHtmlLoader(urls)\n",
    "        docs = loader.load()\n",
    "\n",
    "        html2text_transformer = Html2TextTransformer()\n",
    "        docs_transformed = html2text_transformer.transform_documents(docs)\n",
    "\n",
    "        if docs_transformed != None and len(docs_transformed) > 0:\n",
    "            metadata = docs_transformed[0].metadata\n",
    "            title = metadata.get('title', '')\n",
    "            return {\n",
    "                'summary': docs_transformed[0].page_content,\n",
    "                'title': title,\n",
    "                'metadata': metadata,\n",
    "                'clean_content': html2text.html2text(docs_transformed[0].page_content)\n",
    "            }\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example Data: from https://dev.to/ranjancse/web-scraping-with-langchain-and-html2text-5edl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_search_results = ['https://www.yelp.com/search?cflt=seafood&find_loc=Mountain+View%2C+CA+94043',\n",
    " 'https://www.yelp.com/search?cflt=seafood&find_loc=Mountain+View%2C+CA',\n",
    " 'https://www.opentable.com/cuisine/best-seafood-restaurants-mountain-view-ca']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execution/Demo: from https://dev.to/ranjancse/web-scraping-with-langchain-and-html2text-5edl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for link in google_search_results:\n",
    "  print(link)\n",
    "  response = await do_webscraping(link)\n",
    "  if response != None:\n",
    "    structured_response.append(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installation: from https://python.langchain.com/docs/integrations/document_transformers/html2text/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade --quiet  html2text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H/L Imports: from https://python.langchain.com/docs/integrations/document_transformers/html2text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import AsyncHtmlLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code Snippet 1: from https://python.langchain.com/docs/integrations/document_transformers/html2text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\"https://www.espn.com\", \"https://lilianweng.github.io/posts/2023-06-23-agent/\"]\n",
    "loader = AsyncHtmlLoader(urls)\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H/L Imports 2: from https://python.langchain.com/docs/integrations/document_transformers/html2text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_transformers import Html2TextTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code Snippet 2: from https://python.langchain.com/docs/integrations/document_transformers/html2text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\"https://www.espn.com\", \"https://lilianweng.github.io/posts/2023-06-23-agent/\"]\n",
    "html2text = Html2TextTransformer()\n",
    "docs_transformed = html2text.transform_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example Output: from https://python.langchain.com/docs/integrations/document_transformers/html2text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_transformed[0].page_content[1000:2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installation: from https://github.com/GoogleCloudPlatform/generative-ai/blob/main/search/retrieval-augmented-generation/examples/rag_google_documentation.ipynb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q --upgrade --user google-cloud-aiplatform==1.36.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H/L Imports: from https://github.com/GoogleCloudPlatform/generative-ai/blob/main/search/retrieval-augmented-generation/examples/rag_google_documentation.ipynb \n",
    "NB NO LANGCHAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy.linalg\n",
    "import vertexai\n",
    "\n",
    "from google.api_core import retry\n",
    "from vertexai.language_models import TextEmbeddingModel, TextGenerationModel\n",
    "from tqdm.auto import tqdm\n",
    "from bs4 import BeautifulSoup, Tag\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Init GCP Vertex: from https://github.com/GoogleCloudPlatform/generative-ai/blob/main/search/retrieval-augmented-generation/examples/rag_google_documentation.ipynb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define project information\n",
    "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
    "LOCATION = \"us-central1\"  # @param {type:\"string\"}\n",
    "\n",
    "# Initialize Vertex AI SDK\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code Snippet: --> List of URLs: from https://github.com/GoogleCloudPlatform/generative-ai/blob/main/search/retrieval-augmented-generation/examples/rag_google_documentation.ipynb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/main/search/retrieval-augmented-generation/examples/URLs.txt\"\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    # The request was successful, and the content is in response.text\n",
    "    content = response.text\n",
    "\n",
    "URLS = [line.strip() for line in content.splitlines()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code Snippet: url(s) --> Text: from https://github.com/GoogleCloudPlatform/generative-ai/blob/main/search/retrieval-augmented-generation/examples/rag_google_documentation.ipynb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a Google documentation URL, retrieve a list of all text chunks within h2 sections\n",
    "def get_sections(url: str) -> list[str]:\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "    sections = []\n",
    "    paragraphs = []\n",
    "\n",
    "    body_div = soup.find(\"div\", class_=\"devsite-article-body\")\n",
    "    for child in body_div.findChildren():\n",
    "        if child.name == \"p\":\n",
    "            paragraphs.append(child.get_text().strip())\n",
    "        if child.name == \"h2\":\n",
    "            sections.append(\" \".join(paragraphs))\n",
    "            break\n",
    "\n",
    "    for header in soup.find_all(\"h2\"):\n",
    "        paragraphs = []\n",
    "        nextNode = header.nextSibling\n",
    "        while nextNode:\n",
    "            if isinstance(nextNode, Tag):\n",
    "                if nextNode.name in {\"p\", \"ul\"}:\n",
    "                    paragraphs.append(nextNode.get_text().strip())\n",
    "                elif nextNode.name == \"h2\":\n",
    "                    sections.append(\" \".join(paragraphs))\n",
    "                    break\n",
    "            nextNode = nextNode.nextSibling\n",
    "    return sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text = [t for url in URLS for t in get_sections(url) if t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_lengths = [len(t) for t in all_text]\n",
    "pd.DataFrame(text_lengths).hist()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-python311-py",
   "name": "workbench-notebooks.m120",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m120"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local) (Local)",
   "language": "python",
   "name": "conda-env-python311-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
