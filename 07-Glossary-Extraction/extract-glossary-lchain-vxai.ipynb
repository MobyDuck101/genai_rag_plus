{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8f9e3f7-ade1-4049-90e9-96d963538c5c",
   "metadata": {},
   "source": [
    "****Extract Glossary From Text****\n",
    "\n",
    "**Part 1** - Extract Keywords and Definitions from Block of Text Using Gemini.\n",
    "\n",
    "Includes langchain to address the Gemini API Key Problem\n",
    "\n",
    "This is based on the following examples\n",
    "\n",
    " - https://github.com/GoogleCloudPlatform/generative-ai/blob/main/language/prompts/examples/text_extraction.ipynb\n",
    " - https://medium.com/@joansantoso/gemini-reshaping-the-nlp-task-for-extracting-knowledge-in-text-c0d5fdd4edd8\n",
    " - https://codelabs.developers.google.com/codelabs/genai-text-gen-java-palm-langchain4j#4\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "raw",
   "id": "5fa5cee1-967c-4024-9329-7c473430ceca",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "**Minimal install for Vertex AI**\n",
    "\n",
    "Does not explicitly install google generative ai in case this forces use of Geminin API Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9d33f38-6324-4175-8689-d4e8f278c8ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.2.7-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting langchain-google-vertexai\n",
      "  Downloading langchain_google_vertexai-1.0.6-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.0.31)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (3.9.5)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (4.0.3)\n",
      "Collecting langchain-core<0.3.0,>=0.2.12 (from langchain)\n",
      "  Downloading langchain_core-0.2.12-py3-none-any.whl.metadata (6.0 kB)\n",
      "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.2.2-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.1.84-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.7.4)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (8.4.2)\n",
      "Requirement already satisfied: google-cloud-aiplatform<2.0.0,>=1.56.0 in /opt/conda/lib/python3.10/site-packages (from langchain-google-vertexai) (1.57.0)\n",
      "Collecting google-cloud-storage<3.0.0,>=2.17.0 (from langchain-google-vertexai)\n",
      "  Downloading google_cloud_storage-2.17.0-py2.py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.56.0->langchain-google-vertexai) (1.34.1)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform<2.0.0,>=1.56.0->langchain-google-vertexai) (2.30.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform<2.0.0,>=1.56.0->langchain-google-vertexai) (1.24.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform<2.0.0,>=1.56.0->langchain-google-vertexai) (3.20.3)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform<2.0.0,>=1.56.0->langchain-google-vertexai) (24.1)\n",
      "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform<2.0.0,>=1.56.0->langchain-google-vertexai) (3.25.0)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform<2.0.0,>=1.56.0->langchain-google-vertexai) (1.12.3)\n",
      "Requirement already satisfied: shapely<3.0.0dev in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform<2.0.0,>=1.56.0->langchain-google-vertexai) (2.0.4)\n",
      "Requirement already satisfied: docstring-parser<1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform<2.0.0,>=1.56.0->langchain-google-vertexai) (0.16)\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.56.0->langchain-google-vertexai)\n",
      "  Downloading google_api_core-2.19.1-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage<3.0.0,>=2.17.0->langchain-google-vertexai) (2.4.1)\n",
      "Requirement already satisfied: google-resumable-media>=2.6.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage<3.0.0,>=2.17.0->langchain-google-vertexai) (2.7.1)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-storage<3.0.0,>=2.17.0->langchain-google-vertexai) (1.5.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.12->langchain) (1.33)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.5)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (2.18.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2024.6.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.56.0->langchain-google-vertexai) (1.63.2)\n",
      "INFO: pip is looking at multiple versions of google-api-core[grpc] to determine which version is compatible with other requirements. This could take a while.\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.56.0->langchain-google-vertexai) (1.64.1)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.56.0->langchain-google-vertexai) (1.48.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.56.0->langchain-google-vertexai) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.56.0->langchain-google-vertexai) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.56.0->langchain-google-vertexai) (4.9)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.56.0->langchain-google-vertexai) (2.9.0)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /opt/conda/lib/python3.10/site-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform<2.0.0,>=1.56.0->langchain-google-vertexai) (0.13.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.12->langchain) (3.0.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform<2.0.0,>=1.56.0->langchain-google-vertexai) (0.6.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil<3.0dev,>=2.7.2->google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.56.0->langchain-google-vertexai) (1.16.0)\n",
      "Downloading langchain-0.2.7-py3-none-any.whl (983 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.6/983.6 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading langchain_google_vertexai-1.0.6-py3-none-any.whl (72 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.0/73.0 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_cloud_storage-2.17.0-py2.py3-none-any.whl (126 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.5/126.5 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-0.2.12-py3-none-any.whl (355 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m355.8/355.8 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\n",
      "Downloading langsmith-0.1.84-py3-none-any.whl (127 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_api_core-2.19.1-py3-none-any.whl (139 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.4/139.4 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: langsmith, google-api-core, langchain-core, langchain-text-splitters, google-cloud-storage, langchain, langchain-google-vertexai\n",
      "  Attempting uninstall: google-api-core\n",
      "    Found existing installation: google-api-core 1.34.1\n",
      "    Uninstalling google-api-core-1.34.1:\n",
      "      Successfully uninstalled google-api-core-1.34.1\n",
      "\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/opt/conda/lib/python3.10/site-packages/google/~pi_core'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Attempting uninstall: google-cloud-storage\n",
      "    Found existing installation: google-cloud-storage 2.14.0\n",
      "    Uninstalling google-cloud-storage-2.14.0:\n",
      "      Successfully uninstalled google-cloud-storage-2.14.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-api-python-client 1.8.0 requires google-api-core<2dev,>=1.13.0, but you have google-api-core 2.19.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed google-api-core-2.19.1 google-cloud-storage-2.17.0 langchain-0.2.7 langchain-core-0.2.12 langchain-google-vertexai-1.0.6 langchain-text-splitters-0.2.2 langsmith-0.1.84\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U langchain langchain-google-vertexai "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9ccb08-3868-4a2b-9eda-6dab0e99b53e",
   "metadata": {},
   "source": [
    "**Check Version Nos of what was installed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9709e6a-f98c-4e5e-b7b1-b734db5ae1e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Package(s) not found: google-ai-generativelanguage, google-generativeai, neo4j\u001b[0m\u001b[33m\n",
      "\u001b[0mName: langchain\n",
      "Version: 0.2.7\n",
      "Summary: Building applications with LLMs through composability\n",
      "Home-page: https://github.com/langchain-ai/langchain\n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: /opt/conda/lib/python3.10/site-packages\n",
      "Requires: aiohttp, async-timeout, langchain-core, langchain-text-splitters, langsmith, numpy, pydantic, PyYAML, requests, SQLAlchemy, tenacity\n",
      "Required-by: \n",
      "---\n",
      "Name: langchain-core\n",
      "Version: 0.2.12\n",
      "Summary: Building applications with LLMs through composability\n",
      "Home-page: https://github.com/langchain-ai/langchain\n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: /opt/conda/lib/python3.10/site-packages\n",
      "Requires: jsonpatch, langsmith, packaging, pydantic, PyYAML, tenacity\n",
      "Required-by: langchain, langchain-google-vertexai, langchain-text-splitters\n",
      "---\n",
      "Name: langchain-google-vertexai\n",
      "Version: 1.0.6\n",
      "Summary: An integration package connecting Google VertexAI and LangChain\n",
      "Home-page: https://github.com/langchain-ai/langchain-google\n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: /opt/conda/lib/python3.10/site-packages\n",
      "Requires: google-cloud-aiplatform, google-cloud-storage, langchain-core\n",
      "Required-by: \n",
      "---\n",
      "Name: google-cloud-aiplatform\n",
      "Version: 1.57.0\n",
      "Summary: Vertex AI API client library\n",
      "Home-page: https://github.com/googleapis/python-aiplatform\n",
      "Author: Google LLC\n",
      "Author-email: googleapis-packages@google.com\n",
      "License: Apache 2.0\n",
      "Location: /opt/conda/lib/python3.10/site-packages\n",
      "Requires: docstring-parser, google-api-core, google-auth, google-cloud-bigquery, google-cloud-resource-manager, google-cloud-storage, packaging, proto-plus, protobuf, pydantic, shapely\n",
      "Required-by: langchain-google-vertexai\n"
     ]
    }
   ],
   "source": [
    "!pip show langchain langchain-core langchain-google-vertexai neo4j google-cloud-aiplatform google-generativeai google-ai-generativelanguage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3475874d-7cdc-4e51-8a0c-50421f4a3d70",
   "metadata": {},
   "source": [
    "**Check Jupyter Version No**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "332bfcdc-8d2c-410d-8473-c4cb65ad3d4a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Jupyter core packages...\n",
      "IPython          : 8.21.0\n",
      "ipykernel        : 6.29.4\n",
      "ipywidgets       : 8.1.3\n",
      "jupyter_client   : 7.4.9\n",
      "jupyter_core     : 5.7.2\n",
      "jupyter_server   : 1.24.0\n",
      "jupyterlab       : 3.4.8\n",
      "nbclient         : 0.10.0\n",
      "nbconvert        : 7.16.4\n",
      "nbformat         : 5.10.4\n",
      "notebook         : 6.5.7\n",
      "qtconsole        : not installed\n",
      "traitlets        : 5.14.3\n"
     ]
    }
   ],
   "source": [
    "!jupyter --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38b224b-03e5-4068-a564-2fa642cab286",
   "metadata": {},
   "source": [
    "**Check Python Version/Path** - *Expect 3.10.14*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dea00fad-2121-4150-a520-60d8ca5c8f1e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.10.14 | packaged by conda-forge | (main, Mar 20 2024, 12:45:18) [GCC 12.3.0]\n",
      "3.10.14\n",
      "['/opt/conda/lib/python310.zip', '/opt/conda/lib/python3.10', '/opt/conda/lib/python3.10/lib-dynload', '', '/opt/conda/lib/python3.10/site-packages']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import platform\n",
    "print(sys.version)\n",
    "print(platform.python_version())\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4cc7f4-ee89-4e5e-bd61-054c71931ffd",
   "metadata": {},
   "source": [
    "**Now for the Imports**\n",
    "\n",
    "This time we are isloating Vertex AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "642f246f-53e3-4786-ab49-8fb5bdb567f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "#from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "from langchain_google_vertexai import ChatVertexAI\n",
    "from langchain_core.documents import Document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f00f8cc-8185-4fcb-b670-9c423d033b50",
   "metadata": {},
   "source": [
    "**Diagnostic Methods**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "695f63e0-8c42-49bd-adf0-c01df7b8d31f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Vertex AI Model Diagnostic Dump\n",
    "def print_llm(llm):\n",
    "    print(f\"llm: {llm}\")\n",
    "    print(f\"name: {llm.model_name}\")\n",
    "    print(f\"examples: {llm.examples}\") \n",
    "    print(f\"tuned_model_name: {llm.tuned_model_name}\") \n",
    "    print(f\"convert_system_message_to_human: {llm.convert_system_message_to_human}\") \n",
    "    print(f\"max_output_tokens: {llm.max_output_tokens}\") \n",
    "    print(f\"top_p: {llm.top_p}\") \n",
    "    print(f\"top_k: {llm.top_k}\") \n",
    "    print(f\"credentials: {llm.credentials}\")     \n",
    "    print(f\"n: {llm.n}\") \n",
    "    print(f\"streaming: {llm.streaming}\") \n",
    "    print(f\"safety_settings: {llm.safety_settings}\")     \n",
    "    print(f\"api_transport: {llm.api_transport}\") \n",
    "    print(f\"api_endpoint: {llm.api_endpoint}\") \n",
    " \n",
    "    print('properties') \n",
    "    print('----------') \n",
    "    \n",
    "    print(f\"_llm_type: {llm._llm_type}\") \n",
    "    #print(f\"is_codey_model: {llm.is_codey_model}\")     \n",
    "    print(f\"_is_gemini_model: {llm._is_gemini_model}\")\n",
    "    print(f\"_identifying_params: {llm._identifying_params}\")     \n",
    "    print(f\"_default_params: {llm._default_params}\") \n",
    "    print(f\"_user_agent: {llm._user_agent}\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a1967b-907b-4635-9d14-29c51de06016",
   "metadata": {},
   "source": [
    "**Connect to Google LLMs**\n",
    "\n",
    "*Least Privilege Security.*\n",
    "\n",
    "The Notebook is \"owned\" by a bespoke Service Account created in terrafrom for this purpose.\n",
    "\n",
    "Minimal permisisons are added (also via terraform) via predefined roles (esp. Vertex) as required.\n",
    "\n",
    "This is typically triggered by a PERMISSION DENIED error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc6314e9-e801-4103-aa9b-85c7a1befdd2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32f9af541e5febaadd9eeb230be8cef11dc9d171\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Set It - will require regeneration\n",
    "os.environ['GOOGLE_API_KEY'] = '32f9af541e5febaadd9eeb230be8cef11dc9d171'\n",
    "# Access the environment variable later in your code\n",
    "api_key = os.environ['GOOGLE_API_KEY']\n",
    "print(api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03c9d7a-f26a-40ff-9784-837c9b80d270",
   "metadata": {},
   "source": [
    "****Enable Langchain Debugging****\n",
    "\n",
    "See: https://python.langchain.com/v0.1/docs/guides/development/debugging/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24d3fce2-7775-4b22-8b61-b4e10ae87edd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.globals import set_debug   \n",
    "\n",
    "set_debug(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a2b08b-8722-41ae-a5aa-4dda5af5f7ad",
   "metadata": {},
   "source": [
    "**Create The LLMs**\n",
    "\n",
    "Both *Gemini* & *Chat Bison* were created.\n",
    "\n",
    "Chat Bison malfunctioned so has been abandoned FTTB \n",
    "\n",
    "Sourced from here: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a9c76ea-8232-4404-b82a-8d344ae786b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Avalable Model Variables\n",
    "\n",
    "# Gemini 1.5 Pro (Preview)\n",
    "# 404 Publisher Model `projects/nlp-dev-6aae/locations/us-central1/publishers/google/models/gemini-1.5-pro` not found.\n",
    "gemini_1pt5_proOnVertex = ChatVertexAI(model=\"gemini-1.5-pro-001\")\n",
    "\n",
    "\n",
    "\n",
    "# Gemini 1.0 Pro\n",
    "# This works with Errors - chunking\n",
    "gemini_1pt0_proOnVertex = ChatVertexAI(model=\"gemini-1.0-pro\")\n",
    "\n",
    "gemini_proOnVertex = ChatVertexAI(model=\"gemini-pro\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e39c0ff-e607-4a74-ab7b-962c16c8c45c",
   "metadata": {},
   "source": [
    "**Choose which model we are using**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ecd7658-ec29-474c-b89e-9a59d43015f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chat_llm = gemini_1pt5_proOnVertex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7dba7c3-8534-496f-a4bc-bf086c546815",
   "metadata": {},
   "source": [
    "*Check Model Properties*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c67bec55-3505-4481-b385-d152838cc891",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm: project='nlp-dev-6aae' model_name='gemini-1.5-pro-001' model_family=<GoogleModelFamily.GEMINI_ADVANCED: '2'> full_model_name='projects/nlp-dev-6aae/locations/us-central1/publishers/google/models/gemini-1.5-pro-001' client_options=ClientOptions: {'api_endpoint': 'us-central1-aiplatform.googleapis.com', 'client_cert_source': None, 'client_encrypted_cert_source': None, 'quota_project_id': None, 'credentials_file': None, 'scopes': None, 'api_key': None, 'api_audience': None} default_metadata=()\n",
      "name: gemini-1.5-pro-001\n",
      "examples: None\n",
      "tuned_model_name: None\n",
      "convert_system_message_to_human: False\n",
      "max_output_tokens: None\n",
      "top_p: None\n",
      "top_k: None\n",
      "credentials: None\n",
      "n: 1\n",
      "streaming: False\n",
      "safety_settings: None\n",
      "api_transport: None\n",
      "api_endpoint: None\n",
      "properties\n",
      "----------\n",
      "_llm_type: vertexai\n",
      "_is_gemini_model: True\n",
      "_identifying_params: {'model_name': 'gemini-1.5-pro-001', 'temperature': 0.0, 'max_output_tokens': 128, 'candidate_count': 1, 'top_k': 40, 'top_p': 0.95}\n",
      "_default_params: {'temperature': 0.0, 'max_output_tokens': 128, 'candidate_count': 1, 'top_k': 40, 'top_p': 0.95}\n",
      "_user_agent: langchain-google-vertexai/1.0.6-ChatVertexAI_gemini-1.5-pro-001\n"
     ]
    }
   ],
   "source": [
    "print_llm(chat_llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b46647-b939-400e-b569-30f93fe24c45",
   "metadata": {},
   "source": [
    "****Test Data****\n",
    "\n",
    "This is an extract from the Transcript of a GCP ML Engineer Professional Certification Training Course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52a0456c-cf46-48d4-aa5c-b2d97a6933fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "tutorial_text = \"\"\"\n",
    "Transcript\n",
    "Hello, everyone.\n",
    "So this video will be will be a gentle and brief introduction on what is data science, what is artificial\n",
    "intelligence, machine learning and deep learning.\n",
    "And this will be a short video just in like getting ourselves familiarized with the basic definition\n",
    "of all these four concepts.\n",
    "So let's get started.\n",
    "So just remember this diagram and I will be covering the definition also.\n",
    "So data science is something which which overlaps with all deep learning, machine learning and artificial\n",
    "intelligence.\n",
    "And this is a very, very wide and extensive field.\n",
    "It contains a lot of like mathematics, maths statistics and other things.\n",
    "But this, these three things, so deep learning is a very, very, very specialized field.\n",
    "And deep learning, we can say, is a subset of machine learning.\n",
    "And machine learning is all about computers learning or machines learning about the different like they\n",
    "are learning about the system and coming up with a way to predict or predict the outcome.\n",
    "So deep learning is very specialized.\n",
    "It's a subset.\n",
    "It's a it's a specialized field of machine learning.\n",
    "And same way machine learning is a superset of deep learning.\n",
    "But machine learning is a subset of artificial intelligence, which is a very huge and wide field.\n",
    "So deep learning is part of machine learning.\n",
    "Machine learning is a part of artificial intelligence.\n",
    "And we can say deep learning is also a very small subset of artificial intelligence.\n",
    "So just think of just remember this diagram and you will be like able to distinguish between these three\n",
    "concepts and data.\n",
    "Science is something where separate, but it has a connection with all three topics.\n",
    "So data science.\n",
    "So data science is a field that involves using statistical and computational techniques to extract insights\n",
    "and knowledge from data.\n",
    "It is a multidisciplinary disciplinary field that combines elements from computer science statistics\n",
    "and domain expertise in order to understand and analyze complex data sets.\n",
    "Data.\n",
    "Scientists use a variety of tools and techniques to analyze data, including machine learning, algorithms,\n",
    "statistics, statistical analysis and visualization tools.\n",
    "So Data Science Part two.\n",
    "So they work with structured and unstructured data and use a variety of methods to clean prepare and\n",
    "process the data for analysis.\n",
    "The goal of data science is to extract useful insights and knowledge from data that can be used to inform\n",
    "decision making and solve problems.\n",
    "Data scientists may work in a variety of industries, including finance, healthcare and e-commerce,\n",
    "and may use their skills to tackle a wide range of problems, such as predicting customer behaviour,\n",
    "optimizing supply chain logistics or improve health healthcare outcomes.\n",
    "So next is machine learning.\n",
    "Machine learning is a method of teaching computers to learn from data without being explicitly programmed.\n",
    "It is a subset of artificial intelligence that focuses on the development of computer programs that\n",
    "can access data and use it to learn for themselves.\n",
    "There are three main types of machine learning.\n",
    "Supervised Learning.\n",
    "Unsupervised learning and reinforcement learning.\n",
    "In supervised learning.\n",
    "The computer is given a set of labeled training data and a set of desired outputs, and the algorithm\n",
    "learns to map the inputs to the outputs.\n",
    "For example, a supervised learning algorithm might be trained to classify email as spam or not spam\n",
    "based on a set of labeled examples.\n",
    "In unsupervised learning.\n",
    "The algorithm is given a set of data without any labels, and it must find patterns and relationships\n",
    "in the data.\n",
    "One example of unsupervised learning is clustering, where the algorithm groups similar data points\n",
    "together.\n",
    "In reinforcement learning, the algorithm learns by interacting with its environment and receiving towards\n",
    "rewards or penalties for certain actions.\n",
    "So reinforcement enforcement learning is mostly used in like automatic, like self-driving cars and\n",
    "robots and race cars where there is no human involved.\n",
    "So or in some kind of game where you want to program like some, uh, some toy or something and it will\n",
    "keep like going through multiple, multiple races and see, every time it, it has an accident or it\n",
    "hits, it learns and it creates a reinforcement, like a reward.\n",
    "What is the reward and what is a penalty?\n",
    "And it will just keep doing that and it will learn from that environment.\n",
    "So this is the type of learning used by, as I mentioned, self-driving cars and robots to learn how\n",
    "to navigate their environments.\n",
    "So next is artificial intelligence.\n",
    "Artificial intelligence refers to the ability of computers and machines to perform tasks that would\n",
    "normally require human intelligence, such as learning problem solving and decision making.\n",
    "So as I mentioned, this is a higher form of of machine learning or deep learning, but this is a higher\n",
    "form.\n",
    "So this is a machine learning involved, plus some some kind of intelligence like some kind of problem\n",
    "solving or decision making skills.\n",
    "So there are several types of artificial intelligence, including narrow or weak artificial intelligence.\n",
    "This type of AI is used to perform a specific task, such as playing a game or recognizing speech.\n",
    "It is not generally capable of performing other tasks, general or strong AI.\n",
    "This type of AI is capable of performing a wide range of tasks and can exhibit human like intelligence.\n",
    "And last is artificial superintelligence.\n",
    "This is a hypothetical future form of AI that would surpass human intelligence in a wide range of domains.\n",
    "So next, again, continuing artificial intelligence is achieved through a combination of machine learning\n",
    "algorithms and other techniques that allow computers to process and analyze data in order to make decisions\n",
    "and take actions.\n",
    "Some common applications of AI include image and speech recognition, natural language processing and\n",
    "autonomous vehicles.\n",
    "He has the potential to revolutionize.\n",
    "Revolutionize many industries and has already had a significant impact on fields such as healthcare,\n",
    "finance and manufacturing.\n",
    "Next last concept is deep learning.\n",
    "Deep learning is a subfield of machine learning that is inspired by the structure and function of the\n",
    "brain, especially the neural networks that make up the brain.\n",
    "It involves training artificial neural networks on a large dataset, allowing allowing the network to\n",
    "learn and make intelligent decisions on its own.\n",
    "Deep learning algorithms are constructed using multiple layers of artificial neural networks with each\n",
    "layer processing the input data and passing it on to the next layer.\n",
    "So part to this hierarchical structure allows the algorithm to learn and represent very complex patterns\n",
    "in the data.\n",
    "Deep learning has been successful in a wide range of applications, including image and speech recognition,\n",
    "natural language processing and even playing games like Chess and Go.\n",
    "It has also been used to improve the performance of machine learning algorithms in other fields such\n",
    "as healthcare and finance.\n",
    "So just I'll try to explain in the simplest possible way.\n",
    "In manual programming.\n",
    "So in like in regular programming, you tell the computer like what is the algorithm equation formula\n",
    "or rules, for example, I'll just take one example.\n",
    "For example, you tell like you give some input and you say one plus two equal to three.\n",
    "So you just program, you just write a program where that it gets two inputs and outcome or output wil\n",
    "be three.\n",
    "So you just you just tell that this is the formula, this is the equation, this is the rule.\n",
    "So the computer will just perform this.\n",
    "There is no learning involved.\n",
    "Just you tell this is the the formula, right?\n",
    "But in machine learning machines learn the algorithm equation or the formula by themselves, by different\n",
    "permutations.\n",
    "So for example.\n",
    "You just feed in the data.\n",
    "You just say input that to input, for example, A and B and the outcome or output.\n",
    "Let's just call let's call it C, So you just say a B is the input and output will be six and you just\n",
    "feed in more data like three and four and output is is 12 and same.\n",
    "You have given the three set of data, just very simplistic example like even 1 or 2 will do.\n",
    "But just to, just to put my point across.\n",
    "So you just feed in, for example, the third set of data like four into four and five A and B and the\n",
    "output will be 20 in this case.\n",
    "So you tell the computer that, tell me what is the formula like?\n",
    "What is the equation?\n",
    "And in this case, for simplistic, it can be plus minus, multiply or divide.\n",
    "So so machines will go through all the data and will figure out, okay, this is like a multiplication\n",
    "multiplication.\n",
    "So this is very simplistic way, but in in real world will be like a very complex problem.\n",
    "It can have exponential logarithms, root square, root, quadratic, root, all kind of things can\n",
    "go.\n",
    "It can be there will be multiple like features where multiple inputs it can span ten, 2000s also and\n",
    "there will be one single output.\n",
    "And the mathematical operator can be not for it can be any number of it can be root, square, root\n",
    "log exponential.\n",
    "So the computer will just will go through all the data and finally come up with the most optimal like\n",
    "generic equation.\n",
    "And then that's how they learn.\n",
    "So we don't have to program and figure out all the logic and all.\n",
    "So for complex real world problems, you feed in lots of data and expected outcomes and machines will\n",
    "come up with the algorithm equation or the formula.\n",
    "So you can just some some people will call it algorithm rules equation problem.\n",
    "So just think of anything that can represent some real world problem and what could be the expected\n",
    "solution.\n",
    "So that's all.\n",
    "Thanks for watching.\n",
    "\"\"\"\n",
    "\n",
    "documents = [Document(page_content=tutorial_text)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3789a7f-3adc-47c6-8596-3779c8da31ac",
   "metadata": {},
   "source": [
    "https://python.langchain.com/v0.2/docs/integrations/llms/google_ai/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "583d7fdc-476a-41b1-9814-7223758b2c64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_text='''\n",
    "1.You are a Named Entity Recognition in English Language.\n",
    "2.Do some analysis to extract the Keywords, that is important entities, from the text. \n",
    "3.Assign a Category for each entity, in Upper Case. Assign MISC for Entites which cannot be classified easily.\n",
    "4.Extract a Summary Definition for each Keyword Extracted. The Summary Definition must not be more than 100 words length. If no definition is available, assign NOT AVAILABLE. \n",
    "4.Return this result as JSON for each Keyword. Thus each Keyword will have 3 JSON Attributes: Entity, Category and Definition.\n",
    "Analyze the following sentences: \"'\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca4799f4-f4f9-47bc-b791-d290d7d1733d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. chunks21\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "# split documents into text and embeddings\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "   chunk_size=512, \n",
    "   chunk_overlap=20,\n",
    "   length_function=len,\n",
    "   is_separator_regex=False\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "print(f\"No. chunks{len(chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b3a3d52-26bb-4b2c-aa37-1930fcb38f95",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='```json\\n[\\n  {\\n    \"Entity\": \"Data Science\",\\n    \"Category\": \"FIELD\",\\n    \"Definition\": \"Data science uses statistical and computational techniques to extract insights from data. It combines computer science, statistics, and domain expertise to analyze complex datasets. Data scientists utilize tools like machine learning algorithms, statistical analysis, and visualization tools to work with structured and unstructured data.\"\\n  },\\n  {\\n    \"Entity\": \"Machine Learning\",\\n    \"Category\": \"FIELD\",\\n    \"Definition\": \"Machine learning teaches computers to learn from data without explicit programming. It\\'s a subset of' response_metadata={'is_blocked': False, 'safety_ratings': [{'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability_label': 'NEGLIGIBLE', 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE'}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability_label': 'NEGLIGIBLE', 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE'}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability_label': 'NEGLIGIBLE', 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE'}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability_label': 'NEGLIGIBLE', 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE'}], 'usage_metadata': {'prompt_token_count': 2154, 'candidates_token_count': 128, 'total_token_count': 2282}} id='run-7b16b3d9-eb18-44e5-a96c-e0eb2c0e2284-0' usage_metadata={'input_tokens': 2154, 'output_tokens': 128, 'total_tokens': 2282}\n"
     ]
    }
   ],
   "source": [
    "response =  chat_llm.invoke(prompt_text+tutorial_text+'\"')\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a3f58cb-f1ec-4fa6-93a2-135b5840d8f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "graph_extract_prompt = '''\n",
    "# Knowledge Graph Instructions for Gemini\n",
    "## 1. Overview\n",
    "You are a top-tier algorithm designed for extracting information in structured \n",
    "formats to build a knowledge graph.\n",
    "Try to capture as much information from the text as possible without \n",
    "sacrificing accuracy. Do not add any information that is not explicitly \n",
    "mentioned in the text\n",
    "- **Nodes** represent entities and concepts.\n",
    "- The aim is to achieve simplicity and clarity in the knowledge graph, making it\n",
    "accessible for a vast audience.\n",
    "## 2. Labeling Nodes\n",
    "- **Consistency**: Ensure you use available types for node labels.\n",
    "Ensure you use basic or elementary types for node labels.\n",
    "- For example, when you identify an entity representing a person, \n",
    "always label it as **'person'**. Avoid using more specific terms \n",
    "like 'mathematician' or 'scientist'\n",
    "  - **Node IDs**: Never utilize integers as node IDs. Node IDs should be \n",
    "names or human-readable identifiers found in the text.\n",
    "- **Relationships** represent connections between entities or concepts.\n",
    "Ensure consistency and generality in relationship types when constructing \n",
    "knowledge graphs. Instead of using specific and momentary types \n",
    "such as 'BECAME_PROFESSOR', use more general and timeless relationship types \n",
    "like 'PROFESSOR'. Make sure to use general and timeless relationship types!\n",
    "## 3. Coreference Resolution\n",
    "- **Maintain Entity Consistency**: When extracting entities, it's vital to \n",
    "ensure consistency.\n",
    "    If an entity, such as John Doe, is mentioned multiple times in the text \n",
    "but is referred to by different names or pronouns (e.g., Joe, he),\n",
    "always use the most complete identifier for that entity throughout the \n",
    "knowledge graph. In this example, use John Doe as the entity ID.\n",
    "Remember, the knowledge graph should be coherent and easily understandable, \n",
    "so maintaining consistency in entity references is crucial.\n",
    "## 4. Strict Compliance\n",
    "Adhere to the rules strictly. Non-compliance will result in termination.\n",
    "Analyze the following text corpus: \"'\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fcd42848-f178-46ef-9758-679788676cc0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "graph_extract_corpus = \"\"\"\n",
    "Current Professional Machine Learning Engineer Certification exam guide\n",
    "A Professional Machine Learning Engineer builds, evaluates, productionizes, and optimizes ML models by using Google Cloud technologies and knowledge of proven models and techniques. The ML Engineer handles large, complex datasets and creates repeatable, reusable code. The ML Engineer considers responsible AI and fairness throughout the ML model development process, and collaborates closely with other job roles to ensure long-term success of ML-based applications. The ML Engineer has strong programming skills and experience with data platforms and distributed data processing tools. The ML Engineer is proficient in the areas of model architecture, data and ML pipeline creation, and metrics interpretation. The ML Engineer is familiar with foundational concepts of MLOps, application development, infrastructure management, data engineering, and data governance. The ML Engineer makes ML accessible and enables teams across the organization. By training, retraining, deploying, scheduling, monitoring, and improving models, the ML Engineer designs and creates scalable, performant solutions.\n",
    "Note: The exam does not directly assess coding skill. If you have a minimum proficiency in Python and Cloud SQL, you should be able to interpret any questions with code snippets.\n",
    "Register now\n",
    "The Professional Machine Learning Engineer exam does not cover generative AI, as the tools used to develop generative AI-based solutions are evolving quickly. If you are interested in generative AI, please refer to the Introduction to Generative AI Learning Path (all audiences) or the Generative AI for Developers Learning Path (technical audience). If you are a partner, please refer to the Gen AI partner courses: Introduction to Generative AI Learning Path, Generative AI for ML Engineers, and Generative AI for Developers.\n",
    "Section 1: Architecting low-code ML solutions (~12% of the exam)\n",
    "1.1 Developing ML models by using BigQuery ML. Considerations include:\n",
    "Building the appropriate BigQuery ML model (e.g., linear and binary classification, regression, time-series, matrix factorization, boosted trees, autoencoders) based on the business problem\n",
    "Feature engineering or selection by using BigQuery ML\n",
    "Generating predictions by using BigQuery ML\n",
    "1.2 Building AI solutions by using ML APIs. Considerations include:\n",
    "Building applications by using ML APIs (e.g., Cloud Vision API, Natural Language API, Cloud Speech API, Translation)\n",
    "Building applications by using industry-specific APIs (e.g., Document AI API, Retail API)\n",
    "1.3 Training models by using AutoML. Considerations include:\n",
    "Preparing data for AutoML (e.g., feature selection, data labeling, Tabular Workflows on AutoML)\n",
    "Using available data (e.g., tabular, text, speech, images, videos) to train custom models\n",
    "Using AutoML for tabular data\n",
    "Creating forecasting models using AutoML\n",
    "Configuring and debugging trained models\n",
    "Section 2: Collaborating within and across teams to manage data and models (~16% of the exam)\n",
    "2.1 Exploring and preprocessing organization-wide data (e.g., Cloud Storage, BigQuery, Spanner, Cloud SQL, Apache Spark, Apache Hadoop). Considerations include:\n",
    "Organizing different types of data (e.g., tabular, text, speech, images, videos) for efficient training\n",
    "Managing datasets in Vertex AI\n",
    "Data preprocessing (e.g., Dataflow, TensorFlow Extended [TFX], BigQuery)\n",
    "Creating and consolidating features in Vertex AI Feature Store\n",
    "Privacy implications of data usage and/or collection (e.g., handling sensitive data such as personally identifiable information [PII] and protected health information [PHI])\n",
    "2.2 Model prototyping using Jupyter notebooks. Considerations include:\n",
    "Choosing the appropriate Jupyter backend on Google Cloud (e.g., Vertex AI Workbench, notebooks on Dataproc)\n",
    "Applying security best practices in Vertex AI Workbench\n",
    "Using Spark kernels\n",
    "Integration with code source repositories\n",
    "Developing models in Vertex AI Workbench by using common frameworks (e.g., TensorFlow, PyTorch, sklearn, Spark, JAX)\n",
    "2.3 Tracking and running ML experiments. Considerations include:\n",
    "Choosing the appropriate Google Cloud environment for development and experimentation (e.g., Vertex AI Experiments, Kubeflow Pipelines, Vertex AI TensorBoard with TensorFlow and PyTorch) given the framework\n",
    "Section 3: Scaling prototypes into ML models (~18% of the exam)\n",
    "3.1 Building models. Considerations include:\n",
    "Choosing ML framework and model architecture\n",
    "Modeling techniques given interpretability requirements\n",
    "3.2 Training models. Considerations include:\n",
    "Organizing training data (e.g., tabular, text, speech, images, videos) on Google Cloud (e.g., Cloud Storage, BigQuery)\n",
    "Ingestion of various file types (e.g., CSV, JSON, images, Hadoop, databases) into training\n",
    "Training using different SDKs (e.g., Vertex AI custom training, Kubeflow on Google Kubernetes Engine, AutoML, tabular workflows)\n",
    "Using distributed training to organize reliable pipelines\n",
    "Hyperparameter tuning\n",
    "Troubleshooting ML model training failures\n",
    "3.3 Choosing appropriate hardware for training. Considerations include:\n",
    "Evaluation of compute and accelerator options (e.g., CPU, GPU, TPU, edge devices)\n",
    "Distributed training with TPUs and GPUs (e.g., Reduction Server on Vertex AI, Horovod)\n",
    "Section 4: Serving and scaling models (~19% of the exam)\n",
    "4.1 Serving models. Considerations include:\n",
    "Batch and online inference (e.g., Vertex AI, Dataflow, BigQuery ML, Dataproc)\n",
    "Using different frameworks (e.g., PyTorch, XGBoost) to serve models\n",
    "Organizing a model registry\n",
    "A/B testing different versions of a model\n",
    "4.2 Scaling online model serving. Considerations include:\n",
    "Vertex AI Feature Store\n",
    "Vertex AI public and private endpoints\n",
    "Choosing appropriate hardware (e.g., CPU, GPU, TPU, edge)\n",
    "Scaling the serving backend based on the throughput (e.g., Vertex AI Prediction, containerized serving)\n",
    "Tuning ML models for training and serving in production (e.g., simplification techniques, optimizing the ML solution for increased performance, latency, memory, throughput)\n",
    "Section 5: Automating and orchestrating ML pipelines (~21% of the exam)\n",
    "5.1 Developing end-to-end ML pipelines. Considerations include:\n",
    "Data and model validation\n",
    "Ensuring consistent data pre-processing between training and serving\n",
    "Hosting third-party pipelines on Google Cloud (e.g., MLFlow)\n",
    "Identifying components, parameters, triggers, and compute needs (e.g., Cloud Build, Cloud Run)\n",
    "Orchestration framework (e.g., Kubeflow Pipelines, Vertex AI Pipelines, Cloud Composer)\n",
    "Hybrid or multicloud strategies\n",
    "System design with TFX components or Kubeflow DSL (e.g., Dataflow)\n",
    "5.2 Automating model retraining. Considerations include:\n",
    "Determining an appropriate retraining policy\n",
    "Continuous integration and continuous delivery (CI/CD) model deployment (e.g., Cloud Build, Jenkins)\n",
    "5.3 Tracking and auditing metadata. Considerations include: \n",
    "Tracking and comparing model artifacts and versions (e.g., Vertex AI Experiments, Vertex ML Metadata)\n",
    "Hooking into model and dataset versioning\n",
    "Model and data lineage\n",
    "Section 6: Monitoring ML solutions (~14% of the exam)\n",
    "6.1 Identifying risks to ML solutions. Considerations include:\n",
    "Building secure ML systems (e.g., protecting against unintentional exploitation of data or models, hacking)\n",
    "Aligning with Google’s Responsible AI practices (e.g., biases)\n",
    "Assessing ML solution readiness (e.g., data bias, fairness)\n",
    "Model explainability on Vertex AI (e.g., Vertex AI Prediction)\n",
    "6.2 Monitoring, testing, and troubleshooting ML solutions. Considerations include:\n",
    "Establishing continuous evaluation metrics (e.g., Vertex AI Model Monitoring, Explainable AI)\n",
    "Monitoring for training-serving skew\n",
    "Monitoring for feature attribution drift\n",
    "Monitoring model performance against baselines, simpler models, and across the time dimension\n",
    "Common training and serving errors\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "70c6feb5-f77d-4bf9-becc-aa7445f56c03",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='```json\\n{\\n  \"nodes\": [\\n    {\\n      \"id\": \"Professional Machine Learning Engineer\",\\n      \"type\": \"role\"\\n    },\\n    {\\n      \"id\": \"ML models\",\\n      \"type\": \"concept\"\\n    },\\n    {\\n      \"id\": \"Google Cloud technologies\",\\n      \"type\": \"technology\"\\n    },\\n    {\\n      \"id\": \"proven models\",\\n      \"type\": \"concept\"\\n    },\\n    {\\n      \"id\": \"techniques\",\\n      \"type\": \"concept\"\\n    },\\n' response_metadata={'is_blocked': False, 'safety_ratings': [{'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability_label': 'NEGLIGIBLE', 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE'}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability_label': 'NEGLIGIBLE', 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE'}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability_label': 'NEGLIGIBLE', 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE'}, {'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability_label': 'NEGLIGIBLE', 'blocked': False, 'severity': 'HARM_SEVERITY_NEGLIGIBLE'}], 'usage_metadata': {'prompt_token_count': 2091, 'candidates_token_count': 128, 'total_token_count': 2219}} id='run-e2ccf3ad-e610-4d1b-a2f9-d9c6269868e3-0' usage_metadata={'input_tokens': 2091, 'output_tokens': 128, 'total_tokens': 2219}\n"
     ]
    }
   ],
   "source": [
    "response =  chat_llm.invoke(graph_extract_prompt+graph_extract_corpus+'\"')\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3b8cb5-0be9-44af-9447-ecf7435ea975",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m123",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m123"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
